<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=description content="The Computational Vision Lab combines computational theory with behavioral and brain image experiments to understand how we see the world around us."><meta name=author content="Daniel Kersten"><meta name=lang:clipboard.copy content="Copy to clipboard"><meta name=lang:clipboard.copied content="Copied to clipboard"><meta name=lang:search.language content=en><meta name=lang:search.pipeline.stopwords content=True><meta name=lang:search.pipeline.trimmer content=True><meta name=lang:search.result.none content="No matching documents"><meta name=lang:search.result.one content="1 matching document"><meta name=lang:search.result.other content="# matching documents"><meta name=lang:search.tokenizer content=[\s\-]+><link rel="shortcut icon" href=../../assets/images/favicon.ico><meta name=generator content="mkdocs-1.1, mkdocs-material-4.6.3"><title>Computational Vision - Computational Vision Lab</title><link rel=stylesheet href=../../assets/stylesheets/application.230f4177.css><script src=../../assets/javascripts/modernizr.eca31fed.js></script><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>body,input{font-family:"Open Sans","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style><link rel=stylesheet href=../../assets/fonts/material-icons.css></head> <body dir=ltr> <svg class=md-svg> <defs> </defs> </svg> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay data-md-component=overlay for=__drawer></label> <a href=#computational-vision tabindex=0 class=md-skip> Skip to content </a> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid"> <div class=md-flex> <div class="md-flex__cell md-flex__cell--shrink"> <a href=https://twin-cities.umn.edu title="University of Minnesota homepage" aria-label="University of Minnesota homepage" class="md-header-nav__button md-logo"> <img alt=logo src=/assets/images/D2D-gld-wht.svg width=288 height=38> </a> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--menu md-header-nav__button" for=__drawer></label> </div> <div class="md-flex__cell md-flex__cell--shrink"> <a href=https://twin-cities.umn.edu title="University of Minnesota homepage" aria-label="University of Minnesota homepage" class=block-m> <img alt=logo src=/assets/images/block-m-gold.svg height=34> </a> </div> <div class="md-flex__cell md-flex__cell--stretch"> <div class="md-flex__ellipsis md-header-nav__title" data-md-component=title> <span class=md-header-nav__topic> <a href=https://psych.umn.edu title="Department of Psychology" aria-label="Department of Psychology" class=md-header-nav__parentunit> <small>Department of Psychology</small> </a><br> <a href=../.. title="Computational Vision Lab" aria-label="Computational Vision Lab" class=md-header-nav__site-name> Computational Vision Lab </a> </span> <span class=md-header-nav__topic> <a href=../.. title="Computational Vision Lab" aria-label="Computational Vision Lab" class=md-header-nav__site-name-title> <small>Computational Vision Lab</small> </a> <br> <strong> <font face=Arial>Computational Vision </strong> </span> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--search md-header-nav__button" for=__search></label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input aria-label=search name=query placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=query data-md-state=active> <label class="md-icon md-search__icon" for=__search></label> <button type=reset class="md-icon md-search__icon" data-md-component=reset tabindex=-1> &#xE5CD; </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=result> <div class=md-search-result__meta> Type to start searching </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> </div> </div> </nav> </header> <div class=md-container> <main class=md-main role=main> <div class="md-main__inner md-grid" data-md-component=container> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" data-md-level=0> <label class="md-nav__title md-nav__title--site" for=__drawer> <a href=../.. title="Computational Vision Lab" class="md-nav__button md-logo"> <img alt=logo src=../../assets/images/D2D-gld-wht.svg height=28> </a> Computational Vision Lab </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. title=Home class=md-nav__link> Home </a> </li> <li class=md-nav__item> <a href=../../publications/ title=Publications class=md-nav__link> Publications </a> </li> <li class=md-nav__item> <a href=../ title=Courses class=md-nav__link> Courses </a> </li> <li class=md-nav__item> <a href=../../demos/ title=Demos class=md-nav__link> Demos </a> </li> <li class=md-nav__item> <a href=../../datasets/ title=Datasets class=md-nav__link> Datasets </a> </li> <li class=md-nav__item> <a href=../../people/ title=People class=md-nav__link> People </a> </li> <li class=md-nav__item> <a href=../../contact/ title="Contact information" class=md-nav__link> Contact information </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc>Table of contents</label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#readings class=md-nav__link> Readings </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#main class=md-nav__link> Main </a> </li> <li class=md-nav__item> <a href=#additional-readings class=md-nav__link> Additional readings </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#math-and-vision class=md-nav__link> Math and vision </a> </li> <li class=md-nav__item> <a href=#functional-human-vision class=md-nav__link> Functional human vision </a> </li> <li class=md-nav__item> <a href=#neurophysiology class=md-nav__link> Neurophysiology </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#software class=md-nav__link> Software </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#mathematica class=md-nav__link> Mathematica </a> </li> <li class=md-nav__item> <a href=#pythonipython class=md-nav__link> Python/IPython </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#writing class=md-nav__link> Writing </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <h1 id=computational-vision><font face=Arial>Computational Vision<a class=headerlink href=#computational-vision title="Permanent link">&para;</a></h1> <p></font><font size=4 face=Arial><em>courses.kersten.org</em></font><font size=4 face=Arial><strong>Psychology Department , University of Minnesota</strong></font><font size=4 face=Arial><strong>Psy 5036W, Fall 2017, 3 credits #34359</strong><br> </font><font size=4>08:15 A.M. - 9:30 A.M. Mondays and Wednesdays<br> Elliott Hall N668</font></p> <p><em>Instructor</em>: Daniel Kersten. <em>Office</em>: S212 Elliott Hall. <em>Phone</em>: 612 625-2589 <em>email</em>: <a href=mailto:kersten@.umn.edu>kersten@umn.edu</a><br> <em>Office hours</em>: Mondays 9:30-10:30 am or by appointment.</p> <p>The visual perception of what is in the world is accomplished continually, instantaneously, and usually without conscious thought. The very effortlessness of perception disguises the underlying richness of the problem. We can gain insight into the processes and functions of human vision by studying the relationship between neural mechanisms and visual behavior through computer analysis and simulation. Students will learn about the anatomy and neurophysiology of vision and how they relate to the phenomona of perception. An underlying theme will be to treat vision as a process of statistical inference. There will be in-class programming exercises using the language Mathematica. No prior programming experience is required; however, some familiarity with probability, vector calculus and linear algebra is helpful.</p> <h3 id=readings>Readings<a class=headerlink href=#readings title="Permanent link">&para;</a></h3> <h4 id=main>Main<a class=headerlink href=#main title="Permanent link">&para;</a></h4> <ul> <li><a href=#LectureNotes>Lecture notes, Main Readings &amp; Supplementary Material</a> are online.</li> </ul> <h4 id=additional-readings>Additional readings<a class=headerlink href=#additional-readings title="Permanent link">&para;</a></h4> <h5 id=math-and-vision>Math and vision<a class=headerlink href=#math-and-vision title="Permanent link">&para;</a></h5> <ul> <li> <p>(<strong>EV</strong>) Early Vision. Yuille and Kersten. In <em>From Neuron to Cognition via Computational Neuroscience</em>, M.A. Arbib, James J. Bonaiuto Editors, Cambridge MA: The MIT Press, in 2016 (<a href=../../papers/YuilleKerstenFinalChapter2016.pdf>preprint pdf</a>)</p> </li> <li> <p>Understanding Vision: Theory, Models, and Data. Li Zhaoping. 2014.(<a href="https://global.oup.com/academic/product/understanding-vision-9780199564668?q=Zhaoping%20Vision%20Book&lang=en&cc=gb">publisher page</a>) (<a href=http://www0.cs.ucl.ac.uk/staff/zhaoping.li/VisionBook.html>author's web outline</a>)</p> </li> </ul> <h5 id=functional-human-vision>Functional human vision<a class=headerlink href=#functional-human-vision title="Permanent link">&para;</a></h5> <ul> <li>(<strong>FV</strong>) <em>Foundations of Vision</em>. Wandell (<a href=https://foundationsofvision.stanford.edu>web</a>)</li> </ul> <h5 id=neurophysiology>Neurophysiology<a class=headerlink href=#neurophysiology title="Permanent link">&para;</a></h5> <ul> <li>(<strong>NVN</strong>) <a href=https://mitpress.mit.edu/books/new-visual-neurosciences><em>The New Visual Neurosciences</em></a>. John S. Werner and Leo M. Chalupa, edts. 2014. <a href=../../coursepapers/NewVisualNeurosciences9780262019163_toc_0001.pdf>(Table of Contents pdf)</a></li> </ul> <h3 id=software>Software<a class=headerlink href=#software title="Permanent link">&para;</a></h3> <h4 id=mathematica>Mathematica<a class=headerlink href=#mathematica title="Permanent link">&para;</a></h4> <p>Mathematica is the primary programming environment for this course. Students who have registered for the course will have Google Docs access through the Psychology Department's site license.</p> <p><span class=p3>Alternatives: <font size=-1 face=Arial>Mathematica is available in several labs on campus, go to <a href=http://www.oit.umn.edu/computer-labs/software/index.htm>http://www.oit.umn.edu/computer-labs/software/index.htm<br> </a></font>You may wish to purchase <em><span style=font-size:10.0pt;font-family:Arial>Mathematica for Students</span></em> see <span style=font-family:Arial><a href=http://www.wolfram.com/products/student/mathforstudents/index.html><span style=font-size:10.0pt;>http://www.wolfram.com/products/student/mathforstudents/index.html</span></a>.</span></span><span class=p3><br> You can also access <strong><em>Mathematica</em></strong> on the CLA servers:</span></p> <p><span class=p3><a href=http://gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2013/rdc%20for%20mac.pdf>mac</a> (Note: you may have to change the forward slash to a back slash)<br> <a href=http://gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2013/rdc%20for%20windows.pdf>windows</a></span></p> <p>If you never programmed before go <a href=http://www.wolfram.com/language/elementary-introduction/2nd-ed/ >here</a>. If you have programming experience, go <a href=http://www.wolfram.com/language/fast-introduction-for-programmers/en/ >here</a>.</p> <p>For user help on using Mathematica, see: <a href=http://mathematica.stackexchange.com>http://mathematica.stackexchange.com</a></p> <h4 id=pythonipython>Python/IPython<a class=headerlink href=#pythonipython title="Permanent link">&para;</a></h4> <p><a href=http://ipython.org>http://ipython.org</a><a href=http://jupyter-notebook-beginner-guide.readthedocs.org/en/latest/index.html><br> http://jupyter-notebook-beginner-guide.readthedocs.org/en/latest/index.html</a><br> <a href=http://www.scipy.org>http://www.scipy.org</a></p> <p>For an online course in using Python and PsychoPy for research in human vision see:<a href=http://www.scipy.org><br> </a><a href=http://nbviewer.ipython.org/github/gestaltrevision/python_for_visres/blob/master/index.ipynb>http://nbviewer.ipython.org/github/gestaltrevision/python_for_visres/blob/master/index.ipynb</a> </p> <h3 id=writing><strong><span style=font-family:Arial>Writing</span></strong><a class=headerlink href=#writing title="Permanent link">&para;</a></h3> <ul> <li> <p>Gopen, G. D., &amp; Swan, J. A., 1990. The Science of Scientific Writing. <u>American Scientist</u>, <u>78</u>, 550-558. (<a href=../../coursepapers/GopenSwan1990.pdf>pdf</a>)</p> </li> <li> <p><span class=p3><font size=-1 face=Arial><strong>Supplementary:</strong></font></span></p> <ul> <li><span class=p3>The Sense of Style: The Thinking Person's Guide to Writing in the 21<sup>st</sup> Century (2014), Pinker, Steven. (<a href=http://www.amazon.com/The-Sense-Style-Thinking-Persons/dp/0670025852>amazon link</a>)</span></li> <li><span class=p3><font size=-1 face=Arial>Penrose, A. M., &amp; Katz, S. B. (1998). <u>Writing in the Sciences: Exploring Conventions of Scientific Discourse</u>. New York: St. Martin's Press, Inc.</font></span></li> <li><span class=p3><font size=-1 face=Arial>American Psychological Association. (2009). <u>Publication manual of the American Psychological Association</u> (6<sup>th</sup> ed.). Washington, DC: American Psychological Association</font></span></li> </ul> </li> <li> <p><span class=p3><strong><font size=-1 face=Arial>Writing assistance.</font></strong> <font size=-1 face=Arial>THE CENTER FOR WRITING offers free one-to-one writing assistance to undergraduate and graduate students, with appointments up to 45 minutes. Nonnative speaker specialists are available. For more information, see <a href=http://writing.umn.edu>http://writing.umn.edu</a>.</font></span></p> </li> <li>Psychology department resources: <a href=http://writing.psych.umn.edu/student-resources>http://writing.psych.umn.edu/student-resources</a></li> </ul> <p>**Grade Requirements </p> <p>**<font size=-1 face=Arial>There will be programming assignments and a <a href=#FinalProject>final project</a>.</font></p> <p><font size=-1 face=Arial>The grade weights are:</font></p> <ul> <li> <p>Exercise/programming assignments: 55% </p> </li> <li> <p>Final project presentations: 5 %</p> </li> <li> <p>Final project : 40% (four parts: 2%+5%+5%+28%)</p> </li> </ul> <p><font size=-1 face=Arial>The programming assignments will use the <em>Mathematica</em> programming environment. No prior experience with <em>Mathematica</em> is necessary.</font> </p> <dl> <dd> <font size=-1 face=Arial>Assignment due</font> <font size=-1 face=Arial color=#FF0000>By the midnight on</font> <font size=-1 face=Arial>the day due. _**<font color=#FF0000>Late Policy</font>: Assignments turned in within 24 hours following the due date will have 15% deducted from the assignment score. Assignments turned in between 24 and 48 hours following the due date will have 30% deducted from the score. Assignments more than 48 hours late will receive a score of zero.**_</font> </dd> </dl> <hr> <h1 id=lectures><a name=LectureNotes></a>Lectures<a class=headerlink href=#lectures title="Permanent link">&para;</a></h1> <p><font face=Arial><strong><em>Check this section before each class for recent additions and revisions.</em></strong></font></p> <p><a href=http://vision.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5036W2015/5036Syllabus.html>(5036W Course material from 2015)</a></p> <p><font face=Arial><strong><em><span style=text-align:center><span style=font-size:9.0pt;font-family:Arial;>Lecture notes are in <span class=SpellE>Mathematica</span> Notebook and <span class=SpellE>pdf</span> format. You can download the <span class=SpellE>Mathematica</span> notebook files below to view with <span class=SpellE>Mathematica</span> or Wolfram CDF <a href=http://www.wolfram.com/products/player/ >Player</a> (which is free).</span></span><br> </em></strong></font></p> <table name="Table of Lectures" width=79% border=1 align=center> <tbody> <tr> <td bordercolor=#999999 width=72 align=center><span class=p3>[University Calendar](http://onestop.umn.edu/onestop/calendar.html)</span></td> <td width=24 align=center><span class=p3>**Date**</span></td> <td width=159 valign=top align=center><span class=p3>**Lecture**</span></td> <td width=159 valign=top align=center><span class=p3>_**Main Readings**_</span></td> <td width=379 valign=top align=center><span class=p3>**Supplementary Material**</span></td> <td width=163 valign=top align=center><span class=p3>**Assignments due**</span></td> </tr> <tr> <td rowspan=4 bordercolor=#999999 width=72 valign=top height=33 align=left> <div align=center><span class=p3>**I. Introduction**</span></div> </td> <td valign=top height=33 bgcolor=#FFFFFF align=left> <div align=center><span class=p3>Sep 6</span></div> </td> <td class=p3 width=159 valign=top bgcolor=#FFFFFF align=left><span class=p3>1\. Introduction to Computational Vision</span></td> <td width=159 valign=top height=33 bgcolor=#FFFFFF align=left> _[1.IntroToComputationalVision.nb](Lectures/1_MultidisciplinaryStudy/1.IntroToComputationalVision.nb) ([pdf](Lectures/1_MultidisciplinaryStudy/1.IntroToComputationalVision.nb.pdf))_ Olshausen, B. A. (2013). Perception as an Inference Problem. In M. Gazzaniga (Ed.), The New Cognitive Neurosciences, 5th Edition (pp. 1â€“22). MIT Press. (pp. 1â€“18). MIT Press. ([pdf](../../coursepapers/Olshausen2013Perception_as_an_Inference_Problem.pdf)) </td> <td width=379 valign=top height=33 bgcolor=#FFFFFF align=left> Screencast: [http://www.wolfram.com/broadcast/screencasts/handsonstart/](http://www.wolfram.com/broadcast/screencasts/handsonstart/) (WITH AUDIO)[ ](Lectures/1_MultidisciplinaryStudy/FoxApertures2.mov)Check out demos under: **Life Sciences/Cognitive Science/Perception** and **Engineering & Technology/Image Processing** on the Mathematica Demonstrations site: [http://demonstrations.wolfram.com/](http://demonstrations.wolfram.com/) _Kersten, D., & Yuille, A. (2003). Bayesian models of object perception. Current Opinion in Neurobiology, 13(2), 1-9\. ([pdf](../../coursepapers/KerstenYuilleCurrOpinNeu2003.pdf))_ [EV: Section 1](../../papers/YuilleKerstenFinalChapter2016.pdf) </td> <td class=p3 width=163 valign=top height=33 bgcolor=#FFFFFF align=left> </td> </tr> <tr bgcolor=lightgrey> <td valign=top height=39 bgcolor=#CCCCCC align=left> <div align=center><span class=p3>Sep 11</span></div> </td> <td width=159 valign=top bgcolor=#CCCCCC align=left><span class=p3>2.Limits to Vision</span></td> <td width=159 valign=top height=39 bgcolor=#CCCCCC align=left><span class=p3>_[2.LimitsToVision.nb](Lectures/2_Limits to Vision/2_LimitsToVision.nb) [(pdf)](Lectures/2_Limits to Vision/2_LimitsToVision.nb.pdf)__ Hecht, S., Shlaer, S., & Pirenne, M. H. (1942). Energy, quanta, and vision. Journal of General Physiology, 25, 819-840\. ([pdf](../../coursepapers/hecht+al_42.pdf))_</span></td> <td width=379 valign=top height=39 bgcolor=#CCCCCC> Barlow, H. B. (1981). Critical Limiting Factors in the Design of the Eye and Visual Cortex. Proc. Roy. Soc. Lond. B, 212, 1-34\. ([pdf](../../coursepapers/barlow_81.pdf)) Baylor, D. A., Lamb, T. D., & Yau, K. W. (1979). Responses of retinal rods to single photons. Journal of Physiology, Lond., 288, 613-634\. ([pdf](../../coursepapers/baylor+al_79b.pdf)) Tinsley, J. N., Molodtsov, M. I., Prevedel, R., Wartmann, D., Pons, J. E. E., Lauwers, M., & Vaziri, A. (2016). Direct detection of a single photon by humans. Nature Communications, 7, 1–9\. [http://doi.org/10.1038/ncomms12172](http://doi.org/10.1038/ncomms12172) ([pdf)](../../coursepapers/Tinsley16.pdf) </td> <td width=163 valign=top height=39 bgcolor=#CCCCCC> </td> </tr> <tr bgcolor=white> <td bgcolor=#CCCCCC align=left> <div align=center><span class=p3>Sep 13</span></div> </td> <td width=159 valign=top bgcolor=#CCCCCC><span class=p3>3\. The Ideal Observer</span></td> <td width=159 valign=top bgcolor=#CCCCCC><span class=p3>_[3.TheIdealObserver.nb](Lectures/3_TheIdealObserver/3_TheIdealObserver.nb) [(pdf)](Lectures/3_TheIdealObserver/3_TheIdealObserver.nb.pdf)_</span></td> <td width=379 valign=top bgcolor=#CCCCCC> [ProbabilityOverview.nb](Lectures/3_TheIdealObserver/ProbabilityOverview2017.nb) [(pdf)](Lectures/3_TheIdealObserver/ProbabilityOverview2017.nb.pdf) Griffiths, T. L., & Yuille, A. (2008). A primer on probabilistic inference. In M. Oaksford and N. Chater (Eds.). The probabilistic mind: Prospects for rational models of cognition. Oxford: Oxford University Press [(pdf](../../coursepapers/GriffithsYuilleProbPrimerTICsmmc1.pdf)). Try your luck against an ideal discriminator of dot density [YesNoDotDiscriminationDemo.nb](Lectures/3_TheIdealObserver/YesNoDotDiscriminationDemo.nb) </td> <td width=163 valign=top bgcolor=#CCCCCC> Upload Assignment #1 to [Moodle ](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Assignment_1_Mathematica.nb](Grading, Exercises & Exams/Assignments_due/Problem_Set_1.nb) </td> </tr> <tr bgcolor=white> <td bgcolor=#FFFFFF align=left> <div align=center><span class=p3>Sep 18</span></div> </td> <td width=159 valign=top bgcolor=#FFFFFF><span class=p3>4\. Ideal observer analysis: Humans vs. ideals. Neurons vs. ideals</span></td> <td width=159 valign=top bgcolor=#FFFFFF> _[4.IdealObserverAnalysis.nb](Lectures/4_Ideal Observer Analysis/4_IdealObserverAnalysis.nb)_ ([pdf](Lectures/4_Ideal Observer Analysis/4_IdealObserverAnalysis.nb.pdf)) </td> <td width=379 valign=top bgcolor=#FFFFFF> Kersten and Mamassian (2008), Ideal observer theory. The New Encyclopedia of Neuroscience, Squire et al., editors ([pdf](../../coursepapers/KerstenMamassian2009IdealObsTheory.pdf)). Geisler, W. S. (2011). Contributions of ideal observer theory to vision research. Vision Research, 51(7), 771–781.[(pdf)](../../coursepapers/Geisler2011Contributions_of_ideal_observer_theory_to_vision_research.pdf) Burgess, A. E., Wagner, R. F., Jennings, R. J., & Barlow, H. B. (1981)_. Efficiency of human visual signal discrimination. Science, 214(4516), 93-94. [(pdf)](../../coursepapers/BurgessScience1981.pdf)_ Deneve, S., Latham, P. E., & Pouget, A. (1999). Reading population codes: a neural implementation of ideal observers. Nature Neuroscience, 2(8), 740–745\. [(pdf)](../../coursepapers/Deneve1999Reading_population_codes_a_neural_implementation_of_ideal_observers.pdf) Measure your absolute efficiency to discriminate dot density using a 2AFC task [2AFCDotDiscriminationDemo.nb](Lectures/4_Ideal%20Observer%20Analysis/2AFCDotDiscriminationDemo.nb) </td> <td width=163 valign=top bgcolor=#FFFFFF> </td> </tr> <tr> <td rowspan=3 bordercolor=#999999 width=72> <div align=center><span class=p3>**II. Image formation, pattern synthesis**</span></div> </td> <td bgcolor=#FFFFFF align=left> <div align=center><span class=p3>Sep 20</span></div> </td> <td width=159 valign=top bgcolor=#FFFFFF><span class=p3>5.Psychophysics: tools & techniques</span></td> <td width=159 valign=top bgcolor=#FFFFFF> _[5.Psychophysics.nb](Lectures/5_PsychophysicsSKEobserver/5_Psychophysics.nb)[](Lectures/5_PsychophysicsSKEobserver/5_Psychophysics.nb) [(pdf)](Lectures/5_PsychophysicsSKEobserver/5_Psychophysics.nb.pdf) _ </td> <td width=379 valign=top bgcolor=#FFFFFF> [SKEDetection2AFCInLineDisplay.nb](Lectures/5_PsychophysicsSKEobserver/SKEDetection2AFCInLineDisplay.nb) Farell, B. & Pelli, D. G. (1999) Psychophysical methods, or how to measure a threshold and why. In R. H. S. Carpenter & J. G. Robson (Eds.), Vision Research: A Practical Guide to Laboratory Methods, New York: Oxford University ([pdf](../../coursepapers/farell1999chapter.pdf)) Press.http://psych.nyu.edu/pelli/ Morgenstern, Y., & Elder, J. H. (2012). Local Visual Energy Mechanisms Revealed by Detection of Global Patterns. Journal of Neuroscience, 32(11), 3679–3696\. For a free Matlab psychophysics package, see: [http://psychotoolbox.org](http://psychtoolbox.org/) For a free Python psychophysics package, see: [http://www.psychopy.org](http://www.psychopy.org) </td> <td width=163 valign=top bgcolor=#FFFFFF> </td> </tr> <tr bgcolor=lightgrey> <td bgcolor=#CCCCCC align=left> <div align=center><span class=p3>Sep 25</span></div> </td> <td width=159 valign=top bgcolor=#CCCCCC><span class=p3>6\. Bayesian decision theory & perception</span></td> <td width=159 valign=top bgcolor=#CCCCCC> _[6.BayesDecisionTheory.nb](Lectures/6_BayesDecisionTheory/6_BayesDecisionTheory.nb.pdf) [(pdf)](Lectures/6_BayesDecisionTheory/6_BayesDecisionTheory.nb.pdf)_ _Geisler, W. S., & Kersten, D. (2002). Illusions, perception and Bayes. Nat Neurosci, 5(6), 508-510\. ([pdf](http://gandalf.psych.umn.edu/%7Ekersten/kersten-lab/papers/GeislerKerstennn0602-508.pdf))_ </td> <td width=379 valign=top bgcolor=#CCCCCC> [EV Section 3](../../coursepapers/YuilleKerstenFinalChapter2016.pdf#3) </td> <td width=163 valign=top bgcolor=#CCCCCC><span class=p3> </span></td> </tr> <tr bgcolor=white> <td height=97 bgcolor=#CCCCCC align=left> <div align=center><span class=p3>Sep 27</span></div> </td> <td width=159 valign=top bgcolor=#CCCCCC><span class=p3>7\. Limits to spatial resolution, image modeling, introduction to linear systems</span></td> <td width=159 valign=top bgcolor=#CCCCCC> _[7.ImageModelLinearSystems.nb](Lectures/7.ImageModelingLinearSystems/7.ImageModelLinearSystems.nb) [(pdf)](Lectures/7.ImageModelingLinearSystems/7.ImageModelLinearSystems.nb.pdf)_ _Campbell, F. W., & Green, D. (1965). Optical and retinal factors affecting visual resolution. Journal of Physiology (Lond.), 181, 576-593\. ([pdf](../../coursepapers/CampbellGreen_JP1965.pdf))_ </td> <td width=379 valign=top height=97 bgcolor=#CCCCCC> Williams, D. R. (1986). Seeing through the photoreceptor mosaic. 9(5), 193-197\. ([pdf](../../coursepapers/williams86.pdf)) [LinearAlgebraReview.nb](Lectures/7.ImageModelingLinearSystems/LinearAlgebraReview.nb) [Convolutions_Tutorial.nb](Lectures/7.ImageModelingLinearSystems/Convolutions_Tutorial.nb) [IPython convolutions notebook](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/2a.Convolution.ipynb) </td> <td width=163 valign=top height=97 bgcolor=#CCCCCC>     Upload Assignment #2 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Problem_Set_2.nb](Grading, Exercises & Exams/Assignments_due/Problem_Set_2.nb) (correction 10/4/17) </td> </tr> <tr> <td rowspan=5 bordercolor=#999999 width=72> <div align=center><span class=p3>**III. Early visual coding**</span></div> </td> <td height=52 bgcolor=#FFFFFF align=left> <div align=center><span class=p3>Oct 2</span></div> </td> <td width=159 valign=top bgcolor=#FFFFFF><span class=p3>8\. Linear systems analysis</span></td> <td width=159 valign=top height=52 bgcolor=#FFFFFF><span class=p3>_[8.LinearSystemsOptics.nb](Lectures/8\. Spatial filters/8.LinearSystemsOptics.nb) [(pdf)](Lectures/8\. Spatial filters/8.LinearSystemsOptics.nb.pdf) _</span></td> <td width=379 valign=top height=52 bgcolor=#FFFFFF> [EV: Section 2](../../papers/YuilleKerstenFinalChapter2016.pdf) _[CSF.gif](Lectures/8\. Spatial filters/CSF.gif)_ Tutorials: [Fourier_neural_image.nb](Lectures/8\. Spatial filters/Fourier_neural_image.nb) </td> <td width=163 valign=top height=52 bgcolor=#FFFFFF> </td> </tr> <tr bgcolor=lightgrey> <td bgcolor=#FFFFFF align=left> <div align=center><span class=p3>Oct 4</span></div> </td> <td width=159 valign=top bgcolor=#FFFFFF><span class=p3>9\. Features and filters. Spatial filter models of early human vision</span></td> <td width=159 valign=top bgcolor=#FFFFFF> _[9.NeuralSpatialFiltering.nb](Lectures/9\. Multi-scale analysis/9.NeuralSpatialFiltering.nb) [(pdf)](Lectures/9\. Multi-scale analysis/9.NeuralSpatialFiltering.nb.pdf)_ </td> <td width=379 valign=top bgcolor=#FFFFFF> Campbell, F. W., & Robson, J. R. (1968). Application of Fourier Analysis to the Visibility of Gratings. Journal of Physiology 197, 551-566\. ([pdf](../../coursepapers/CampbellRobson_JP1968.pdf)) De Valois, R. L., Albrecht, D. G., & Thorell, L. G. (1982). Spatial frequency selectivity of cells in macaque visual cortex. Vision Res, 22(5), 545-559\. ([pdf](../../coursepapers/DeValoisAlbrechtThorell1982.pdf)) Watson, A. B. (1987). Efficiency of a model human image code. J Opt Soc Am A, 4(12), 2401-2417\. ([pdf)](http://vision.arc.nasa.gov/publications/Efficiency.pdf) [IPython demo of gabor filtering](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/2b.Gabor.ipynb) Steerable pyramids: [http://www.cns.nyu.edu/~eero/steerpyr/](http://www.cns.nyu.edu/%7Eeero/steerpyr/) </td> <td width=163 valign=top bgcolor=#FFFFFF> </td> </tr> <tr bgcolor=lightgrey> <td height=68 bgcolor=#CCCCCC align=left> <div align=center><span class=p3>Oct 9</span></div> </td> <td width=159 valign=top bgcolor=#CCCCCC><span class=p3>10\. Features and filters. Local processing & image analysis</span></td> <td width=159 valign=top height=68 bgcolor=#CCCCCC><span class=p3>_[10.ImageProcessing.nb](Lectures/10.ImageManipulations/10.ImageProcessing.nb) [(pdf)](Lectures/10.ImageManipulations/10.ImageProcessing.nb.pdf)_ Gollisch, T., & Meister, M. (2010). Eye Smarter than Scientists Believed: Neural Computations in Circuits of the Retina. Neuron, 65(2), 150–164\. ([pdf](../../coursepapers/Gollisch2010Eye_Smarter_than_Scientists_Believed_Neural_Computations_in_Circuits_of_the_Retina.pdf))</span></td> <td width=379 valign=top height=68 bgcolor=#CCCCCC><span class=p3>Albrecht, D. G., De Valois, R. L., & Thorell, L. G. (1980). Visual cortical neurons: are bars or gratings the optimal stimuli? Science, 207(4426), 88-90.[(pdf)](../../coursepapers/AlbrechtDeValoisThorellScience1980.pdf) Adelson, E. H., & Bergen, J. R. (1991). The plenoptic function and the elements of early vision. In M. S. Landy & J. A. Movshon (Eds.), Computational Models of Visual Processing. Cambridge, MA: The MIT Press: A Bradford Book.[(pdf](../../coursepapers/AdelsonBergenPlenopticelements91.pdf)[)](../../coursepapers/adelson-bergen-85.pdf) ClassificationImage demo ([ReverseCorrelation.nb](Reverse%20correlation/ReverseCorrelation.nb)) Ahumada, A. J., Jr. (2002). Classification image weights and internal noise level estimation. J Vis, 2(1), 121-131. ([pdf)](Reverse%20correlation/Ahumada-2002-jov-2-1-8.pdf)</span></td> <td width=163 valign=top height=68 bgcolor=#CCCCCC> Upload Assignment 3 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Problem_Set_3.nb](Grading, Exercises & Exams/Assignments_due/Problem_Set_3.nb) [](Grading,%20Exercises%20&%20Exams/Assignments_due/Assignmt_2_Convolve.nb) </td> </tr> <tr bgcolor=white> <td bgcolor=#CCCCCC align=left> <div align=center><span class=p3>Oct 11</span></div> </td> <td width=159 valign=top bgcolor=#CCCCCC><span class=p3>11\. Coding efficiency: Retina</span></td> <td width=159 valign=top bgcolor=#CCCCCC background="Lectures/11\. Efficient
            coding/11.CodingEfficiency.nb"> _[11.CodingEfficiency.nb](Lectures/11\. Efficient coding/11.CodingEfficiency.nb) [(pdf)](Lectures/11\. Efficient coding/11.CodingEfficiency.nb.pdf)_ Geisler, W. S. (2008). Visual perception and the statistical properties of natural scenes. Annu Rev Psychol, 59, 167-192\. [(pdf)](../../coursepapers/Geisler2008annurev.psych.58.110405.085632.pdf) </td> <td width=379 valign=top bgcolor=#CCCCCC> Laughlin, S. (1981). A simple coding procedure enhances a neuron's information capacity. Z Naturforsch [C], 36(9-10), 910-912.([pdf](../../coursepapers/Laughlin1981.pdf)) Atick, J. J., & Redlich, A. N. (1992). What does the retina know about natural scenes? Neural Computation, 4(2), 196–210\. Meister, M., & Berry, M. J., 2nd. (1999). The neural code of the retina. Neuron, 22(3), 435-450.[(pdf](../../coursepapers/meister+berry_99.pdf)) Srinivasan, M. V., Laughlin, S. B., & Dubs, A. (1982). Predictive coding: a fresh view of inhibition in the retina. Proc R Soc Lond B Biol Sci, 216(1205), 427-459.([pdf](../../coursepapers/srinivasan+al_82.pdf)) [IPython demo of natural image statistics](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/3a.Natural%20Image%20Statistics.ipynb) </td> <td width=163 valign=top bgcolor=#CCCCCC> </td> </tr> <tr bgcolor=white> <td bgcolor=#FFFFFF align=left> <div align=center><span class=p3>Oct 16</span></div> </td> <td width=159 valign=top bgcolor=#FFFFFF><span class=p3>12\. Coding efficiency: Cortex </span></td> <td width=159 valign=top bgcolor=#FFFFFF> _[12.SpatialCodingEfficiency.nb](Lectures/12\. Efficent coding Spatial/12.SpatialCodingEfficiency.nb) [(pdf)](Lectures/12\. Efficent coding Spatial/12.SpatialCodingEfficiency.nb.pdf)_ _Simoncelli, E. P., & Olshausen, B. A. (2001). Natural image statistics and neural representation. Annu Rev Neurosci, 24, 1193-1216.[(pdf](../../coursepapers/SimoncelliOlshausenAnnRev1999.pdf))_ </td> <td width=379 valign=top bgcolor=#FFFFFF> [ContrastNormalizationNotes.nb](Lectures/12\. Efficent coding Spatial/ContrasNormalizationNotes.nb) Laughlin, S. B., de Ruyter van Steveninck, R. R., & Anderson, J. C. (1998). The metabolic cost of neural information. Nat Neurosci, 1(1), 36-41.([pdf)](../../coursepapers/laughlin+al_98.pdf) Lennie, P. (2003). The cost of cortical computation. Curr Biol, 13(6), 493-497. [(pdf)](../../coursepapers/LennieCurBio2003.pdf) Multi-resolution, image pyramids, and efficient coding: [JepsonFleet2005pyramids_notes.pdf ](../../coursepapers/JepsonFleet2005pyramids_notes.pdf)[AdelsonPyramidRCA84.pdf](../../coursepapers/AdelsonPyramidRCA84.pdf) </td> <td width=163 valign=top bgcolor=#FFFFFF> </td> </tr> <tr> <td rowspan=11 bordercolor=#999999 width=72> <div align=center><span class=p3>**IV. Intermediate-level vision, integration, grouping**</span></div> </td> <td height=72 bgcolor=#FFFFFF align=left> <div align=center><span class=p3>Oct 18</span></div> </td> <td width=159 valign=top bgcolor=#FFFFFF><span class=p3>13\. Edge detection</span></td> <td width=159 valign=top height=72 bgcolor=#FFFFFF><span class=p3>[13.EdgeDetection.nb](Lectures/13\. Edges/13.EdgeDetection.nb) [(pdf)](Lectures/13\. Edges/13.EdgeDetection.nb.pdf)</span></td> <td width=379 valign=top height=72 bgcolor=#FFFFFF> Hubel, D. H., & Wiesel, T. N. (1977). Ferrier lecture. Functional architecture of macaque monkey visual cortex. Proc R Soc Lond B Biol Sci, 198(1130), 1-59\. [(pdf)](../../coursepapers/HubelWieselFerrier1977.pdf) [IPython demo of statistical edge detection](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/3b.Statistical%20Edge%20Detection.ipynb) </td> <td width=163 valign=top height=72 bgcolor=#FFFFFF> </td> </tr> <tr bgcolor=lightgrey> <td bgcolor=#CCCCCC align=left> <div align=center><span class=p3>Oct 23</span></div> </td> <td valign=top bgcolor=#CCCCCC><span class=p3>14. Objects and scenes from images. The visual cortical pathways and hierarchy.</span></td> <td valign=top height=72 bgcolor=#CCCCCC> _[14.ScenesfromImages.nb](Lectures/14.Scenes from images/14.ScenesfromImages.nb) [(pdf)](Lectures/14.Scenes from images/14.ScenesfromImages.nb.pdf)__ von der Heydt R (2003) Image parsing mechanisms of the visual cortex. In: The Visual Neurosciences (Werner JS, Chalupa LM, eds.), pp 1139-1150\. Cambridge, Mass.: MIT press.[(pdf](../../coursepapers/VonderHeydt_ImageParsing_neuroscience.pdf))_ Kersten, D. J., & Yuille, A. L. (2014). Inferential Models of the Visual Cortical Hierarchy. In M. S. Gazzaniga & G. R. Mangun (Eds.), The New Cognitive Neurosciences, 5th Edition (pp. 1â€“22). MIT Press. [(pdf)](http://vision.psych.umn.edu/users/kersten//kersten-lab/coursepapers/KerstenYuilleNewCogNeuro2014.pdf) </td> <td valign=top height=72 bgcolor=#CCCCCC><span class=p3>Zhou H, Friedman HS, von der Heydt R (2000) Coding of border ownership in monkey visual cortex. J Neuroscience 20: 6594-6611\. ([pdf](../../coursepapers/ZhouFriedmanVonDerHeydt_2000_6594.pdf))</span></td> <td width=163 valign=top bgcolor=#CCCCCC> </td> </tr> <tr bgcolor=white> <td bgcolor=#CCCCCC align=left> <div align=center><span class=p3>Oct 25</span></div> </td> <td width=159 valign=top bgcolor=#FFFFFF><span class=p3>15\. Scene-based generative models</span></td> <td width=159 valign=top bgcolor=#FFFFFF> _[15.SurfaceGeometryDepth.nb](Lectures/15\. Surfacegeometrydepth/15.SurfaceGeometryDepth.nb) [(pdf)](Lectures/15\. Surfacegeometrydepth/15.SurfaceGeometryDepth.nb.pdf)_ _Kersten, D., Mamassian, P., & Yuille, A. (2004). Object perception as Bayesian Inference. Annual Review of Psychology, 55, 271-304\. ([pdf](../../coursepapers/KerstenMamassianYuille_2004_annurev.psych.55.090902.142005.pdf))_ </td> <td width=379 valign=top bgcolor=#FFFFFF></td> <td width=163 valign=top height=22 bgcolor=#FFFFFF></td> </tr> <tr bgcolor=white> <td height=22 bgcolor=#FFFFFF align=left> <div align=center><span class=p3>Oct 30</span></div> </td> <td class=p3 width=159 valign=top bgcolor=#FFFFFF><span class=p3>16\. Shape-from-X</span></td> <td width=159 valign=top bgcolor=#FFFFFF><span class=p3>_[16.ShapeFromX.nb](Lectures/16\. Shape-from-X/16.ShapeFromX.nb) [(pdf)](Lectures/16\. Shape-from-X/16.ShapeFromX.nb.pdf)_</span></td> <td width=379 valign=top height=23 bgcolor=#FFFFFF> Reflectance map: Shape from shading: Horn BKP (1986) Robot Vision. Cambridge MA: MIT Press. Ch 11 ([pdf)](../../coursepapers/ch11_Shape_from_Shading.pdf). Barron, J. T., & Malik, J. (2015). Shape, Illumination, and Reflectance from Shading. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(8), 1670â€“1687. http://doi.org/10.1109/TPAMI.2014.2377712 [(pdf)](../../coursepapers/BarronMalik2015IEEE_Transactions_on_Pattern_Analysis_and_Machine_Intelligence.pdf) Belhumeur, P. N., Kriegman, D. J., & Yuille, A. (1997). The Bas-Relief Ambiguity. ([pdf](https://pdfs.semanticscholar.org/71ac/0dc7634e4a56fd41dfac270ec5883fcbb44f.pdf)) Johnson, M. K., & Adelson, E. H. (2011). Shape Estimation in Natural Illumination. Computer Vision and Pattern Recognition (CVPR), 2553–2560. Muryy, A. A., Welchman, A. E., Blake, A., & Fleming, R. W. (2013). Specular reflections and the estimation of shape from binocular disparity. Proceedings of the National Academy of Sciences of the United States of America, 110(6), 2413–2418\. [(link](http://www.pnas.org/content/110/6/2413.short)) [cube.mov](../../coursepapers/cube.mp4) [random.mov](../../coursepapers/random.mp4) </td> <td width=163 valign=top height=23 bgcolor=#FFFFFF><span class=p3> </span> Upload Assignment #4 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Problem_Set_4.nb ](Grading, Exercises & Exams/Assignments_due/Problem_Set_4.nb)[(pdf)](Grading, Exercises & Exams/Assignments_due/Problem_Set_4.nb.pdf) [bluradaptationdemo](../../coursepapers/WebsterGeorgeBlurAdnn906-S1.mp4) [(Webster et al. pdf)](../../coursepapers/WebsterGeorgesonBlurAdaptationnn906.pdf) [motion-induced-blindness demo](../../coursepapers/BasicBonnehYellowDisksBlueDots.gif) [(Bonneh et al. pdf)](../../coursepapers/BonnehCoopemanSagiNature2001411798.pdf) <span class=p3> </span></td> </tr> <tr bgcolor=lightgrey> <td height=23 bgcolor=#FFFFFF align=left> <div align=center><span class=p3>Nov 1</span></div> </td> <td class=p3 width=159 valign=top bgcolor=#CCCCCC> 17\. Shape from shading <span style='font-size:9.0pt;font-family:Arial;"Times New
                Roman"'>Overview of python/ipython for computational vision</span>[ ](https://wakari.io/sharing/bundle/kersten/Lect_19Intro_Python) </td> <td width=159 valign=top height=38 bgcolor=#CCCCCC> _[17. Shape from shading.nb](Lectures/17.Shape from shading/17.ShapeFromShading.nb)_ [(pdf)](Lectures/17.Shape from shading/17.ShapeFromShading.nb.pdf) [Lect_17Intro_Python.ipynb](Lectures/17_PythonForVision/Lect_17Intro_Python.ipynb) (source) ([pdf](Lectures/17_PythonForVision/Lect_17Intro_Python.pdf)) <span class=p3>_[17\. IPython notebook](http://nbviewer.jupyter.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2017/Lectures/17_PythonForVision/Lect_17Intro_Python.ipynb)_</span> [Demos](Lectures/17_PythonForVision/Demos/index.html) <span class=p3>by Weichao Qiu and Dan Kersten, supplement to _**Early Vision**._ Yuille and Kersten. A chapter in _From Neuron to Cognition via Computational Neuroscience_, M.A. Arbib, James J. Bonaiuto Editors, Cambridge MA: The MIT Press, in 2016</span> </td> <td width=379 valign=top height=38 bgcolor=#CCCCCC> [Anaconda](https://store.continuum.io/cshop/anaconda/) python installation recommended. We will use [Juypter/IPython](http://ipython.org), a browser-based notebook interface for python. See [here](http://nbviewer.ipython.org/github/ipython/ipython/blob/1.x/examples/notebooks/Part%205%20-%20Rich%20Display%20System.ipynb) for illustrations of IPython cell types, and [here](https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks) for a collection of sample notebooks. Look [here](http://iacs-courses.seas.harvard.edu/courses/am207/blog/installing-python.html) for some good tips on installation, as well as the parent directory for excellent ipython-based course material on scientific computing using Monte Carlo methods. For a quick start to scientific programming, see: [http://nbviewer.ipython.org/gist/rpmuller/5920182](http://nbviewer.ipython.org/gist/rpmuller/5920182) For a comphrensive coverage of scientific python see[:https://scipy-lectures.github.io](https://scipy-lectures.github.io) And for a ground-up set of tutorials on python see: [http://learnpythonthehardway.org/book/](http://learnpythonthehardway.org/book/) Switching from matlab to python? [http://wiki.scipy.org/NumPy_for_Matlab_User](http://mathesaurus.sourceforge.net/matlab-numpy.html) [ProjectIdeasF2015.nb](Grading,%20Exercises%20&%20Exams/FinalProjectIdeasF2015.nb) [(pdf)](Grading,%20Exercises%20&%20Exams/FinalProjectIdeasF2015.nb.pdf) </td> <td width=163 valign=top height=38 bgcolor=#CCCCCC></td> </tr> <tr bgcolor=lightgrey> <td height=38 bgcolor=#CCCCCC align=left> <div align=center><span class=p3>Nov 6</span></div> </td> <td class=p3 width=159 valign=top bgcolor=#CCCCCC><span class=p3>18\. Motion: optic flow</span></td> <td width=159 valign=top height=38 bgcolor=#CCCCCC> _[18.MotionOpticFlow.nb](Lectures/18.MotionOpticFlow/18.MotionOpticFlow.nb) [(pdf)](Lectures/18.MotionOpticFlow/18.MotionOpticFlow.nb.pdf)_ _OpenCV python demo:_ [OpticFlowSparse.ipynb](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/Lectures/18.MotionOpticFlow/OpticFlowSparse.ipynb) needs: [648aa10.avi](Lectures/17_PythonForVision/648aa10.avi) </td> <td width=379 valign=top height=38 bgcolor=#CCCCCC> Horn, B. K. P., & Schunck, B. G. (1981). Determining Optical Flow. Artificial Intelligence, 17, 185-203\. ([pdf](../../coursepapers/Optical_Flow_OPT.pdf)) Optic Flow (2013) Florian Raudies, Scholarpedia, 8(7):30724\. doi:10.4249/scholarpedia.30724 ([link](http://www.scholarpedia.org/article/Optic_flow)) (with available matlab code) Optic flow matlab code from Michael Black's lab. ([link](http://cs.brown.edu/people/black/code.html)) Borst, A. (2007). Correlation versus gradient type motion detectors: the pros and cons. Philos Trans R Soc Lond B Biol Sci, 362(1479), 369-374\. [pdf](../../coursepapers/Borst2007rstb20061964.pdf)) [http://web.mit.edu/persci/people/adelson/illusions_demos.html](http://web.mit.edu/persci/people/adelson/illusions_demos.html) [IPython aperture demo](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/Lectures/17_PythonForVision/Aperture%20demo.ipynb) EV: Section 2.4 FV: Chapter 10 </td> <td width=163 valign=top bgcolor=#CCCCCC></td> </tr> <tr bgcolor=white> <td bgcolor=#CCCCCC align=left> <div align=center><span class=p3>Nov 8</span></div> </td> <td class=p3 width=159 valign=top bgcolor=#FFFFFF><span class=p3>19\. Motion: biological, human perception</span></td> <td width=159 valign=top bgcolor=#FFFFFF background=Lectures/19.MotionIllusionsBayes/19.MotionHumanPerception.nb> _[19.MotionHumanPerception.nb](Lectures/19.MotionIllusionsBayes/19.MotionHumanPerception.nb) [(pdf)](Lectures/19.MotionIllusionsBayes/19.MotionHumanPerception.nb.pdf)_ _Weiss, Y., Simoncelli, E. P., & Adelson, E. H. (2002). Motion illusions as optimal percepts. Nat Neurosci, 5(6), 598-604. ([pdf](../../coursepapers/WeissSimonAdelNatNeu2002.pdf))_ </td> <td width=379 valign=top bgcolor=#FFFFFF background=Lectures/18.MotionOpticFlow/aperturedemomovie.mov> Heeger, D. J., Simoncelli, E. P., & Movshon, J. A. (1996). Computational models of cortical visual processing. Proc Natl Acad Sci U S A, 93(2), 623-627\. ([pdf](../../coursepapers/Heeger96-reprint%20PNAS.pdf)) [http://demonstrations.wolfram.com/DisappearingDotIllusion/](http://demonstrations.wolfram.com/DisappearingDotIllusion/) [http://www.biomotionlab.ca/Demos/BMLwalker.html](http://www.biomotionlab.ca/Demos/BMLwalker.html) EV: Section 4.4 FV: Chapter 10 </td> <td width=163 valign=top bgcolor=#FFFFFF> </td> </tr> <tr bgcolor=white> <td bgcolor=#FFFFFF align=left> <div align=center><span class=p3>Nov 13</span></div> </td> <td class=p3 width=159 valign=top bgcolor=#FFFFFF><span class=p3>20\. Material perception</span></td> <td width=159 valign=top bgcolor=#FFFFFF> _[20.SurfaceMaterial.nb](Lectures/20\. Surface material/20.SurfaceMaterial.nb) [(pdf)](Lectures/20\. Surface material/20.SurfaceMaterial.nb.pdf)_ V1 and lightness ([pdf](Lectures/20.%20Surface%20material/V1Lightness.pdf)) Doerschner, K., Fleming, R. W., Yilmaz, O., Schrater, P. R., Hartung, B., & Kersten, D. (2011). Visual motion and the perception of surface material. Current Biology, 21(23), 2010–2016\. ([pdf](../../coursepapers/Doerschner2011Doerschner2011CURRENT-BIOLOGY-S-11-00953-3.pdf)) </td> <td width=379 valign=top bgcolor=#FFFFFF><span class=p3>Fleming, R. W., Dror, R. O., & Adelson, E. H. (2003). Real-world illumination and the perception of surface reflectance properties. J Vis, 3(5), 347-368\. [(link](http://journalofvision.org/3/5/3/)) _Adelson, E. H. (1993). Perceptual organization and the judgment of brightness. Science, 262, 2042-2044 ([pdf](../../coursepapers/AdelsonScience1993.pdf))_ Boyaci, H., Fang, F., Murray, S. O., & Kersten, D. (2007). Responses to lightness variations in early human visual cortex. Curr Biol, 17(11), 989-993 ([pdf](../../coursepapers/BoyaciCurrBiol2007.pdf))_[http://www.bilkent.edu.tr/~hboyaci/Vision/](http://www.bilkent.edu.tr/%7Ehboyaci/Vision/)_ [http://web.mit.edu/persci/people/adelson/checkershadow_illusion.html](http://web.mit.edu/persci/people/adelson/checkershadow_illusion.html) [http://gandalf.psych.umn.edu/users/kersten/kersten-lab/demos/transparency.html](http://gandalf.psych.umn.edu/users/kersten/kersten-lab/demos/transparency.html) [http://gandalf.psych.umn.edu/~kersten/kersten-lab/demos/MatteOrShiny.html](http://gandalf.psych.umn.edu/%7Ekersten/kersten-lab/demos/MatteOrShiny.html)</span></td> <td width=163 valign=top bgcolor=#EDEDED> Upload Assignment 5 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [texture_classification_plot_gabor.ipynb](Grading, Exercises & Exams/Assignments_due/texture_classification_plot_gabor.ipynb) [(view)](http://nbviewer.jupyter.org/url/vision.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5036W2017/Grading, Exercises & Exams/Assignments_due/texture_classification_plot_gabor.ipynb) Upload Final project title & paragraph outline to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) </td> </tr> <tr bgcolor=lightgrey> <td bgcolor=#FFFFFF align=left> <div align=center><span class=p3>Nov 15</span></div> </td> <td class=p3 width=159 valign=top bgcolor=#CCCCCC><span class=p3>21\. Texture.</span></td> <td width=159 valign=top bgcolor=#CCCCCC> _[21.Texture.nb](Lectures/21\. Texture/21.Texture.nb) [(pdf)](Lectures/21\. Texture/21.Texture.nb.pdf)_ Freeman, J., & Simoncelli, E. P. (2011). Metamers of the ventral stream. Nature Publishing Group, 14(9), 1195-1201\. http://doi.org/10.1038/nn.2889 ([pdf](../../coursepapers/Freeman2011Metamers_of_the_ventral_stream.pdf)) </td> <td width=379 valign=top bgcolor=#CCCCCC> Heeger DJ and Bergen JR, Pyramid Based Texture Analysis/Synthesis, Computer Graphics Proceedings, p. 229-238, 1995\. ([pdf)](../../coursepapers/heeger-siggraph95.pdf). [EfrosTextureSynthesis.ipynb](Lectures/21\. Texture/EfrosTextureSynthesis.ipynb) From: [https://github.com/rbaravalle/efros](https://github.com/rbaravalle/efros) [img2.png](Lectures/21\. Texture/img2.png) A sample: [out2.png](Lectures/21\. Texture/out2.png) </td> <td valign=top bgcolor=#CCCCCC> </td> </tr> <tr> <td bgcolor=#CCCCCC align=left> <div align=center><span class=p3>Nov 20</span></div> </td> <td class=p3 valign=top bgcolor=#CCCCCC align=center><span class=p3>22.Science writing (Thanksgiving week)</span></td> <td valign=top bgcolor=#CCCCCC><span class=p3>_[22.ScienceWriting.nb](Lectures/22\. Science Writing/22.ScienceWriting.nb) [(pdf)](Lectures/22\. Science Writing/22.ScienceWriting.nb.pdf)_</span></td> <td valign=top bgcolor=#CCCCCC> Gopen & Swan, 1990 ([pdf](../../coursepapers/GopenSwan1990.pdf)) [UM Psychology](http://writing.psych.umn.edu/student-resources) [Denis <span class=SpellE>Pelli's</span> advice for scientific writing](http://psych.nyu.edu/pelli/style.html) </td> <td width=163 valign=top bgcolor=#CCCCCC> </td> </tr> <tr> <td bgcolor=#CCCCCC align=left> <div align=center><span class=p3>Nov 22 </span></div> </td> <td class=p3 valign=top bgcolor=#FFFFFF><span class=p3>23.Perceptual integration</span></td> <td valign=top bgcolor=#FFFFFF><span class=p3>_[23.PerceptualIntegration.nb](Lectures/23.PerceptualIntegration/23.PerceptualIntegration.nb) [(pdf)](Lectures/23.PerceptualIntegration/23.PerceptualIntegration.nb.pdf) _</span></td> <td valign=top bgcolor=#FFFFFF> McDermott, J., Weiss, Y., & Adelson, E. H. (2001). Beyond junctions: nonlocal form constraints on motion interpretation. Perception, 30(8), 905-923\. ([pdf](../../coursepapers/McDermottbeyond_junctions.pdf)) [http://www.perceptionweb.com/perception/perc0801/square.html](http://www.perceptionweb.com/perception/perc0801/square.html) Hillis, J. M., Ernst, M. O., Banks, M. S., & Landy, M. S. (2002). Combining sensory information: mandatory fusion within, but not between, senses. Science, 298(5598), 1627-1630.([pdf](../../coursepapers/HillisErnstBanksLandyscience02.pdf)) Ernst, M. O., & Banks, M. S. (2002). Humans integrate visual and haptic information in a statistically optimal fashion. Nature, 415(6870), 429-433\. ([pdf](../../coursepapers/ErnstBanks2002.pdf)) Stocker, A. A., & Simoncelli, E. (2008). A Bayesian model of conditioned perception. Advances in Neural Information Processing Systems, 20, 1409-1416\. ([pdf](http://papers.nips.cc/paper/3369-a-bayesian-model-of-conditioned-perception.pdf)) [IPython demo of ideal integration](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/5.Cue%20Combination.ipynb) EV: Section 5 </td> <td valign=top bgcolor=#FFFFFF> </td> </tr> <tr bgcolor=lightgrey> <td rowspan=4 bordercolor=#999999 width=72 bgcolor=white> <div align=center><span class=p3>**V. High-level vision**</span></div> </td> <td bgcolor=#FFFFFF align=left> <div align=center><span class=p3>Nov 27</span></div> </td> <td class=p3 valign=top bgcolor=#FFFFFF><span class=p3>24. Object recognition I</span></td> <td valign=top bgcolor=#FFFFFF> _[24.ObjectRecognition.nb](Lectures/24\. ObjectRecognition_I/24.ObjectRecognition.nb) [(pdf)](Lectures/24\. ObjectRecognition_I/24.ObjectRecognition.nb.pdf)_ _DiCarlo, J. J., Zoccolan, D., & Rust, N. C. (2012). How does the brain solve visual object recognition? Neuron, 73(3), 415–434\._ ([pdf](../../coursepapers/DiCarlo2012How_does_the_brain_solve_visual_object_recognition-2.pdf)) </td> <td width=379 valign=top bgcolor=#FFFFFF> Liu, Z., Knill, D. C., & Kersten, D. (1995). Object Classification for Human and Ideal Observers. Vision Research, 35(4), 549-568\. ([pdf)](../../papers/LiuKnillKersten95.pdf) Tjan, B., Braje, W., Legge, G. E., & Kersten, D. (1995). Human efficiency for recognizing 3-D objects in luminance noise. Vision Research, 35(21), 3053-3069\. ([pdf](../../coursepapers/Tjan1995.pdf)) Tanaka K (2003) Columns for complex visual object features in the inferotemporal cortex: clustering of cells with similar but slightly different stimulus selectivities. Cerebral cortex 13:90-99.([pdf](../../coursepapers/Tanaka2003.pdf)) Serre, T., Oliva, A., & Poggio, T. (2007). A feedforward architecture accounts for rapid categorization. Proc Natl Acad Sci U S A, 104(15), 6424-6429\. ([pdf](../../coursepapers/SerreOlivaPoggioPNAS2007.pdf)) Yamins, D. L. K., Hong, H., Cadieu, C. F., Solomon, E. A., Seibert, D., & DiCarlo, J. J. (2014). Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proceedings of the National Academy of Sciences of the United States of America, 111(23), 8619-8624\. ([pdf](http://www.pnas.org/content/111/23/8619.full.pdf)) </td> <td width=163 valign=top bgcolor=#FFFFFF></td> </tr> <tr bgcolor=lightgrey> <td bgcolor=#FFFFFF align=left> <div align=center><span class=p3>Nov 29</span></div> </td> <td class=p3 width=159 valign=top bgcolor=#CCCCCC><span class=p3>25\. Object recognition II feeforward architectures</span></td> <td width=159 valign=top bgcolor=#CCCCCC><span class=p3>_25_Bidirectional_I.key.pdf ([pdf](Lectures/25\. ObjectRecognition_II/25_Bidirectional_I.pdf)) __ Ullman, S., Vidal-Naquet, M., & Sali, E. (2002). Visual features of intermediate complexity and their use in classification. Nat Neurosci, 5(7), 682-687\. ([pdf](../../coursepapers/UllmanNatureNeuro2002.pdf)) _</span></td> <td width=379 valign=top bgcolor=#CCCCCC> Grill-Spector, K. (2003). The neural basis of object perception. Curr Opin Neurobiol, 13(2), 159-166.([pdf](../../coursepapers/GrillSpector_CurrOpinNeuroB2003.pdf)) Rao, R. P., & Ballard, D. H. (1999). Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat Neurosci, 2(1), 79-87\. ([pdf](../../coursepapers/RaoBallard99.pdf)) Bullier, J. (2001). Integrated model of visual processing. Brain Res Brain Res Rev, 36(2-3), 96-107\. ([pdf](../../coursepapers/bullier2001.pdf)) Tenenbaum JB: Bayesian modeling of human concept learning. In Advances in Neural Information Processing Systems. Edited by Kearns MSS, Solla A, Cohn DA: Cambridge, MA: MIT Press: 1999.([pdf)](../../coursepapers/JoshTenenbaumbayes.pdf) </td> <td width=163 valign=top bgcolor=#CCCCCC> Upload Assignment 6 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Problem_Set_6 .nb](Grading, Exercises & Exams/Assignments_due/Problem_Set_6.nb) </td> </tr> <tr bgcolor=lightgrey> <td bgcolor=#CCCCCC align=left> <div align=center><span class=p3>Dec 4 </span></div> </td> <td class=p3 width=159 valign=top bgcolor=#CCCCCC>26. Object recognition III feedback architectures</td> <td width=159 valign=top bgcolor=#CCCCCC> _26_BidirectionalFeedback.key.pdf_ [(pdf](Lectures/26\. ObjectRecognition_III/26_BidirectionalFeedback.pdf)) </td> <td width=379 valign=top bgcolor=#CCCCCC> Torralba, A., Oliva, A., Castelhano, M. S., & Henderson, J. M. (2006). Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search. Psychol Rev, 113(4), 766-786\. [(pdf](../../coursepapers/Torralba-etal-PsychRev-06.pdf)) Chikkerur, S., Serre, T., Tan, C., & Poggio, T. (2010). What and where: A Bayesian inference theory of attention. Vision Research, 50(22), 2233–2247. </td> <td width=163 valign=top bgcolor=#CCCCCC> </td> </tr> <tr bgcolor=white> <td bgcolor=#CCCCCC align=left> <div align=center><span class=p3>Dec 6</span></div> </td> <td class=p3 valign=top bgcolor=#FFFFFF> 27. Empirical evidence for bidirectional computations </td> <td valign=top bgcolor=#FFFFFF> 27.EmpiricalEvidenceBidirectionalProcessing([pdf](Lectures/27\. EmpiricalEvidenceBidirectionalProcessing/27\. EmpiricalEvidenceBidirectionalProcessing.pdf)) </td> <td valign=top bgcolor=#FFFFFF> Longuet-Higgins, H. C., & Prazdny, K. (1980). The Interpretation of a Moving Retinal Image. Proceedings of the Royal Society of London B, 208, 385-397\. ([pdf](../../coursepapers/LonguetHigginsPrazdnyProcRoySoc1980.pdf)) Horn BKP (1986) Robot Vision. Cambridge MA: MIT Press., chapter 17 ([pdf](../../coursepapers/Hornch17_Structure_From_Motion.pdf)) Schrater PR, Kersten D (2000) How optimal depth cue integration depends on the task. International Journal of Computer Vision 40:73-91\. ([pdf](../../coursepapers/SchraterKerstenIJCV2000.pdf)) </td> <td valign=top bgcolor=#FFFFFF><span class=p3>Upload a complete DRAFT of FINAL PROJECT to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) by _**Wednesday December** __**6th, 5 PM.**_</span></td> </tr> <tr> <td rowspan=3 bordercolor=#999999 width=72> </td> <td bgcolor=#FFFFFF align=left> <div align=center><span class=p3>Dec 11</span></div> </td> <td class=p3 valign=top bgcolor=#FFFFFF>28\. Vision for action, spatial layout, heading. Homegeneous coordinates.</td> <td valign=top bgcolor=#FFFFFF> _[28.SpatialLayoutScenes.nb](Lectures/28\. SpatialLayoutScenes/28.SpatialLayoutScenes.nb) [(pdf](Lectures/28\. SpatialLayoutScenes/28.SpatialLayoutScenes.nb.pdf))_ _Kalman filter notes ([pdf](http://vision.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/Lectures/27\. SpatialLayoutScenes/kalman.pdf))_ </td> <td valign=top bgcolor=#FFFFFF> </td> <td valign=top bgcolor=#FFFFFF><span class=p3>Upload your peer comments to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) by Monday Dec 11th</span></td> </tr> <tr> <td bgcolor=#FFFFFF align=left> <div align=center><span class=p3>Dec 13</span></div> <span class=p3>(Last day of class) </span></td> <td class=p3 width=159 valign=top bgcolor=#FFFFFF> </td> <td width=159 valign=top bgcolor=#FFFFFF><span class=p3>_In Class Project Presentations_</span></td> <td width=379 valign=top bgcolor=#FFFFFF> </td> <td width=163 valign=top bgcolor=#FFFFFF> Drafts returned to you with Instructor comments </td> </tr> <tr> <td bgcolor=#CCCCCC align=left> <div align=center><span class=p3>Dec 21</span></div> </td> <td class=p3 valign=top bgcolor=#CCCCCC> </td> <td valign=top bgcolor=#CCCCCC> </td> <td valign=top bgcolor=#CCCCCC> </td> <td valign=top bgcolor=#CCCCCC><span class=p3 id=R>Upload Final Revised Draft of Project to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100)</span></td> </tr> </tbody> </table> <hr> <p><font face=Arial><a name=FinalProject></a><strong>Final Project Assignment</strong>.</font></p> <p><font face=Arial></p> <p><font face=Arial>Goal: This course integrates the behavioral, neural and computational principles of perception. Students often find the interdisciplinary integration to be the most challenging aspect of the course. Through writing, you will learn to synthesize results from diverse and typically isolated disciplines. By writing about your project work, you will learn to think through the broader implications of your project, and to effectively communicate the rationale and results of your contribution in words. You will do a final page research report in which you will describe, in the form of a scientific paper, the results of an original computer program on a topic in computational vision.</font></p> <p><font face=Arial></p> <p><font face=Arial>Your final project will involve: 1) a computer program and; 2) a 2000-3000 word final paper describing your project. For your computer project, you will do one of the following: 1) Write a program to simulate a model from the computer vision literature ; 2) Design and program a method for solving some problem in perception. 3) Design and program a psychophysical experiment to study an aspect of human visual perception. The results of your final project should be written up in the form of a short scientific paper or Mathematica Notebook, describing the motivation, methods, results, and interpretation.</font></p> <p></font></p> <p>If you choose to write your program in Mathematica, your paper and program can be combined can be formated as a Mathematica notebook. See: <a href=http://www.wolfram.com/solutions/publishing/tutorials.html>Books and Tutorials on Notebooks.</a> If you do your final project using Python, you can turn your paper in as a <a href=https://jupyter.org>Jupyter</a> notebook.</p> <p><font face=Arial><font face=Arial><font face=Arial></p> <p><font face=Arial>Your paper will be critiqued and returned for you to revise and resubmit in final form. You should write for an audience consisting of your class peers.</font></p> <p><font face=Arial></p> <p>Completing the final paper involves 4 steps. Each step requires that you email a document to the teaching assistant.</p> <ol> <li> <p><strong>Outline</strong> <strong>(2% of grade)**</strong>.** You will submit a working title and paragraph outline by the deadline noted in the syllabus. These outlines will be critiqued in order to help you find an appropriate focus for your papers. (Consult with the instructor or TA for ideas well ahead of time).</p> </li> <li> <p><strong>Complete draft (5% of grade).</strong> A double-spaced, complete draft of the paper must be turned in by the deadline noted in the syllabus. Papers should be between <strong>2000</strong> and <strong>3000</strong> words. In addition to the title, author and date lines, papers must include the following sections: Abstract, Introduction, Methods, Results, Discussion, and Bibliography. Use citations to motivate your problem and to justify your claims. Cite authors by name and date, e.g. (Marr &amp; Poggio, 1979). <em>Citations should be original sources, not wikipedia.</em> Use a standard citation format, such as APA. (The UM library has information on <a href="http://www.lib.umn.edu/libdata/page_print.phtml?page_id=791">style guides</a>, and in particular <a href=http://tutorial.lib.umn.edu/infomachine4051.html>APA style</a>.) Papers must be typed, with a page number on each page. Figures should be numbered and have figure captions. This draft will be reviewed by your instructor and one of you class peers. <strong>The point break down for the total 5% is: 2 pts for completing Introduction, 2 pts for completing Methods, 1 pt for completing Discussion)</strong></p> </li> <li> <p><strong>Peer commentary (5% of grade)</strong>. You will submit a written commentary <strong>(200</strong> to <strong>500</strong> words) on a complete draft of one of your class peers. The project drafts and commentaries will be anonymous. The commentary should provide feedback to improve the quality and clarity of the writing.</p> </li> <li> <p><strong>Final draft (20% of grade) and "Cover letter" (8% of grade).</strong> The final draft must be turned in by the date noted on the syllabus. The "Cover letter" should describe how your revision addressed comments from your peer evaluator and from your instructor. It should itemize key criticisms together with a brief description of the changes you made to your draft manuscript.</p> </li> <li> <p><strong>Some Resources:</strong></p> </li> <li> <p>Student Writing Support: Center for Writing, 306b Lind Hall and satellite locations (612.625.1893) <a href=http://writing.umn.edu>http://writing.umn.edu</a>. </p> <p><em>NOTE: Plagiarism, a form of scholastic dishonesty and a disciplinary offense, is described by the Regents as follows: Scholastic dishonesty means plagiarizing; cheating on assignments or examinations; engaging in unauthorized collaboration on academic work; taking, acquiring, or using test materials without faculty permission; submitting false or incomplete records of academic achievement; acting alone or in cooperation with another to falsify records or to obtain dishonestly grades, honors, awards, or professional endorsement; altering, forging, or misusing a University academic record; or fabricating or falsifying data, research procedures, or data analysis. <a href=http://www1.umn.edu/regents/policies/academic/Code_of_Conduct.html>http://www1.umn.edu/regents/policies/academic/Code_of_Conduct.html.</a> See too: <a href=http://writing.umn.edu/tww/plagiarism/ >http://writing.umn.edu/tww/plagiarism/</a> and</em><a href=http://writing.umn.edu/tww/plagiarism/definitions.html>http://writing.umn.edu/tww/plagiarism/definitions.html</a></p> </li> </ol> <p></font><font size=-1><a href=http://privacy.umn.edu/ >Privacy Statement</a></font></font></font></font></font></p> </article> </div> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> &copy; 2020 Regents of the University of Minnesota. All rights reserved. The University of Minnesota is an equal opportunity educator and employer. <br> <a href=http://privacy.umn.edu>Privacy Statement</a> </div> </div> <div class=md-footer-social> <link rel=stylesheet href=../../assets/fonts/font-awesome.css> <a href="https://scholar.google.com/citations?user=6j1ZjJsAAAAJ&hl=en&oi=ao" target=_blank rel=noopener title=google class="md-footer-social__link fa fa-google"></a> <a href=https://github.com/danielkersten/ target=_blank rel=noopener title=github class="md-footer-social__link fa fa-github"></a> </div> </div> </div> </footer> </div> <script src=../../assets/javascripts/application.3b0a34b1.js></script> <script>app.initialize({version:"1.1",url:{base:"../.."}})</script> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script> </body> </html>