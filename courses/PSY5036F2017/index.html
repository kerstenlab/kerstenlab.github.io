<!DOCTYPE html>
<html class="no-js" lang="en"> <head><meta charset="utf-8"/><meta content="width=device-width,initial-scale=1" name="viewport"/><meta content="ie=edge" http-equiv="x-ua-compatible"/><meta content="The Computational Vision Lab combines computational theory with behavioral and brain image experiments to understand how we see the world around us." name="description"/><meta content="Daniel Kersten" name="author"/><meta content="Copy to clipboard" name="lang:clipboard.copy"/><meta content="Copied to clipboard" name="lang:clipboard.copied"/><meta content="en" name="lang:search.language"/><meta content="True" name="lang:search.pipeline.stopwords"/><meta content="True" name="lang:search.pipeline.trimmer"/><meta content="No matching documents" name="lang:search.result.none"/><meta content="1 matching document" name="lang:search.result.one"/><meta content="# matching documents" name="lang:search.result.other"/><meta content="[\s\-]+" name="lang:search.tokenizer"/><link href="/assets/images/favicon.ico" rel="shortcut icon"/><meta content="mkdocs-1.1, mkdocs-material-4.6.3" name="generator"/><title>PSY5036F2017 - Computational Vision Lab</title><link href="../../assets/stylesheets/application.87b292c3.css" rel="stylesheet"/><link href="../../assets/stylesheets/application-palette.b246af5e.css" rel="stylesheet"/><script src="../../assets/javascripts/modernizr.eca31fed.js"></script><link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/><link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,400i,700%7CRoboto+Mono&amp;display=fallback" rel="stylesheet"/><style>body,input{font-family:"Open Sans","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style><link href="../../assets/fonts/material-icons.css" rel="stylesheet"/></head> <body class="psy5036f2017" data-md-color-accent="umn-gold" data-md-color-primary="umn-maroon" dir="ltr"> <svg class="md-svg"> <defs> </defs> </svg> <input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/> <input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/> <label class="md-overlay" data-md-component="overlay" for="__drawer"></label> <a class="md-skip" href="#computational-vision" tabindex="0"> Skip to content </a> <header class="md-header" data-md-component="header"> <nav class="md-header-nav md-grid"> <div class="md-flex"> <div class="md-flex__cell md-flex__cell--shrink"> <a aria-label="University of Minnesota homepage" class="md-header-nav__button md-logo" href="https://twin-cities.umn.edu" title="University of Minnesota homepage"> <img alt="logo" height="38" src="/assets/images/D2D-gld-wht.svg" width="288"/> </a> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label> </div> <div class="md-flex__cell md-flex__cell--shrink"> <a aria-label="University of Minnesota homepage" class="block-m" href="https://twin-cities.umn.edu" title="University of Minnesota homepage"> <img alt="logo" height="24" src="/assets/images/block-m-gold.svg"/> </a> </div> <div class="md-flex__cell md-flex__cell--stretch"> <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title"> <span class="md-header-nav__topic"> <a aria-label="Department of Psychology" class="md-header-nav__parentunit" href="https://psych.umn.edu" title="Department of Psychology"> <small>Department of Psychology</small> </a><br/> <a aria-label="Computational Vision Lab" class="md-header-nav__site-name" href="../.." title="Computational Vision Lab"> Computational Vision Lab </a> </span> <span class="md-header-nav__topic"> <a aria-label="Computational Vision Lab" class="md-header-nav__site-name-title" href="../.." title="Computational Vision Lab"> <small>Computational Vision Lab</small> </a> <br/> <strong> PSY5036F2017 </strong> </span> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label> <div class="md-search" data-md-component="search" role="dialog"> <label class="md-search__overlay" for="__search"></label> <div class="md-search__inner" role="search"> <form class="md-search__form" name="search"> <input aria-label="search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="query" data-md-state="active" name="query" placeholder="Search" spellcheck="false" type="text"/> <label class="md-icon md-search__icon" for="__search"></label> <button class="md-icon md-search__icon" data-md-component="reset" tabindex="-1" type="reset">  </button> </form> <div class="md-search__output"> <div class="md-search__scrollwrap" data-md-scrollfix=""> <div class="md-search-result" data-md-component="result"> <div class="md-search-result__meta"> Type to start searching </div> <ol class="md-search-result__list"></ol> </div> </div> </div> </div> </div> </div> </div> </nav> </header> <div class="md-container"> <main class="md-main" role="main"> <div class="md-main__inner md-grid" data-md-component="container"> <div class="md-sidebar md-sidebar--primary" data-md-component="navigation"> <div class="md-sidebar__scrollwrap"> <div class="md-sidebar__inner"> <nav class="md-nav md-nav--primary" data-md-level="0"> <label class="md-nav__title md-nav__title--site" for="__drawer"> <a class="md-nav__button md-logo" href="../.." title="Computational Vision Lab"> <img alt="logo" height="28" src="/assets/images/D2D-gld-wht.svg"/> </a> Computational Vision Lab </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../.." title="Home"> Home </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../publications/" title="Publications"> Publications </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../people/" title="People"> People </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../research/" title="Research"> Research </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input checked="" class="md-toggle md-nav__toggle" data-md-toggle="nav-5" id="nav-5" type="checkbox"/> <label class="md-nav__link" for="nav-5"> Courses </label> <nav class="md-nav" data-md-component="collapsible" data-md-level="1"> <label class="md-nav__title" for="nav-5"> Courses </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../PSY5036F2019/" title="PSY5036F2019"> PSY5036F2019 </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../PSY8036SP2019/" title="PSY8036SP2019"> PSY8036SP2019 </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../PSY5038F2018/" title="PSY5038F2018"> PSY5038F2018 </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../PSY8036SP2018/" title="PSY8036SP2018"> PSY8036SP2018 </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-toggle md-nav__toggle" data-md-toggle="toc" id="__toc" type="checkbox"/> <label class="md-nav__link md-nav__link--active" for="__toc"> PSY5036F2017 </label> <a class="md-nav__link md-nav__link--active" href="./" title="PSY5036F2017"> PSY5036F2017 </a> <nav class="md-nav md-nav--secondary"> <label class="md-nav__title" for="__toc">Table of contents</label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="#readings"> Readings </a> <nav class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#main"> Main </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#additional-readings"> Additional readings </a> <nav class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#math-and-vision"> Math and vision </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#functional-human-vision"> Functional human vision </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#neurophysiology"> Neurophysiology </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#software"> Software </a> <nav class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#mathematica"> Mathematica </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#pythonipython"> Python/IPython </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#writing"> Writing </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" id="nav-6" type="checkbox"/> <label class="md-nav__link" for="nav-6"> Demos </label> <nav class="md-nav" data-md-component="collapsible" data-md-level="1"> <label class="md-nav__title" for="nav-6"> Demos </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../demos/lightness-shape/" title="Lightness and Shape"> Lightness and Shape </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../demos/matte-shiny/" title="Shiny or Matte?"> Shiny or Matte? </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../demos/retinotopy/" title="Retinotopy"> Retinotopy </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../demos/shadows/" title="Shadows"> Shadows </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../demos/transparency/" title="Transparency"> Transparency </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../images/BlojKerstenHurlbertDemo99.pdf" title="Color and Mutual Illumination"> Color and Mutual Illumination </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7" id="nav-7" type="checkbox"/> <label class="md-nav__link" for="nav-7"> Data sets </label> <nav class="md-nav" data-md-component="collapsible" data-md-level="1"> <label class="md-nav__title" for="nav-7"> Data sets </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../datasets/camouflage/camouflage/" title="Camouflage"> Camouflage </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../contact/" title="Contact"> Contact </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component="toc"> <div class="md-sidebar__scrollwrap"> <div class="md-sidebar__inner"> <nav class="md-nav md-nav--secondary"> <label class="md-nav__title" for="__toc">Table of contents</label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="#readings"> Readings </a> <nav class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#main"> Main </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#additional-readings"> Additional readings </a> <nav class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#math-and-vision"> Math and vision </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#functional-human-vision"> Functional human vision </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#neurophysiology"> Neurophysiology </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#software"> Software </a> <nav class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#mathematica"> Mathematica </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#pythonipython"> Python/IPython </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#writing"> Writing </a> </li> </ul> </nav> </div> </div> </div> <div class="md-content"> <article class="md-content__inner md-typeset"><a class="md-icon md-content__icon" download href="PSY5036F2017.pdf" title="PDF Export"></a> <h1 id="computational-vision"><font face="Arial">Computational Vision<a class="headerlink" href="#computational-vision" title="Permanent link">¶</a></font></h1> <p></p></article></div></div></main></div></body></html><font face="Arial" size="4"><em>courses.kersten.org</em></font><font face="Arial" size="4"><strong>Psychology Department , University of Minnesota</strong></font><font face="Arial" size="4"><strong>Psy 5036W, Fall 2017, 3 credits #34359</strong><br/> </font><font size="4">08:15 A.M. - 9:30 A.M. Mondays and Wednesdays<br/> Elliott Hall N668</font> <p><em>Instructor</em>: Daniel Kersten. <em>Office</em>: S212 Elliott Hall. <em>Phone</em>: 612 625-2589 <em>email</em>: <a href="mailto:kersten@.umn.edu">kersten@umn.edu</a><br/> <em>Office hours</em>: Mondays 9:30-10:30 am or by appointment.</p> <p>The visual perception of what is in the world is accomplished continually, instantaneously, and usually without conscious thought. The very effortlessness of perception disguises the underlying richness of the problem. We can gain insight into the processes and functions of human vision by studying the relationship between neural mechanisms and visual behavior through computer analysis and simulation. Students will learn about the anatomy and neurophysiology of vision and how they relate to the phenomona of perception. An underlying theme will be to treat vision as a process of statistical inference. There will be in-class programming exercises using the language Mathematica. No prior programming experience is required; however, some familiarity with probability, vector calculus and linear algebra is helpful.</p> <h3 id="readings">Readings<a class="headerlink" href="#readings" title="Permanent link">¶</a></h3> <h4 id="main">Main<a class="headerlink" href="#main" title="Permanent link">¶</a></h4> <ul> <li><a href="#LectureNotes">Lecture notes, Main Readings &amp; Supplementary Material</a> are online.</li> </ul> <h4 id="additional-readings">Additional readings<a class="headerlink" href="#additional-readings" title="Permanent link">¶</a></h4> <h5 id="math-and-vision">Math and vision<a class="headerlink" href="#math-and-vision" title="Permanent link">¶</a></h5> <ul> <li> <p>(<strong>EV</strong>) Early Vision. Yuille and Kersten. In <em>From Neuron to Cognition via Computational Neuroscience</em>, M.A. Arbib, James J. Bonaiuto Editors, Cambridge MA: The MIT Press.</p> </li> <li> <p>Understanding Vision: Theory, Models, and Data. Li Zhaoping. 2014.(<a href="https://global.oup.com/academic/product/understanding-vision-9780199564668?q=Zhaoping%20Vision%20Book&amp;lang=en&amp;cc=gb">publisher page</a>) (<a href="http://www0.cs.ucl.ac.uk/staff/zhaoping.li/VisionBook.html">author's web outline</a>)</p> </li> </ul> <h5 id="functional-human-vision">Functional human vision<a class="headerlink" href="#functional-human-vision" title="Permanent link">¶</a></h5> <ul> <li>(<strong>FV</strong>) <em>Foundations of Vision</em>. Wandell (<a href="https://foundationsofvision.stanford.edu">web</a>)</li> </ul> <h5 id="neurophysiology">Neurophysiology<a class="headerlink" href="#neurophysiology" title="Permanent link">¶</a></h5> <ul> <li>(<strong>NVN</strong>) <a href="https://mitpress.mit.edu/books/new-visual-neurosciences"><em>The New Visual Neurosciences</em></a>. John S. Werner and Leo M. Chalupa, edts. 2014.</li> </ul> <h3 id="software">Software<a class="headerlink" href="#software" title="Permanent link">¶</a></h3> <h4 id="mathematica">Mathematica<a class="headerlink" href="#mathematica" title="Permanent link">¶</a></h4> <p>Mathematica is the primary programming environment for this course. Students who have registered for the course will have Google Docs access through the Psychology Department's site license.</p> <p><span class="p3">Alternatives: <font face="Arial" size="-1">Mathematica is available in several labs on campus, go to <a href="http://www.oit.umn.edu/computer-labs/software/index.htm">http://www.oit.umn.edu/computer-labs/software/index.htm<br/> </a></font>You may wish to purchase <em><span style="font-size:10.0pt;font-family:Arial">Mathematica for Students</span></em> see <span style="font-family:Arial"><a href="http://www.wolfram.com/products/student/mathforstudents/index.html"><span style="font-size:10.0pt;">http://www.wolfram.com/products/student/mathforstudents/index.html</span></a>.</span></span><span class="p3"><br/> You can also access <strong><em>Mathematica</em></strong> on the CLA servers:</span></p> <p><span class="p3"><a href="http://gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2013/rdc%20for%20mac.pdf">mac</a> (Note: you may have to change the forward slash to a back slash)<br/> <a href="http://gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2013/rdc%20for%20windows.pdf">windows</a></span></p> <p>If you never programmed before go <a href="http://www.wolfram.com/language/elementary-introduction/2nd-ed/">here</a>. If you have programming experience, go <a href="http://www.wolfram.com/language/fast-introduction-for-programmers/en/">here</a>.</p> <p>For user help on using Mathematica, see: <a href="http://mathematica.stackexchange.com">http://mathematica.stackexchange.com</a></p> <h4 id="pythonipython">Python/IPython<a class="headerlink" href="#pythonipython" title="Permanent link">¶</a></h4> <p><a href="http://ipython.org">http://ipython.org</a><a href="http://jupyter-notebook-beginner-guide.readthedocs.org/en/latest/index.html"><br/> http://jupyter-notebook-beginner-guide.readthedocs.org/en/latest/index.html</a><br/> <a href="http://www.scipy.org">http://www.scipy.org</a></p> <p>For an online course in using Python and PsychoPy for research in human vision see:<a href="http://www.scipy.org"><br/> </a><a href="http://nbviewer.ipython.org/github/gestaltrevision/python_for_visres/blob/master/index.ipynb">http://nbviewer.ipython.org/github/gestaltrevision/python_for_visres/blob/master/index.ipynb</a> </p> <h3 id="writing"><strong><span style="font-family:Arial">Writing</span></strong><a class="headerlink" href="#writing" title="Permanent link">¶</a></h3> <ul> <li>Gopen, G. D., &amp; Swan, J. A., 1990. The Science of Scientific Writing. <u>American Scientist</u>, <u>78</u>, 550-558.</li> <li> <p><span class="p3"><font face="Arial" size="-1"><strong>Supplementary:</strong></font></span></p> <ul> <li><span class="p3">The Sense of Style: The Thinking Person's Guide to Writing in the 21<sup>st</sup> Century (2014), Pinker, Steven. (<a href="http://www.amazon.com/The-Sense-Style-Thinking-Persons/dp/0670025852">amazon link</a>)</span></li> <li><span class="p3"><font face="Arial" size="-1">Penrose, A. M., &amp; Katz, S. B. (1998). <u>Writing in the Sciences: Exploring Conventions of Scientific Discourse</u>. New York: St. Martin's Press, Inc.</font></span></li> <li><span class="p3"><font face="Arial" size="-1">American Psychological Association. (2009). <u>Publication manual of the American Psychological Association</u> (6<sup>th</sup> ed.). Washington, DC: American Psychological Association</font></span></li> </ul> </li> <li> <p><span class="p3"><strong><font face="Arial" size="-1">Writing assistance.</font></strong> <font face="Arial" size="-1">THE CENTER FOR WRITING offers free one-to-one writing assistance to undergraduate and graduate students, with appointments up to 45 minutes. Nonnative speaker specialists are available. For more information, see <a href="http://writing.umn.edu">http://writing.umn.edu</a>.</font></span></p> </li> <li>Psychology department resources: <a href="http://writing.psych.umn.edu/student-resources">http://writing.psych.umn.edu/student-resources</a></li> </ul> <p>**Grade Requirements </p> <p>**<font face="Arial" size="-1">There will be programming assignments and a <a href="#FinalProject">final project</a>.</font></p> <p><font face="Arial" size="-1">The grade weights are:</font></p> <ul> <li> <p>Exercise/programming assignments: 55% </p> </li> <li> <p>Final project presentations: 5 %</p> </li> <li> <p>Final project : 40% (four parts: 2%+5%+5%+28%)</p> </li> </ul> <p><font face="Arial" size="-1">The programming assignments will use the <em>Mathematica</em> programming environment. No prior experience with <em>Mathematica</em> is necessary.</font> </p> <dl> <dd> <font face="Arial" size="-1">Assignment due</font> <font color="#FF0000" face="Arial" size="-1">By the midnight on</font> <font face="Arial" size="-1">the day due. _**<font color="#FF0000">Late Policy</font>: Assignments turned in within 24 hours following the due date will have 15% deducted from the assignment score. Assignments turned in between 24 and 48 hours following the due date will have 30% deducted from the score. Assignments more than 48 hours late will receive a score of zero.**_</font> </dd> </dl> <hr/> <h1 id="lectures"><a name="LectureNotes"></a>Lectures<a class="headerlink" href="#lectures" title="Permanent link">¶</a></h1> <p><font face="Arial"><strong><em>Check this section before each class for recent additions and revisions.</em></strong></font></p> <p><a href="http://vision.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5036W2015/5036Syllabus.html">(5036W Course material from 2015)</a></p> <p><font face="Arial"><strong><em><span style="text-align:center"><span style="font-size:9.0pt;font-family:Arial;">Lecture notes are in <span class="SpellE">Mathematica</span> Notebook and <span class="SpellE">pdf</span> format. You can download the <span class="SpellE">Mathematica</span> notebook files below to view with <span class="SpellE">Mathematica</span> or Wolfram CDF <a href="http://www.wolfram.com/products/player/">Player</a> (which is free).</span></span><br/> </em></strong></font></p> <table align="center" border="1" name="Table of Lectures" width="79%"> <tbody> <tr> <td align="center" bordercolor="#999999" width="72"><span class="p3">[University Calendar](http://onestop.umn.edu/onestop/calendar.html)</span></td> <td align="center" width="24"><span class="p3">**Date**</span></td> <td align="center" valign="top" width="159"><span class="p3">**Lecture**</span></td> <td align="center" valign="top" width="159"><span class="p3">_**Main Readings**_</span></td> <td align="center" valign="top" width="379"><span class="p3">**Supplementary Material**</span></td> <td align="center" valign="top" width="163"><span class="p3">**Assignments due**</span></td> </tr> <tr> <td align="left" bordercolor="#999999" height="33" rowspan="4" valign="top" width="72"> <div align="center"><span class="p3">**I. Introduction**</span></div> </td> <td align="left" bgcolor="#FFFFFF" height="33" valign="top"> <div align="center"><span class="p3">Sep 6</span></div> </td> <td align="left" bgcolor="#FFFFFF" class="p3" valign="top" width="159"><span class="p3">1\. Introduction to Computational Vision</span></td> <td align="left" bgcolor="#FFFFFF" height="33" valign="top" width="159"> _[1.IntroToComputationalVision.nb](Lectures/1_MultidisciplinaryStudy/1.IntroToComputationalVision.nb) ([pdf](Lectures/1_MultidisciplinaryStudy/1.IntroToComputationalVision.nb.pdf))_ Olshausen, B. A. (2013). Perception as an Inference Problem. In M. Gazzaniga (Ed.), The New Cognitive Neurosciences, 5th Edition (pp. 1â€“22). MIT Press. (pp. 1â€“18). MIT Press. ([pdf](../../coursepapers/Olshausen2013Perception_as_an_Inference_Problem.pdf)) </td> <td align="left" bgcolor="#FFFFFF" height="33" valign="top" width="379"> Screencast: [http://www.wolfram.com/broadcast/screencasts/handsonstart/](http://www.wolfram.com/broadcast/screencasts/handsonstart/) (WITH AUDIO)[ ](Lectures/1_MultidisciplinaryStudy/FoxApertures2.mov)Check out demos under: **Life Sciences/Cognitive Science/Perception** and **Engineering &amp; Technology/Image Processing** on the Mathematica Demonstrations site: [http://demonstrations.wolfram.com/](http://demonstrations.wolfram.com/) _Kersten, D., &amp; Yuille, A. (2003). Bayesian models of object perception. Current Opinion in Neurobiology, 13(2), 1-9\. ([pdf](../../coursepapers/KerstenYuilleCurrOpinNeu2003.pdf))_ [EV: Section 1](../../papers/YuilleKerstenFinalChapter2016.pdf) </td> <td align="left" bgcolor="#FFFFFF" class="p3" height="33" valign="top" width="163"> </td> </tr> <tr bgcolor="lightgrey"> <td align="left" bgcolor="#CCCCCC" height="39" valign="top"> <div align="center"><span class="p3">Sep 11</span></div> </td> <td align="left" bgcolor="#CCCCCC" valign="top" width="159"><span class="p3">2.Limits to Vision</span></td> <td align="left" bgcolor="#CCCCCC" height="39" valign="top" width="159"><span class="p3">_[2.LimitsToVision.nb](Lectures/2_Limits to Vision/2_LimitsToVision.nb) [(pdf)](Lectures/2_Limits to Vision/2_LimitsToVision.nb.pdf)__ Hecht, S., Shlaer, S., &amp; Pirenne, M. H. (1942). Energy, quanta, and vision. Journal of General Physiology, 25, 819-840\. ([pdf](../../coursepapers/hecht+al_42.pdf))_</span></td> <td bgcolor="#CCCCCC" height="39" valign="top" width="379"> Barlow, H. B. (1981). Critical Limiting Factors in the Design of the Eye and Visual Cortex. Proc. Roy. Soc. Lond. B, 212, 1-34\. ([pdf](../../coursepapers/barlow_81.pdf)) Baylor, D. A., Lamb, T. D., &amp; Yau, K. W. (1979). Responses of retinal rods to single photons. Journal of Physiology, Lond., 288, 613-634\. ([pdf](../../coursepapers/baylor+al_79b.pdf)) Tinsley, J. N., Molodtsov, M. I., Prevedel, R., Wartmann, D., Pons, J. E. E., Lauwers, M., &amp; Vaziri, A. (2016). Direct detection of a single photon by humans. Nature Communications, 7, 1–9\. [http://doi.org/10.1038/ncomms12172](http://doi.org/10.1038/ncomms12172) ([pdf)](../../coursepapers/Tinsley16.pdf) </td> <td bgcolor="#CCCCCC" height="39" valign="top" width="163"> </td> </tr> <tr bgcolor="white"> <td align="left" bgcolor="#CCCCCC"> <div align="center"><span class="p3">Sep 13</span></div> </td> <td bgcolor="#CCCCCC" valign="top" width="159"><span class="p3">3\. The Ideal Observer</span></td> <td bgcolor="#CCCCCC" valign="top" width="159"><span class="p3">_[3.TheIdealObserver.nb](Lectures/3_TheIdealObserver/3_TheIdealObserver.nb) [(pdf)](Lectures/3_TheIdealObserver/3_TheIdealObserver.nb.pdf)_</span></td> <td bgcolor="#CCCCCC" valign="top" width="379"> [ProbabilityOverview.nb](Lectures/3_TheIdealObserver/ProbabilityOverview2017.nb) [(pdf)](Lectures/3_TheIdealObserver/ProbabilityOverview2017.nb.pdf) Griffiths, T. L., &amp; Yuille, A. (2008). A primer on probabilistic inference. In M. Oaksford and N. Chater (Eds.). The probabilistic mind: Prospects for rational models of cognition. Oxford: Oxford University Press [(pdf](../../coursepapers/GriffithsYuilleProbPrimerTICsmmc1.pdf)). Try your luck against an ideal discriminator of dot density [YesNoDotDiscriminationDemo.nb](Lectures/3_TheIdealObserver/YesNoDotDiscriminationDemo.nb) </td> <td bgcolor="#CCCCCC" valign="top" width="163"> Upload Assignment #1 to [Moodle ](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Assignment_1_Mathematica.nb](Grading, Exercises &amp; Exams/Assignments_due/Problem_Set_1.nb) </td> </tr> <tr bgcolor="white"> <td align="left" bgcolor="#FFFFFF"> <div align="center"><span class="p3">Sep 18</span></div> </td> <td bgcolor="#FFFFFF" valign="top" width="159"><span class="p3">4\. Ideal observer analysis: Humans vs. ideals. Neurons vs. ideals</span></td> <td bgcolor="#FFFFFF" valign="top" width="159"> _[4.IdealObserverAnalysis.nb](Lectures/4_Ideal Observer Analysis/4_IdealObserverAnalysis.nb)_ ([pdf](Lectures/4_Ideal Observer Analysis/4_IdealObserverAnalysis.nb.pdf)) </td> <td bgcolor="#FFFFFF" valign="top" width="379"> Kersten and Mamassian (2008), Ideal observer theory. The New Encyclopedia of Neuroscience, Squire et al., editors ([pdf](../../coursepapers/KerstenMamassian2009IdealObsTheory.pdf)). Geisler, W. S. (2011). Contributions of ideal observer theory to vision research. Vision Research, 51(7), 771–781.[(pdf)](../../coursepapers/Geisler2011Contributions_of_ideal_observer_theory_to_vision_research.pdf) Burgess, A. E., Wagner, R. F., Jennings, R. J., &amp; Barlow, H. B. (1981)_. Efficiency of human visual signal discrimination. Science, 214(4516), 93-94. [(pdf)](../../coursepapers/BurgessScience1981.pdf)_ Deneve, S., Latham, P. E., &amp; Pouget, A. (1999). Reading population codes: a neural implementation of ideal observers. Nature Neuroscience, 2(8), 740–745\. [(pdf)](../../coursepapers/Deneve1999Reading_population_codes_a_neural_implementation_of_ideal_observers.pdf) Measure your absolute efficiency to discriminate dot density using a 2AFC task [2AFCDotDiscriminationDemo.nb](Lectures/4_Ideal%20Observer%20Analysis/2AFCDotDiscriminationDemo.nb) </td> <td bgcolor="#FFFFFF" valign="top" width="163"> </td> </tr> <tr> <td bordercolor="#999999" rowspan="3" width="72"> <div align="center"><span class="p3">**II. Image formation, pattern synthesis**</span></div> </td> <td align="left" bgcolor="#FFFFFF"> <div align="center"><span class="p3">Sep 20</span></div> </td> <td bgcolor="#FFFFFF" valign="top" width="159"><span class="p3">5.Psychophysics: tools &amp; techniques</span></td> <td bgcolor="#FFFFFF" valign="top" width="159"> _[5.Psychophysics.nb](Lectures/5_PsychophysicsSKEobserver/5_Psychophysics.nb)[](Lectures/5_PsychophysicsSKEobserver/5_Psychophysics.nb) [(pdf)](Lectures/5_PsychophysicsSKEobserver/5_Psychophysics.nb.pdf) _ </td> <td bgcolor="#FFFFFF" valign="top" width="379"> [SKEDetection2AFCInLineDisplay.nb](Lectures/5_PsychophysicsSKEobserver/SKEDetection2AFCInLineDisplay.nb) Farell, B. &amp; Pelli, D. G. (1999) Psychophysical methods, or how to measure a threshold and why. In R. H. S. Carpenter &amp; J. G. Robson (Eds.), Vision Research: A Practical Guide to Laboratory Methods, New York: Oxford University ([pdf](../../coursepapers/farell1999chapter.pdf)) Press.http://psych.nyu.edu/pelli/ Morgenstern, Y., &amp; Elder, J. H. (2012). Local Visual Energy Mechanisms Revealed by Detection of Global Patterns. Journal of Neuroscience, 32(11), 3679–3696\. For a free Matlab psychophysics package, see: [http://psychotoolbox.org](http://psychtoolbox.org/) For a free Python psychophysics package, see: [http://www.psychopy.org](http://www.psychopy.org) </td> <td bgcolor="#FFFFFF" valign="top" width="163"> </td> </tr> <tr bgcolor="lightgrey"> <td align="left" bgcolor="#CCCCCC"> <div align="center"><span class="p3">Sep 25</span></div> </td> <td bgcolor="#CCCCCC" valign="top" width="159"><span class="p3">6\. Bayesian decision theory &amp; perception</span></td> <td bgcolor="#CCCCCC" valign="top" width="159"> _[6.BayesDecisionTheory.nb](Lectures/6_BayesDecisionTheory/6_BayesDecisionTheory.nb.pdf) [(pdf)](Lectures/6_BayesDecisionTheory/6_BayesDecisionTheory.nb.pdf)_ _Geisler, W. S., &amp; Kersten, D. (2002). Illusions, perception and Bayes. Nat Neurosci, 5(6), 508-510\. ([pdf](http://gandalf.psych.umn.edu/%7Ekersten/kersten-lab/papers/GeislerKerstennn0602-508.pdf))_ </td> <td bgcolor="#CCCCCC" valign="top" width="379"> [EV Section 3](../../coursepapers/YuilleKerstenFinalChapter2016.pdf#3) </td> <td bgcolor="#CCCCCC" valign="top" width="163"><span class="p3"> </span></td> </tr> <tr bgcolor="white"> <td align="left" bgcolor="#CCCCCC" height="97"> <div align="center"><span class="p3">Sep 27</span></div> </td> <td bgcolor="#CCCCCC" valign="top" width="159"><span class="p3">7\. Limits to spatial resolution, image modeling, introduction to linear systems</span></td> <td bgcolor="#CCCCCC" valign="top" width="159"> _[7.ImageModelLinearSystems.nb](Lectures/7.ImageModelingLinearSystems/7.ImageModelLinearSystems.nb) [(pdf)](Lectures/7.ImageModelingLinearSystems/7.ImageModelLinearSystems.nb.pdf)_ _Campbell, F. W., &amp; Green, D. (1965). Optical and retinal factors affecting visual resolution. Journal of Physiology (Lond.), 181, 576-593\. ([pdf](../../coursepapers/CampbellGreen_JP1965.pdf))_ </td> <td bgcolor="#CCCCCC" height="97" valign="top" width="379"> Williams, D. R. (1986). Seeing through the photoreceptor mosaic. 9(5), 193-197\. ([pdf](../../coursepapers/williams86.pdf)) [LinearAlgebraReview.nb](Lectures/7.ImageModelingLinearSystems/LinearAlgebraReview.nb) [Convolutions_Tutorial.nb](Lectures/7.ImageModelingLinearSystems/Convolutions_Tutorial.nb) [IPython convolutions notebook](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/2a.Convolution.ipynb) </td> <td bgcolor="#CCCCCC" height="97" valign="top" width="163">     Upload Assignment #2 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Problem_Set_2.nb](Grading, Exercises &amp; Exams/Assignments_due/Problem_Set_2.nb) (correction 10/4/17) </td> </tr> <tr> <td bordercolor="#999999" rowspan="5" width="72"> <div align="center"><span class="p3">**III. Early visual coding**</span></div> </td> <td align="left" bgcolor="#FFFFFF" height="52"> <div align="center"><span class="p3">Oct 2</span></div> </td> <td bgcolor="#FFFFFF" valign="top" width="159"><span class="p3">8\. Linear systems analysis</span></td> <td bgcolor="#FFFFFF" height="52" valign="top" width="159"><span class="p3">_[8.LinearSystemsOptics.nb](Lectures/8\. Spatial filters/8.LinearSystemsOptics.nb) [(pdf)](Lectures/8\. Spatial filters/8.LinearSystemsOptics.nb.pdf) _</span></td> <td bgcolor="#FFFFFF" height="52" valign="top" width="379"> [EV: Section 2](../../papers/YuilleKerstenFinalChapter2016.pdf) _[CSF.gif](Lectures/8\. Spatial filters/CSF.gif)_ Tutorials: [Fourier_neural_image.nb](Lectures/8\. Spatial filters/Fourier_neural_image.nb) </td> <td bgcolor="#FFFFFF" height="52" valign="top" width="163"> </td> </tr> <tr bgcolor="lightgrey"> <td align="left" bgcolor="#FFFFFF"> <div align="center"><span class="p3">Oct 4</span></div> </td> <td bgcolor="#FFFFFF" valign="top" width="159"><span class="p3">9\. Features and filters. Spatial filter models of early human vision</span></td> <td bgcolor="#FFFFFF" valign="top" width="159"> _[9.NeuralSpatialFiltering.nb](Lectures/9\. Multi-scale analysis/9.NeuralSpatialFiltering.nb) [(pdf)](Lectures/9\. Multi-scale analysis/9.NeuralSpatialFiltering.nb.pdf)_ </td> <td bgcolor="#FFFFFF" valign="top" width="379"> Campbell, F. W., &amp; Robson, J. R. (1968). Application of Fourier Analysis to the Visibility of Gratings. Journal of Physiology 197, 551-566\. ([pdf](../../coursepapers/CampbellRobson_JP1968.pdf)) De Valois, R. L., Albrecht, D. G., &amp; Thorell, L. G. (1982). Spatial frequency selectivity of cells in macaque visual cortex. Vision Res, 22(5), 545-559\. ([pdf](../../coursepapers/DeValoisAlbrechtThorell1982.pdf)) Watson, A. B. (1987). Efficiency of a model human image code. J Opt Soc Am A, 4(12), 2401-2417\. ([pdf)](http://vision.arc.nasa.gov/publications/Efficiency.pdf) [IPython demo of gabor filtering](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/2b.Gabor.ipynb) Steerable pyramids: [http://www.cns.nyu.edu/~eero/steerpyr/](http://www.cns.nyu.edu/%7Eeero/steerpyr/) </td> <td bgcolor="#FFFFFF" valign="top" width="163"> </td> </tr> <tr bgcolor="lightgrey"> <td align="left" bgcolor="#CCCCCC" height="68"> <div align="center"><span class="p3">Oct 9</span></div> </td> <td bgcolor="#CCCCCC" valign="top" width="159"><span class="p3">10\. Features and filters. Local processing &amp; image analysis</span></td> <td bgcolor="#CCCCCC" height="68" valign="top" width="159"><span class="p3">_[10.ImageProcessing.nb](Lectures/10.ImageManipulations/10.ImageProcessing.nb) [(pdf)](Lectures/10.ImageManipulations/10.ImageProcessing.nb.pdf)_ Gollisch, T., &amp; Meister, M. (2010). Eye Smarter than Scientists Believed: Neural Computations in Circuits of the Retina. Neuron, 65(2), 150–164\. ([pdf](../../coursepapers/Gollisch2010Eye_Smarter_than_Scientists_Believed_Neural_Computations_in_Circuits_of_the_Retina.pdf))</span></td> <td bgcolor="#CCCCCC" height="68" valign="top" width="379"><span class="p3">Albrecht, D. G., De Valois, R. L., &amp; Thorell, L. G. (1980). Visual cortical neurons: are bars or gratings the optimal stimuli? Science, 207(4426), 88-90.[(pdf)](../../coursepapers/AlbrechtDeValoisThorellScience1980.pdf) Adelson, E. H., &amp; Bergen, J. R. (1991). The plenoptic function and the elements of early vision. In M. S. Landy &amp; J. A. Movshon (Eds.), Computational Models of Visual Processing. Cambridge, MA: The MIT Press: A Bradford Book.[(pdf](../../coursepapers/AdelsonBergenPlenopticelements91.pdf)[)](../../coursepapers/adelson-bergen-85.pdf) ClassificationImage demo ([ReverseCorrelation.nb](Reverse%20correlation/ReverseCorrelation.nb)) Ahumada, A. J., Jr. (2002). Classification image weights and internal noise level estimation. J Vis, 2(1), 121-131. ([pdf)](Reverse%20correlation/Ahumada-2002-jov-2-1-8.pdf)</span></td> <td bgcolor="#CCCCCC" height="68" valign="top" width="163"> Upload Assignment 3 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Problem_Set_3.nb](Grading, Exercises &amp; Exams/Assignments_due/Problem_Set_3.nb) [](Grading,%20Exercises%20&amp;%20Exams/Assignments_due/Assignmt_2_Convolve.nb) </td> </tr> <tr bgcolor="white"> <td align="left" bgcolor="#CCCCCC"> <div align="center"><span class="p3">Oct 11</span></div> </td> <td bgcolor="#CCCCCC" valign="top" width="159"><span class="p3">11\. Coding efficiency: Retina</span></td> <td background="Lectures/11\. Efficient
            coding/11.CodingEfficiency.nb" bgcolor="#CCCCCC" valign="top" width="159"> _[11.CodingEfficiency.nb](Lectures/11\. Efficient coding/11.CodingEfficiency.nb) [(pdf)](Lectures/11\. Efficient coding/11.CodingEfficiency.nb.pdf)_ Geisler, W. S. (2008). Visual perception and the statistical properties of natural scenes. Annu Rev Psychol, 59, 167-192\. [(pdf)](../../coursepapers/Geisler2008annurev.psych.58.110405.085632.pdf) </td> <td bgcolor="#CCCCCC" valign="top" width="379"> Laughlin, S. (1981). A simple coding procedure enhances a neuron's information capacity. Z Naturforsch [C], 36(9-10), 910-912.([pdf](../../coursepapers/Laughlin1981.pdf)) Atick, J. J., &amp; Redlich, A. N. (1992). What does the retina know about natural scenes? Neural Computation, 4(2), 196–210\. Meister, M., &amp; Berry, M. J., 2nd. (1999). The neural code of the retina. Neuron, 22(3), 435-450.[(pdf](../../coursepapers/meister+berry_99.pdf)) Srinivasan, M. V., Laughlin, S. B., &amp; Dubs, A. (1982). Predictive coding: a fresh view of inhibition in the retina. Proc R Soc Lond B Biol Sci, 216(1205), 427-459.([pdf](../../coursepapers/srinivasan+al_82.pdf)) [IPython demo of natural image statistics](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/3a.Natural%20Image%20Statistics.ipynb) </td> <td bgcolor="#CCCCCC" valign="top" width="163"> </td> </tr> <tr bgcolor="white"> <td align="left" bgcolor="#FFFFFF"> <div align="center"><span class="p3">Oct 16</span></div> </td> <td bgcolor="#FFFFFF" valign="top" width="159"><span class="p3">12\. Coding efficiency: Cortex </span></td> <td bgcolor="#FFFFFF" valign="top" width="159"> _[12.SpatialCodingEfficiency.nb](Lectures/12\. Efficent coding Spatial/12.SpatialCodingEfficiency.nb) [(pdf)](Lectures/12\. Efficent coding Spatial/12.SpatialCodingEfficiency.nb.pdf)_ _Simoncelli, E. P., &amp; Olshausen, B. A. (2001). Natural image statistics and neural representation. Annu Rev Neurosci, 24, 1193-1216.[(pdf](../../coursepapers/SimoncelliOlshausenAnnRev1999.pdf))_ </td> <td bgcolor="#FFFFFF" valign="top" width="379"> [ContrastNormalizationNotes.nb](Lectures/12\. Efficent coding Spatial/ContrasNormalizationNotes.nb) Laughlin, S. B., de Ruyter van Steveninck, R. R., &amp; Anderson, J. C. (1998). The metabolic cost of neural information. Nat Neurosci, 1(1), 36-41.([pdf)](../../coursepapers/laughlin+al_98.pdf) Lennie, P. (2003). The cost of cortical computation. Curr Biol, 13(6), 493-497. [(pdf)](../../coursepapers/LennieCurBio2003.pdf) Multi-resolution, image pyramids, and efficient coding: [JepsonFleet2005pyramids_notes.pdf ](../../coursepapers/JepsonFleet2005pyramids_notes.pdf)[AdelsonPyramidRCA84.pdf](../../coursepapers/AdelsonPyramidRCA84.pdf) </td> <td bgcolor="#FFFFFF" valign="top" width="163"> </td> </tr> <tr> <td bordercolor="#999999" rowspan="11" width="72"> <div align="center"><span class="p3">**IV. Intermediate-level vision, integration, grouping**</span></div> </td> <td align="left" bgcolor="#FFFFFF" height="72"> <div align="center"><span class="p3">Oct 18</span></div> </td> <td bgcolor="#FFFFFF" valign="top" width="159"><span class="p3">13\. Edge detection</span></td> <td bgcolor="#FFFFFF" height="72" valign="top" width="159"><span class="p3">[13.EdgeDetection.nb](Lectures/13\. Edges/13.EdgeDetection.nb) [(pdf)](Lectures/13\. Edges/13.EdgeDetection.nb.pdf)</span></td> <td bgcolor="#FFFFFF" height="72" valign="top" width="379"> Hubel, D. H., &amp; Wiesel, T. N. (1977). Ferrier lecture. Functional architecture of macaque monkey visual cortex. Proc R Soc Lond B Biol Sci, 198(1130), 1-59\. [(pdf)](../../coursepapers/HubelWieselFerrier1977.pdf) [IPython demo of statistical edge detection](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/3b.Statistical%20Edge%20Detection.ipynb) </td> <td bgcolor="#FFFFFF" height="72" valign="top" width="163"> </td> </tr> <tr bgcolor="lightgrey"> <td align="left" bgcolor="#CCCCCC"> <div align="center"><span class="p3">Oct 23</span></div> </td> <td bgcolor="#CCCCCC" valign="top"><span class="p3">14. Objects and scenes from images. The visual cortical pathways and hierarchy.</span></td> <td bgcolor="#CCCCCC" height="72" valign="top"> _[14.ScenesfromImages.nb](Lectures/14.Scenes from images/14.ScenesfromImages.nb) [(pdf)](Lectures/14.Scenes from images/14.ScenesfromImages.nb.pdf)__ von der Heydt R (2003) Image parsing mechanisms of the visual cortex. In: The Visual Neurosciences (Werner JS, Chalupa LM, eds.), pp 1139-1150\. Cambridge, Mass.: MIT press.[(pdf](../../coursepapers/VonderHeydt_ImageParsing_neuroscience.pdf))_ Kersten, D. J., &amp; Yuille, A. L. (2014). Inferential Models of the Visual Cortical Hierarchy. In M. S. Gazzaniga &amp; G. R. Mangun (Eds.), The New Cognitive Neurosciences, 5th Edition (pp. 1â€“22). MIT Press. [(pdf)](http://vision.psych.umn.edu/users/kersten//kersten-lab/coursepapers/KerstenYuilleNewCogNeuro2014.pdf) </td> <td bgcolor="#CCCCCC" height="72" valign="top"><span class="p3">Zhou H, Friedman HS, von der Heydt R (2000) Coding of border ownership in monkey visual cortex. J Neuroscience 20: 6594-6611\. ([pdf](../../coursepapers/ZhouFriedmanVonDerHeydt_2000_6594.pdf))</span></td> <td bgcolor="#CCCCCC" valign="top" width="163"> </td> </tr> <tr bgcolor="white"> <td align="left" bgcolor="#CCCCCC"> <div align="center"><span class="p3">Oct 25</span></div> </td> <td bgcolor="#FFFFFF" valign="top" width="159"><span class="p3">15\. Scene-based generative models</span></td> <td bgcolor="#FFFFFF" valign="top" width="159"> _[15.SurfaceGeometryDepth.nb](Lectures/15\. Surfacegeometrydepth/15.SurfaceGeometryDepth.nb) [(pdf)](Lectures/15\. Surfacegeometrydepth/15.SurfaceGeometryDepth.nb.pdf)_ _Kersten, D., Mamassian, P., &amp; Yuille, A. (2004). Object perception as Bayesian Inference. Annual Review of Psychology, 55, 271-304\. ([pdf](../../coursepapers/KerstenMamassianYuille_2004_annurev.psych.55.090902.142005.pdf))_ </td> <td bgcolor="#FFFFFF" valign="top" width="379"></td> <td bgcolor="#FFFFFF" height="22" valign="top" width="163"></td> </tr> <tr bgcolor="white"> <td align="left" bgcolor="#FFFFFF" height="22"> <div align="center"><span class="p3">Oct 30</span></div> </td> <td bgcolor="#FFFFFF" class="p3" valign="top" width="159"><span class="p3">16\. Shape-from-X</span></td> <td bgcolor="#FFFFFF" valign="top" width="159"><span class="p3">_[16.ShapeFromX.nb](Lectures/16\. Shape-from-X/16.ShapeFromX.nb) [(pdf)](Lectures/16\. Shape-from-X/16.ShapeFromX.nb.pdf)_</span></td> <td bgcolor="#FFFFFF" height="23" valign="top" width="379"> Reflectance map: Shape from shading: Horn BKP (1986) Robot Vision. Cambridge MA: MIT Press. Ch 11 ([pdf)](../../coursepapers/ch11_Shape_from_Shading.pdf). Barron, J. T., &amp; Malik, J. (2015). Shape, Illumination, and Reflectance from Shading. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(8), 1670â€“1687. http://doi.org/10.1109/TPAMI.2014.2377712 [(pdf)](../../coursepapers/BarronMalik2015IEEE_Transactions_on_Pattern_Analysis_and_Machine_Intelligence.pdf) Belhumeur, P. N., Kriegman, D. J., &amp; Yuille, A. (1997). The Bas-Relief Ambiguity. ([pdf](https://pdfs.semanticscholar.org/71ac/0dc7634e4a56fd41dfac270ec5883fcbb44f.pdf)) Johnson, M. K., &amp; Adelson, E. H. (2011). Shape Estimation in Natural Illumination. Computer Vision and Pattern Recognition (CVPR), 2553–2560. Muryy, A. A., Welchman, A. E., Blake, A., &amp; Fleming, R. W. (2013). Specular reflections and the estimation of shape from binocular disparity. Proceedings of the National Academy of Sciences of the United States of America, 110(6), 2413–2418\. [(link](http://www.pnas.org/content/110/6/2413.short)) [cube.mov](../../coursepapers/cube.mp4) [random.mov](../../coursepapers/random.mp4) </td> <td bgcolor="#FFFFFF" height="23" valign="top" width="163"><span class="p3"> </span> Upload Assignment #4 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Problem_Set_4.nb ](Grading, Exercises &amp; Exams/Assignments_due/Problem_Set_4.nb)[(pdf)](Grading, Exercises &amp; Exams/Assignments_due/Problem_Set_4.nb.pdf) [bluradaptationdemo](../../coursepapers/WebsterGeorgeBlurAdnn906-S1.mp4) [(Webster et al. pdf)](../../coursepapers/WebsterGeorgesonBlurAdaptationnn906.pdf) [motion-induced-blindness demo](../../coursepapers/BasicBonnehYellowDisksBlueDots.gif) [(Bonneh et al. pdf)](../../coursepapers/BonnehCoopemanSagiNature2001411798.pdf) <span class="p3"> </span></td> </tr> <tr bgcolor="lightgrey"> <td align="left" bgcolor="#FFFFFF" height="23"> <div align="center"><span class="p3">Nov 1</span></div> </td> <td bgcolor="#CCCCCC" class="p3" valign="top" width="159"> 17\. Shape from shading <span style='font-size:9.0pt;font-family:Arial;"Times New
                Roman"'>Overview of python/ipython for computational vision</span>[ ](https://wakari.io/sharing/bundle/kersten/Lect_19Intro_Python) </td> <td bgcolor="#CCCCCC" height="38" valign="top" width="159"> _[17. Shape from shading.nb](Lectures/17.Shape from shading/17.ShapeFromShading.nb)_ [(pdf)](Lectures/17.Shape from shading/17.ShapeFromShading.nb.pdf) [Lect_17Intro_Python.ipynb](Lectures/17_PythonForVision/Lect_17Intro_Python.ipynb) (source) ([pdf](Lectures/17_PythonForVision/Lect_17Intro_Python.pdf)) <span class="p3">_[17\. IPython notebook](http://nbviewer.jupyter.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2017/Lectures/17_PythonForVision/Lect_17Intro_Python.ipynb)_</span> [Demos](Lectures/17_PythonForVision/Demos/index.html) <span class="p3">by Weichao Qiu and Dan Kersten, supplement to _**Early Vision**._ Yuille and Kersten. A chapter in _From Neuron to Cognition via Computational Neuroscience_, M.A. Arbib, James J. Bonaiuto Editors, Cambridge MA: The MIT Press, in 2016</span> </td> <td bgcolor="#CCCCCC" height="38" valign="top" width="379"> [Anaconda](https://store.continuum.io/cshop/anaconda/) python installation recommended. We will use [Juypter/IPython](http://ipython.org), a browser-based notebook interface for python. See [here](http://nbviewer.ipython.org/github/ipython/ipython/blob/1.x/examples/notebooks/Part%205%20-%20Rich%20Display%20System.ipynb) for illustrations of IPython cell types, and [here](https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks) for a collection of sample notebooks. Look [here](http://iacs-courses.seas.harvard.edu/courses/am207/blog/installing-python.html) for some good tips on installation, as well as the parent directory for excellent ipython-based course material on scientific computing using Monte Carlo methods. For a quick start to scientific programming, see: [http://nbviewer.ipython.org/gist/rpmuller/5920182](http://nbviewer.ipython.org/gist/rpmuller/5920182) For a comphrensive coverage of scientific python see[:https://scipy-lectures.github.io](https://scipy-lectures.github.io) And for a ground-up set of tutorials on python see: [http://learnpythonthehardway.org/book/](http://learnpythonthehardway.org/book/) Switching from matlab to python? [http://wiki.scipy.org/NumPy_for_Matlab_User](http://mathesaurus.sourceforge.net/matlab-numpy.html) [ProjectIdeasF2015.nb](Grading,%20Exercises%20&amp;%20Exams/FinalProjectIdeasF2015.nb) [(pdf)](Grading,%20Exercises%20&amp;%20Exams/FinalProjectIdeasF2015.nb.pdf) </td> <td bgcolor="#CCCCCC" height="38" valign="top" width="163"></td> </tr> <tr bgcolor="lightgrey"> <td align="left" bgcolor="#CCCCCC" height="38"> <div align="center"><span class="p3">Nov 6</span></div> </td> <td bgcolor="#CCCCCC" class="p3" valign="top" width="159"><span class="p3">18\. Motion: optic flow</span></td> <td bgcolor="#CCCCCC" height="38" valign="top" width="159"> _[18.MotionOpticFlow.nb](Lectures/18.MotionOpticFlow/18.MotionOpticFlow.nb) [(pdf)](Lectures/18.MotionOpticFlow/18.MotionOpticFlow.nb.pdf)_ _OpenCV python demo:_ [OpticFlowSparse.ipynb](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/Lectures/18.MotionOpticFlow/OpticFlowSparse.ipynb) needs: [648aa10.avi](Lectures/17_PythonForVision/648aa10.avi) </td> <td bgcolor="#CCCCCC" height="38" valign="top" width="379"> Horn, B. K. P., &amp; Schunck, B. G. (1981). Determining Optical Flow. Artificial Intelligence, 17, 185-203\. ([pdf](../../coursepapers/Optical_Flow_OPT.pdf)) Optic Flow (2013) Florian Raudies, Scholarpedia, 8(7):30724\. doi:10.4249/scholarpedia.30724 ([link](http://www.scholarpedia.org/article/Optic_flow)) (with available matlab code) Optic flow matlab code from Michael Black's lab. ([link](http://cs.brown.edu/people/black/code.html)) Borst, A. (2007). Correlation versus gradient type motion detectors: the pros and cons. Philos Trans R Soc Lond B Biol Sci, 362(1479), 369-374\. [pdf](../../coursepapers/Borst2007rstb20061964.pdf)) [http://web.mit.edu/persci/people/adelson/illusions_demos.html](http://web.mit.edu/persci/people/adelson/illusions_demos.html) [IPython aperture demo](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/Lectures/17_PythonForVision/Aperture%20demo.ipynb) EV: Section 2.4 FV: Chapter 10 </td> <td bgcolor="#CCCCCC" valign="top" width="163"></td> </tr> <tr bgcolor="white"> <td align="left" bgcolor="#CCCCCC"> <div align="center"><span class="p3">Nov 8</span></div> </td> <td bgcolor="#FFFFFF" class="p3" valign="top" width="159"><span class="p3">19\. Motion: biological, human perception</span></td> <td background="Lectures/19.MotionIllusionsBayes/19.MotionHumanPerception.nb" bgcolor="#FFFFFF" valign="top" width="159"> _[19.MotionHumanPerception.nb](Lectures/19.MotionIllusionsBayes/19.MotionHumanPerception.nb) [(pdf)](Lectures/19.MotionIllusionsBayes/19.MotionHumanPerception.nb.pdf)_ _Weiss, Y., Simoncelli, E. P., &amp; Adelson, E. H. (2002). Motion illusions as optimal percepts. Nat Neurosci, 5(6), 598-604. ([pdf](../../coursepapers/WeissSimonAdelNatNeu2002.pdf))_ </td> <td background="Lectures/18.MotionOpticFlow/aperturedemomovie.mov" bgcolor="#FFFFFF" valign="top" width="379"> Heeger, D. J., Simoncelli, E. P., &amp; Movshon, J. A. (1996). Computational models of cortical visual processing. Proc Natl Acad Sci U S A, 93(2), 623-627\. ([pdf](../../coursepapers/Heeger96-reprint%20PNAS.pdf)) [http://demonstrations.wolfram.com/DisappearingDotIllusion/](http://demonstrations.wolfram.com/DisappearingDotIllusion/) [http://www.biomotionlab.ca/Demos/BMLwalker.html](http://www.biomotionlab.ca/Demos/BMLwalker.html) EV: Section 4.4 FV: Chapter 10 </td> <td bgcolor="#FFFFFF" valign="top" width="163"> </td> </tr> <tr bgcolor="white"> <td align="left" bgcolor="#FFFFFF"> <div align="center"><span class="p3">Nov 13</span></div> </td> <td bgcolor="#FFFFFF" class="p3" valign="top" width="159"><span class="p3">20\. Material perception</span></td> <td bgcolor="#FFFFFF" valign="top" width="159"> _[20.SurfaceMaterial.nb](Lectures/20\. Surface material/20.SurfaceMaterial.nb) [(pdf)](Lectures/20\. Surface material/20.SurfaceMaterial.nb.pdf)_ V1 and lightness ([pdf](Lectures/20.%20Surface%20material/V1Lightness.pdf)) Doerschner, K., Fleming, R. W., Yilmaz, O., Schrater, P. R., Hartung, B., &amp; Kersten, D. (2011). Visual motion and the perception of surface material. Current Biology, 21(23), 2010–2016\. ([pdf](../../coursepapers/Doerschner2011Doerschner2011CURRENT-BIOLOGY-S-11-00953-3.pdf)) </td> <td bgcolor="#FFFFFF" valign="top" width="379"><span class="p3">Fleming, R. W., Dror, R. O., &amp; Adelson, E. H. (2003). Real-world illumination and the perception of surface reflectance properties. J Vis, 3(5), 347-368\. [(link](http://journalofvision.org/3/5/3/)) _Adelson, E. H. (1993). Perceptual organization and the judgment of brightness. Science, 262, 2042-2044 ([pdf](../../coursepapers/AdelsonScience1993.pdf))_ Boyaci, H., Fang, F., Murray, S. O., &amp; Kersten, D. (2007). Responses to lightness variations in early human visual cortex. Curr Biol, 17(11), 989-993 ([pdf](../../coursepapers/BoyaciCurrBiol2007.pdf))_[http://www.bilkent.edu.tr/~hboyaci/Vision/](http://www.bilkent.edu.tr/%7Ehboyaci/Vision/)_ [http://web.mit.edu/persci/people/adelson/checkershadow_illusion.html](http://web.mit.edu/persci/people/adelson/checkershadow_illusion.html) [http://gandalf.psych.umn.edu/users/kersten/kersten-lab/demos/transparency.html](http://gandalf.psych.umn.edu/users/kersten/kersten-lab/demos/transparency.html) [http://gandalf.psych.umn.edu/~kersten/kersten-lab/demos/MatteOrShiny.html](http://gandalf.psych.umn.edu/%7Ekersten/kersten-lab/demos/MatteOrShiny.html)</span></td> <td bgcolor="#EDEDED" valign="top" width="163"> Upload Assignment 5 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [texture_classification_plot_gabor.ipynb](Grading, Exercises &amp; Exams/Assignments_due/texture_classification_plot_gabor.ipynb) [(view)](http://nbviewer.jupyter.org/url/vision.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5036W2017/Grading, Exercises &amp; Exams/Assignments_due/texture_classification_plot_gabor.ipynb) Upload Final project title &amp; paragraph outline to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) </td> </tr> <tr bgcolor="lightgrey"> <td align="left" bgcolor="#FFFFFF"> <div align="center"><span class="p3">Nov 15</span></div> </td> <td bgcolor="#CCCCCC" class="p3" valign="top" width="159"><span class="p3">21\. Texture.</span></td> <td bgcolor="#CCCCCC" valign="top" width="159"> _[21.Texture.nb](Lectures/21\. Texture/21.Texture.nb) [(pdf)](Lectures/21\. Texture/21.Texture.nb.pdf)_ Freeman, J., &amp; Simoncelli, E. P. (2011). Metamers of the ventral stream. Nature Publishing Group, 14(9), 1195-1201\. http://doi.org/10.1038/nn.2889 ([pdf](../../coursepapers/Freeman2011Metamers_of_the_ventral_stream.pdf)) </td> <td bgcolor="#CCCCCC" valign="top" width="379"> Heeger DJ and Bergen JR, Pyramid Based Texture Analysis/Synthesis, Computer Graphics Proceedings, p. 229-238, 1995\. ([pdf)](../../coursepapers/heeger-siggraph95.pdf). [EfrosTextureSynthesis.ipynb](Lectures/21\. Texture/EfrosTextureSynthesis.ipynb) From: [https://github.com/rbaravalle/efros](https://github.com/rbaravalle/efros) [img2.png](Lectures/21\. Texture/img2.png) A sample: [out2.png](Lectures/21\. Texture/out2.png) </td> <td bgcolor="#CCCCCC" valign="top"> </td> </tr> <tr> <td align="left" bgcolor="#CCCCCC"> <div align="center"><span class="p3">Nov 20</span></div> </td> <td align="center" bgcolor="#CCCCCC" class="p3" valign="top"><span class="p3">22.Science writing (Thanksgiving week)</span></td> <td bgcolor="#CCCCCC" valign="top"><span class="p3">_[22.ScienceWriting.nb](Lectures/22\. Science Writing/22.ScienceWriting.nb) [(pdf)](Lectures/22\. Science Writing/22.ScienceWriting.nb.pdf)_</span></td> <td bgcolor="#CCCCCC" valign="top"> Gopen &amp; Swan, 1990. [UM Psychology](http://writing.psych.umn.edu/student-resources) [Denis <span class="SpellE">Pelli's</span> advice for scientific writing](http://psych.nyu.edu/pelli/style.html) </td> <td bgcolor="#CCCCCC" valign="top" width="163"> </td> </tr> <tr> <td align="left" bgcolor="#CCCCCC"> <div align="center"><span class="p3">Nov 22 </span></div> </td> <td bgcolor="#FFFFFF" class="p3" valign="top"><span class="p3">23.Perceptual integration</span></td> <td bgcolor="#FFFFFF" valign="top"><span class="p3">_[23.PerceptualIntegration.nb](Lectures/23.PerceptualIntegration/23.PerceptualIntegration.nb) [(pdf)](Lectures/23.PerceptualIntegration/23.PerceptualIntegration.nb.pdf) _</span></td> <td bgcolor="#FFFFFF" valign="top"> McDermott, J., Weiss, Y., &amp; Adelson, E. H. (2001). Beyond junctions: nonlocal form constraints on motion interpretation. Perception, 30(8), 905-923\. ([pdf](../../coursepapers/McDermottbeyond_junctions.pdf)) [http://www.perceptionweb.com/perception/perc0801/square.html](http://www.perceptionweb.com/perception/perc0801/square.html) Hillis, J. M., Ernst, M. O., Banks, M. S., &amp; Landy, M. S. (2002). Combining sensory information: mandatory fusion within, but not between, senses. Science, 298(5598), 1627-1630.([pdf](../../coursepapers/HillisErnstBanksLandyscience02.pdf)) Ernst, M. O., &amp; Banks, M. S. (2002). Humans integrate visual and haptic information in a statistically optimal fashion. Nature, 415(6870), 429-433\. ([pdf](../../coursepapers/ErnstBanks2002.pdf)) Stocker, A. A., &amp; Simoncelli, E. (2008). A Bayesian model of conditioned perception. Advances in Neural Information Processing Systems, 20, 1409-1416\. ([pdf](http://papers.nips.cc/paper/3369-a-bayesian-model-of-conditioned-perception.pdf)) [IPython demo of ideal integration](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/5.Cue%20Combination.ipynb) EV: Section 5 </td> <td bgcolor="#FFFFFF" valign="top"> </td> </tr> <tr bgcolor="lightgrey"> <td bgcolor="white" bordercolor="#999999" rowspan="4" width="72"> <div align="center"><span class="p3">**V. High-level vision**</span></div> </td> <td align="left" bgcolor="#FFFFFF"> <div align="center"><span class="p3">Nov 27</span></div> </td> <td bgcolor="#FFFFFF" class="p3" valign="top"><span class="p3">24. Object recognition I</span></td> <td bgcolor="#FFFFFF" valign="top"> _[24.ObjectRecognition.nb](Lectures/24\. ObjectRecognition_I/24.ObjectRecognition.nb) [(pdf)](Lectures/24\. ObjectRecognition_I/24.ObjectRecognition.nb.pdf)_ _DiCarlo, J. J., Zoccolan, D., &amp; Rust, N. C. (2012). How does the brain solve visual object recognition? Neuron, 73(3), 415–434\._ ([pdf](../../coursepapers/DiCarlo2012How_does_the_brain_solve_visual_object_recognition-2.pdf)) </td> <td bgcolor="#FFFFFF" valign="top" width="379"> Liu, Z., Knill, D. C., &amp; Kersten, D. (1995). Object Classification for Human and Ideal Observers. Vision Research, 35(4), 549-568\. ([pdf)](../../papers/LiuKnillKersten95.pdf) Tjan, B., Braje, W., Legge, G. E., &amp; Kersten, D. (1995). Human efficiency for recognizing 3-D objects in luminance noise. Vision Research, 35(21), 3053-3069\. ([pdf](../../coursepapers/Tjan1995.pdf)) Tanaka K (2003) Columns for complex visual object features in the inferotemporal cortex: clustering of cells with similar but slightly different stimulus selectivities. Cerebral cortex 13:90-99.([pdf](../../coursepapers/Tanaka2003.pdf)) Serre, T., Oliva, A., &amp; Poggio, T. (2007). A feedforward architecture accounts for rapid categorization. Proc Natl Acad Sci U S A, 104(15), 6424-6429\. ([pdf](../../coursepapers/SerreOlivaPoggioPNAS2007.pdf)) Yamins, D. L. K., Hong, H., Cadieu, C. F., Solomon, E. A., Seibert, D., &amp; DiCarlo, J. J. (2014). Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proceedings of the National Academy of Sciences of the United States of America, 111(23), 8619-8624\. ([pdf](http://www.pnas.org/content/111/23/8619.full.pdf)) </td> <td bgcolor="#FFFFFF" valign="top" width="163"></td> </tr> <tr bgcolor="lightgrey"> <td align="left" bgcolor="#FFFFFF"> <div align="center"><span class="p3">Nov 29</span></div> </td> <td bgcolor="#CCCCCC" class="p3" valign="top" width="159"><span class="p3">25\. Object recognition II feeforward architectures</span></td> <td bgcolor="#CCCCCC" valign="top" width="159"><span class="p3">_25_Bidirectional_I.key.pdf ([pdf](Lectures/25\. ObjectRecognition_II/25_Bidirectional_I.pdf)) __ Ullman, S., Vidal-Naquet, M., &amp; Sali, E. (2002). Visual features of intermediate complexity and their use in classification. Nat Neurosci, 5(7), 682-687\. ([pdf](../../coursepapers/UllmanNatureNeuro2002.pdf)) _</span></td> <td bgcolor="#CCCCCC" valign="top" width="379"> Grill-Spector, K. (2003). The neural basis of object perception. Curr Opin Neurobiol, 13(2), 159-166.([pdf](../../coursepapers/GrillSpector_CurrOpinNeuroB2003.pdf)) Rao, R. P., &amp; Ballard, D. H. (1999). Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat Neurosci, 2(1), 79-87\. ([pdf](../../coursepapers/RaoBallard99.pdf)) Bullier, J. (2001). Integrated model of visual processing. Brain Res Brain Res Rev, 36(2-3), 96-107\. ([pdf](../../coursepapers/bullier2001.pdf)) Tenenbaum JB: Bayesian modeling of human concept learning. In Advances in Neural Information Processing Systems. Edited by Kearns MSS, Solla A, Cohn DA: Cambridge, MA: MIT Press: 1999.([pdf)](../../coursepapers/JoshTenenbaumbayes.pdf) </td> <td bgcolor="#CCCCCC" valign="top" width="163"> Upload Assignment 6 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Problem_Set_6 .nb](Grading, Exercises &amp; Exams/Assignments_due/Problem_Set_6.nb) </td> </tr> <tr bgcolor="lightgrey"> <td align="left" bgcolor="#CCCCCC"> <div align="center"><span class="p3">Dec 4 </span></div> </td> <td bgcolor="#CCCCCC" class="p3" valign="top" width="159">26. Object recognition III feedback architectures</td> <td bgcolor="#CCCCCC" valign="top" width="159"> _26_BidirectionalFeedback.key.pdf_ [(pdf](Lectures/26\. ObjectRecognition_III/26_BidirectionalFeedback.pdf)) </td> <td bgcolor="#CCCCCC" valign="top" width="379"> Torralba, A., Oliva, A., Castelhano, M. S., &amp; Henderson, J. M. (2006). Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search. Psychol Rev, 113(4), 766-786\. [(pdf](../../coursepapers/Torralba-etal-PsychRev-06.pdf)) Chikkerur, S., Serre, T., Tan, C., &amp; Poggio, T. (2010). What and where: A Bayesian inference theory of attention. Vision Research, 50(22), 2233–2247. </td> <td bgcolor="#CCCCCC" valign="top" width="163"> </td> </tr> <tr bgcolor="white"> <td align="left" bgcolor="#CCCCCC"> <div align="center"><span class="p3">Dec 6</span></div> </td> <td bgcolor="#FFFFFF" class="p3" valign="top"> 27. Empirical evidence for bidirectional computations </td> <td bgcolor="#FFFFFF" valign="top"> 27.EmpiricalEvidenceBidirectionalProcessing([pdf](Lectures/27\. EmpiricalEvidenceBidirectionalProcessing/27\. EmpiricalEvidenceBidirectionalProcessing.pdf)) </td> <td bgcolor="#FFFFFF" valign="top"> Longuet-Higgins, H. C., &amp; Prazdny, K. (1980). The Interpretation of a Moving Retinal Image. Proceedings of the Royal Society of London B, 208, 385-397\. ([pdf](../../coursepapers/LonguetHigginsPrazdnyProcRoySoc1980.pdf)) Horn BKP (1986) Robot Vision. Cambridge MA: MIT Press., chapter 17 ([pdf](../../coursepapers/Hornch17_Structure_From_Motion.pdf)) Schrater PR, Kersten D (2000) How optimal depth cue integration depends on the task. International Journal of Computer Vision 40:73-91\. ([pdf](../../coursepapers/SchraterKerstenIJCV2000.pdf)) </td> <td bgcolor="#FFFFFF" valign="top"><span class="p3">Upload a complete DRAFT of FINAL PROJECT to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) by _**Wednesday December** __**6th, 5 PM.**_</span></td> </tr> <tr> <td bordercolor="#999999" rowspan="3" width="72"> </td> <td align="left" bgcolor="#FFFFFF"> <div align="center"><span class="p3">Dec 11</span></div> </td> <td bgcolor="#FFFFFF" class="p3" valign="top">28\. Vision for action, spatial layout, heading. Homegeneous coordinates.</td> <td bgcolor="#FFFFFF" valign="top"> _[28.SpatialLayoutScenes.nb](Lectures/28\. SpatialLayoutScenes/28.SpatialLayoutScenes.nb) [(pdf](Lectures/28\. SpatialLayoutScenes/28.SpatialLayoutScenes.nb.pdf))_ _Kalman filter notes ([pdf](http://vision.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/Lectures/27\. SpatialLayoutScenes/kalman.pdf))_ </td> <td bgcolor="#FFFFFF" valign="top"> </td> <td bgcolor="#FFFFFF" valign="top"><span class="p3">Upload your peer comments to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) by Monday Dec 11th</span></td> </tr> <tr> <td align="left" bgcolor="#FFFFFF"> <div align="center"><span class="p3">Dec 13</span></div> <span class="p3">(Last day of class) </span></td> <td bgcolor="#FFFFFF" class="p3" valign="top" width="159"> </td> <td bgcolor="#FFFFFF" valign="top" width="159"><span class="p3">_In Class Project Presentations_</span></td> <td bgcolor="#FFFFFF" valign="top" width="379"> </td> <td bgcolor="#FFFFFF" valign="top" width="163"> Drafts returned to you with Instructor comments </td> </tr> <tr> <td align="left" bgcolor="#CCCCCC"> <div align="center"><span class="p3">Dec 21</span></div> </td> <td bgcolor="#CCCCCC" class="p3" valign="top"> </td> <td bgcolor="#CCCCCC" valign="top"> </td> <td bgcolor="#CCCCCC" valign="top"> </td> <td bgcolor="#CCCCCC" valign="top"><span class="p3" id="R">Upload Final Revised Draft of Project to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100)</span></td> </tr> </tbody> </table> <hr/> <p><font face="Arial"><a name="FinalProject"></a><strong>Final Project Assignment</strong>.</font></p> <p><font face="Arial"></font></p> <p><font face="Arial">Goal: This course integrates the behavioral, neural and computational principles of perception. Students often find the interdisciplinary integration to be the most challenging aspect of the course. Through writing, you will learn to synthesize results from diverse and typically isolated disciplines. By writing about your project work, you will learn to think through the broader implications of your project, and to effectively communicate the rationale and results of your contribution in words. You will do a final page research report in which you will describe, in the form of a scientific paper, the results of an original computer program on a topic in computational vision.</font></p> <p><font face="Arial"></font></p> <p><font face="Arial">Your final project will involve: 1) a computer program and; 2) a 2000-3000 word final paper describing your project. For your computer project, you will do one of the following: 1) Write a program to simulate a model from the computer vision literature ; 2) Design and program a method for solving some problem in perception. 3) Design and program a psychophysical experiment to study an aspect of human visual perception. The results of your final project should be written up in the form of a short scientific paper or Mathematica Notebook, describing the motivation, methods, results, and interpretation.</font></p> <p></p> <p>If you choose to write your program in Mathematica, your paper and program can be combined can be formated as a Mathematica notebook. See: <a href="http://www.wolfram.com/solutions/publishing/tutorials.html">Books and Tutorials on Notebooks.</a> If you do your final project using Python, you can turn your paper in as a <a href="https://jupyter.org">Jupyter</a> notebook.</p> <p><font face="Arial"><font face="Arial"><font face="Arial"></font></font></font></p> <p><font face="Arial">Your paper will be critiqued and returned for you to revise and resubmit in final form. You should write for an audience consisting of your class peers.</font></p> <p><font face="Arial"></font></p> <p>Completing the final paper involves 4 steps. Each step requires that you email a document to the teaching assistant.</p> <ol> <li> <p><strong>Outline</strong> <strong>(2% of grade)**</strong>.** You will submit a working title and paragraph outline by the deadline noted in the syllabus. These outlines will be critiqued in order to help you find an appropriate focus for your papers. (Consult with the instructor or TA for ideas well ahead of time).</p> </li> <li> <p><strong>Complete draft (5% of grade).</strong> A double-spaced, complete draft of the paper must be turned in by the deadline noted in the syllabus. Papers should be between <strong>2000</strong> and <strong>3000</strong> words. In addition to the title, author and date lines, papers must include the following sections: Abstract, Introduction, Methods, Results, Discussion, and Bibliography. Use citations to motivate your problem and to justify your claims. Cite authors by name and date, e.g. (Marr &amp; Poggio, 1979). <em>Citations should be original sources, not wikipedia.</em> Use a standard citation format, such as APA. (The UM library has information on <a href="http://www.lib.umn.edu/libdata/page_print.phtml?page_id=791">style guides</a>, and in particular <a href="http://tutorial.lib.umn.edu/infomachine4051.html">APA style</a>.) Papers must be typed, with a page number on each page. Figures should be numbered and have figure captions. This draft will be reviewed by your instructor and one of you class peers. <strong>The point break down for the total 5% is: 2 pts for completing Introduction, 2 pts for completing Methods, 1 pt for completing Discussion)</strong></p> </li> <li> <p><strong>Peer commentary (5% of grade)</strong>. You will submit a written commentary <strong>(200</strong> to <strong>500</strong> words) on a complete draft of one of your class peers. The project drafts and commentaries will be anonymous. The commentary should provide feedback to improve the quality and clarity of the writing.</p> </li> <li> <p><strong>Final draft (20% of grade) and "Cover letter" (8% of grade).</strong> The final draft must be turned in by the date noted on the syllabus. The "Cover letter" should describe how your revision addressed comments from your peer evaluator and from your instructor. It should itemize key criticisms together with a brief description of the changes you made to your draft manuscript.</p> </li> <li> <p><strong>Some Resources:</strong></p> </li> <li> <p>Student Writing Support: Center for Writing, 306b Lind Hall and satellite locations (612.625.1893) <a href="http://writing.umn.edu">http://writing.umn.edu</a>. </p> <p><em>NOTE: Plagiarism, a form of scholastic dishonesty and a disciplinary offense, is described by the Regents as follows: Scholastic dishonesty means plagiarizing; cheating on assignments or examinations; engaging in unauthorized collaboration on academic work; taking, acquiring, or using test materials without faculty permission; submitting false or incomplete records of academic achievement; acting alone or in cooperation with another to falsify records or to obtain dishonestly grades, honors, awards, or professional endorsement; altering, forging, or misusing a University academic record; or fabricating or falsifying data, research procedures, or data analysis. <a href="http://www1.umn.edu/regents/policies/academic/Code_of_Conduct.html">http://www1.umn.edu/regents/policies/academic/Code_of_Conduct.html.</a> See too: <a href="http://writing.umn.edu/tww/plagiarism/">http://writing.umn.edu/tww/plagiarism/</a> and</em><a href="http://writing.umn.edu/tww/plagiarism/definitions.html">http://writing.umn.edu/tww/plagiarism/definitions.html</a></p> </li> </ol> <p></p><font size="-1"><a href="http://privacy.umn.edu/">Privacy Statement</a></font>     <footer class="md-footer"> <div class="md-footer-nav"> <nav class="md-footer-nav__inner md-grid"> <a class="md-flex md-footer-nav__link md-footer-nav__link--prev" href="../PSY8036SP2018/" rel="prev" title="PSY8036SP2018"> <div class="md-flex__cell md-flex__cell--shrink"> <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i> </div> <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"> <span class="md-flex__ellipsis"> <span class="md-footer-nav__direction"> Previous </span> PSY8036SP2018 </span> </div> </a> <a class="md-flex md-footer-nav__link md-footer-nav__link--next" href="../../demos/lightness-shape/" rel="next" title="Lightness and Shape"> <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"> <span class="md-flex__ellipsis"> <span class="md-footer-nav__direction"> Next </span> Lightness and Shape </span> </div> <div class="md-flex__cell md-flex__cell--shrink"> <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class="md-footer-copyright"> <div class="md-footer-copyright__highlight"> © 2020 Regents of the University of Minnesota. All rights reserved. The University of Minnesota is an equal opportunity educator and employer. <br/> <a href="http://privacy.umn.edu">Privacy Statement</a> </div> </div> <div class="md-footer-social"> <link href="../../assets/fonts/font-awesome.css" rel="stylesheet"/> <a class="md-footer-social__link fa fa-google" href="https://scholar.google.com/citations?user=6j1ZjJsAAAAJ&amp;hl=en&amp;oi=ao" rel="noopener" target="_blank" title="google"></a> <a class="md-footer-social__link fa fa-github" href="https://github.com/kerstenlab" rel="noopener" target="_blank" title="github"></a> </div> </div> </div> </footer>  <script src="../../assets/javascripts/application.21234377.js"></script> <script>app.initialize({version:"1.1",url:{base:"../.."}})</script> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>  