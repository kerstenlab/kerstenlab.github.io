<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=description content="The Computational Vision Lab combines computational theory with behavioral and brain image experiments to understand how we see the world around us."><link href=https://kerstenlab.github.io/courses/PSY8036SP2018/ rel=canonical><meta name=author content="Daniel Kersten"><meta name=lang:clipboard.copy content="Copy to clipboard"><meta name=lang:clipboard.copied content="Copied to clipboard"><meta name=lang:search.language content=en><meta name=lang:search.pipeline.stopwords content=True><meta name=lang:search.pipeline.trimmer content=True><meta name=lang:search.result.none content="No matching documents"><meta name=lang:search.result.one content="1 matching document"><meta name=lang:search.result.other content="# matching documents"><meta name=lang:search.tokenizer content=[\s\-]+><link rel="shortcut icon" href=../../assets/images/favicon.ico><meta name=generator content="mkdocs-1.1, mkdocs-material-4.6.3"><title>PSY8036SP2018 - Computational Vision Lab</title><link rel=stylesheet href=../../assets/stylesheets/application.31be5035.css><link rel=stylesheet href=../../assets/stylesheets/application-palette.1456e982.css><meta name=theme-color content><script src=../../assets/javascripts/modernizr.eca31fed.js></script><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>body,input{font-family:"Open Sans","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style><link rel=stylesheet href=../../assets/fonts/material-icons.css></head> <body dir=ltr data-md-color-primary=umn-maroon data-md-color-accent=umn-gold> <svg class=md-svg> <defs> </defs> </svg> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay data-md-component=overlay for=__drawer></label> <a href=#data-driven-generative-models-for-perception-dreaming-and-imagining tabindex=0 class=md-skip> Skip to content </a> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid"> <div class=md-flex> <div class="md-flex__cell md-flex__cell--shrink"> <a href=https://kerstenlab.github.io/ title="Computational Vision Lab" aria-label="Computational Vision Lab" class="md-header-nav__button md-logo"> <img alt=logo src=../../assets/images/D2D-gld-wht.svg height=32> </a> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--menu md-header-nav__button" for=__drawer></label> </div> <div class="md-flex__cell md-flex__cell--stretch"> <div class="md-flex__ellipsis md-header-nav__title" data-md-component=title> <span class=md-header-nav__topic> Computational Vision Lab </span> <span class=md-header-nav__topic> PSY8036SP2018 </span> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--search md-header-nav__button" for=__search></label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input aria-label=search name=query placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=query data-md-state=active> <label class="md-icon md-search__icon" for=__search></label> <button type=reset class="md-icon md-search__icon" data-md-component=reset tabindex=-1> &#xE5CD; </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=result> <div class=md-search-result__meta> Type to start searching </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> </div> </div> </nav> </header> <div class=md-container> <main class=md-main role=main> <div class="md-main__inner md-grid" data-md-component=container> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" data-md-level=0> <label class="md-nav__title md-nav__title--site" for=__drawer> <a href=https://kerstenlab.github.io/ title="Computational Vision Lab" class="md-nav__button md-logo"> <img alt=logo src=../../assets/images/D2D-gld-wht.svg width=48 height=48> </a> Computational Vision Lab </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. title=Home class=md-nav__link> Home </a> </li> <li class=md-nav__item> <a href=../../publications/ title=Publications class=md-nav__link> Publications </a> </li> <li class=md-nav__item> <a href=../ title=Courses class=md-nav__link> Courses </a> </li> <li class=md-nav__item> <a href=../../demos/ title=Demos class=md-nav__link> Demos </a> </li> <li class=md-nav__item> <a href=../../datasets/ title=Datasets class=md-nav__link> Datasets </a> </li> <li class=md-nav__item> <a href=../../people/ title=People class=md-nav__link> People </a> </li> <li class=md-nav__item> <a href=../../contact/ title="Contact information" class=md-nav__link> Contact information </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary"> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <h3 id=data-driven-generative-models-for-perception-dreaming-and-imagining>Data-driven generative models for perception, dreaming, and imagining<a class=headerlink href=#data-driven-generative-models-for-perception-dreaming-and-imagining title="Permanent link">&para;</a></h3> <p>University of Minnesota, Spring Semester, 2018</p> <h3 id=topics-in-computational-vision>**Topics in Computational Vision<a class=headerlink href=#topics-in-computational-vision title="Permanent link">&para;</a></h3> <p>**Psy 8036 (Kersten)<br> Psy 5993 Section 034 (Schrater) </p> <p><font size=-1><a href=http://courses.kersten.org>http://courses.kersten.org</a></font></p> <h3 id=httpsay17moodleumneducourseviewphpid8619section-11><a href="https://ay17.moodle.umn.edu/course/view.php?id=8619#section-11">https://ay17.moodle.umn.edu/course/view.php?id=8619#section-11</a><a class=headerlink href=#httpsay17moodleumneducourseviewphpid8619section-11 title="Permanent link">&para;</a></h3> <p><strong>Instructors:</strong><br> Dan Kersten (<a href=mailto:kersten@umn.edu>&#107;&#101;&#114;&#115;&#116;&#101;&#110;&#64;&#117;&#109;&#110;&#46;&#101;&#100;&#117;</a>)<br> Paul Schrater (<a href=mailto:schrater@umn.edu>&#115;&#99;&#104;&#114;&#97;&#116;&#101;&#114;&#64;&#117;&#109;&#110;&#46;&#101;&#100;&#117;</a>) </p> <p><strong>Summary</strong> </p> <p>It has been proposed that perception is fundamentally a process of “analysis-by-synthesis” in which the sensory input is analyzed bottom-up, with perceptual interpretations tested and refined by top-down predictions of the input, through synthesis. However, while the computational and neural study of the analysis component is well-developed, less is known about the principles and mechanisms that underly synthesis. This seminar will explore recent advances using “deep” learning algorithms to discover hierarchical statistical regularities in large datasets of natural patterns, and the relevance of the learning results to models of human perception and recognition. These algorithms also provide the basis for the stochastic synthesis of novel, yet familiar patterns, which raises the question of whether the human experiences of dreams and hallucinations, and the ability to imagine, reflect the same statistical regularities that are discoverable using machine learning. The class format will include short introductory lectures by the instructors, and weekly student presentations of current literature. The short lectures will provide historical context as well as tutorials on machine learning (e.g. TensorFlow for neural network simulations).</p> <p><font color=#660033><strong><font color=#FF0033>Meeting time</font></strong></font><font color=#FF0033>:</font> First meeting Tuesday, Jan 16<sup>th</sup>, 3:00 pm.<br> <strong><font color=#FF0033>Place:</font> Elliott</strong> <strong>N227</strong></p> <p><span id=yui_3_17_2_1_1513968723300_1232>Students can sign up for either </span>Topics in Computational Vision Psy 8036 (Kersten) <span id=yui_3_17_2_1_1513968723300_2047>or </span>Psy 5993 Section 034 (Schrater) .</p> <p><strong>Background<br> </strong><br> There is a long history of theories of perception in which the brain “explains” sensory input in terms of external, behaviorally relevant causes. A current hypothesis is that this process is implemented in part by cortical feedback mechanisms that synthesize predictions of early data representations in order to test how well the brain's current interpretation of the world corresponds with the sensory data. In this view, perception involves a cycle in which the incoming data triggers a set of explanations, i.e. hypotheses, which are used to measure how far the expected sensory input differs from the actual input. From a computational perspective, such generative models of perceptual inference have a number of advantages over strictly bottom-up inference. A generative model can incorporate measures of "goodness-of-fit" to decide whether to accept or reject an interpretation--some explanations are better than others. Discrepancies between sensory data and predictions may also be used to direct attentional resources and signal whether more complex combinations of hypotheses are needed. Further, with sufficient structure, a generative model could provide the basis for the perceptual interpretation of sensory input outside the range of past experience.</p> <p>While computational theories for bottom-up neural mechanisms for perception have received considerable scientific attention, much less is known about top-down mechanisms. This seminar will explore the idea that the brain has hierarchically structured mechanisms that can synthesize patterns of input representations with the following constraints: 1) the mechanisms build on inductive structural biases that are innate; 2) the mechanisms reflect the statistical regularities induced by the physical causes of sensory experience, i.e. they are "data-driven"; 3) the need for cognitive processes to access semantic, perceptual content over levels of abstraction. Assumptions 1) and 2) constrain the class of generative models to be "data-driven", i.e. models that can be learned from sensory data.</p> <p>Recent computational methods for data-driven pattern synthesis (e.g. VAE, InfoGAN, Adversarial Bayes, StackGAN) will be covered in this seminar.  We will also explore the proposal that the same circuitry that may underly feedback in perception is used during imagery, dreams, and hallucinations. </p> <blockquote> <h1 id=tentative-syllabus><strong><em>Tentative Syllabus</em></strong><a class=headerlink href=#tentative-syllabus title="Permanent link">&para;</a></h1> </blockquote> <table width=876 border=1> <tbody> <tr> <td width=79> <div align=center>**Week**</div> </td> <td width=154> <div align=center> **Topics** </div> </td> <td width=304>**Background material**</td> <td width=311>**Discussion topics and papers**</td> </tr> <tr> <td>1: Jan 16</td> <td align=center> Background Models of perception </td> <td>Yuille, A., & Kersten, D. (2006). Vision as Bayesian inference: analysis by synthesis? Trends in Cognitive Sciences, 10(7), 301–308\.</td> <td> </td> </tr> <tr> <td>2: Jan 23</td> <td align=center> Overview of machine learning </td> <td>Ackley, D. H., Hinton, G. E., & Sejnowski, T. J. (1985). A learning algorithm for Boltzmann machines. Cognitive Science, 9(1), 147–169.</td> <td> </td> </tr> <tr> <td>3: Jan 30</td> <td align=center> Shallow image models, textures </td> <td> Zhu, S. C., Wu, Y., & Mumford, D. (1998). Filters, random fields and maximum entropy (FRAME): Towards a unified theory for texture modeling. International Journal of Computer Vision, 27(2), 107–126\. McDermott, J. H., Schemitsch, M., & Simoncelli, E. P. (2013). Summary statistics in auditory perception. Nature Publishing Group, 16(4), 493–498\. </td> <td></td> </tr> <tr> <td>4: Feb 6</td> <td align=center> Hierarchical image models, deep learning </td> <td>Zhu, S.-C., & Mumford, D. (2006). Quest for a stochastic grammar of images. Foundations and Trends® in Computer Graphics and Vision, 2(4), 259–362\.</td> <td>Topic preview: Visual imagery</td> </tr> <tr> <td>5: Feb 13</td> <td align=center> Hierarchical image models, deep learning </td> <td> </td> <td>Topic preview: Auditory imagery</td> </tr> <tr> <td>6: Feb 20</td> <td align=center> Hierarchical image models, deep learning </td> <td> </td> <td>Topic preview: Hypnagogic imagery</td> </tr> <tr> <td>7: Feb 27</td> <td align=center> Dynamic textures, patterns </td> <td> Xie, J., & Zhu, S. C. (n.d.). Synthesizing Dynamic Patterns by Spatial-Temporal Generative ConvNet. arXiv.org. Vondrick, C., Pirsiavash, H., & Torralba, A. (2016). Generating Videos with Scene Dynamics. Advances in Neural Information Processing Systems NIPS, 613–621. </td> <td>Topic preview: Dreams</td> </tr> <tr> <td>8: Mar 6</td> <td align=center>Visual imagery</td> <td> Christophel, T. B., Klink, P. C., Spitzer, B., Roelfsema, P. R., & Haynes, J.-D. (2017). The Distributed Nature of Working Memory. Trends in Cognitive Sciences, 1–15\. Dijkstra, N., Zeidman, P., Ondobaka, S., Gerven, M. A. J., & Friston, K. (2017). Distinct Top-down and Bottom-up Brain Connectivity During Visual Perception and Imagery. Scientific Reports, 1–9\. </td> <td>Topic preview: Lucid dreaming</td> </tr> <tr> <td>Mar 13</td> <td align=center> Spring Break </td> <td> </td> <td> </td> </tr> <tr> <td>9: Mar 20</td> <td align=center>Auditory, musical imagery</td> <td> Zatorre, R. J., & Halpern, A. R. (2005). Mental Concerts: Musical Imagery and Auditory Cortex. Neuron, 47(1), 9–12. Riecke, L., A. J. van Opstal, R. Goebel, and E. Formisano. “Hearing Illusory Sounds in Noise: Sensory-Perceptual Transformations in Primary Auditory Cortex.” Journal of Neuroscience 27, no. 46 (November 14, 2007): 12684–89\. McDermott, Josh H., and Andrew J. Oxenham. “Spectral Completion of Partially Masked Sounds.” Proceedings of the National Academy of Sciences 105, no. 15 (2008): 5939–5944. </td> <td>Topic overview: Hallucinations & psychedelics</td> </tr> <tr> <td>10: Mar 27</td> <td align=center>Hypnagogic imagery</td> <td>Schacter, D. L. (1976). The hypnagogic state: a critical review of the literature. Psychological Bulletin.</td> <td>Topic preview: Hallucinations & schizophrenia</td> </tr> <tr> <td>11: Apr 3</td> <td align=center>Dreams</td> <td> Stickgold, R., Hobson, J. A., Fosse, R., & Fosse, M. (2001). Sleep, Learning, and Dreams: Off-line Memory Reprocessing. Science, 294(5544), 1052–1057\. Crick, F., G. Mitchison., 1983\. The function of dream sleep. Nature. Springer </td> <td>Topic preview: Imagination</td> </tr> <tr> <td>12: Apr 10</td> <td align=center> Lucid dreaming </td> <td>Voss, U., Holzmann, R., Tuin, I., , J. A. Hobson., 2009\. Lucid dreaming: a state of consciousness with features of both waking and non-lucid dreaming. Sleep.</td> <td> </td> </tr> <tr> <td>13: Apr 17</td> <td align=center>Hallucinations</td> <td> Seriès, P., Reichert, D. P., & Storkey, A. J. (2010). Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model, 2020–2028.  Ermentrout, G. B., & Cowan, J. D. (1979). A mathematical theory of visual hallucination patterns. Biological Cybernetics, 34(3), 137–150 Howard, R. J., Brammer, M. J., David, A., Woodruff, P., & Williams, S. (1998). The anatomy of conscious vision: an fMRI study of visual hallucinations. Nature neuroscience, 1(8), 738-742. </td> <td> </td> </tr> <tr> <td>14: Apr 24</td> <td align=center>Hallucinations</td> <td>Kumar, S., Sedley, W., Barnes, G. R., Teki, S., Friston, K. J., & Griffiths, T. D. (2014). A brain basis for musical hallucinations. Cortex, 52(C), 86–97</td> <td> </td> </tr> <tr> <td>15: May 1</td> <td align=center> Imagination, art and design </td> <td>Friston, K. J., Lin, M., Frith, C. D., Pezzulo, G., Hobson, J. A., & Ondobaka, S. (2017). Active Inference, Curiosity and Insight. Neural Computation, 29(10), 2633–2683.</td> <td> </td> </tr> <tr> <td>16: May 8</td> <td align=center>Finals week</td> <td> </td> <td>FINAL PROJECT PRESENTATIONS</td> </tr> <tr> <td> </td> <td align=center> </td> <td> </td> <td> </td> </tr> </tbody> </table> <hr> <h1 id=sample-readings-under-construction><strong><em>Sample Readings (under construction)</em></strong><a class=headerlink href=#sample-readings-under-construction title="Permanent link">&para;</a></h1> <h3 id=background>Background<a class=headerlink href=#background title="Permanent link">&para;</a></h3> <p>Ackley, D. H., Hinton, G. E., &amp; Sejnowski, T. J. (1985). A learning algorithm for Boltzmann machines. Cognitive Science, 9(1), 147–169.<br> Bastos, A. M., Usrey, W. M., Adams, R. A., Mangun, G. R., Fries, P., &amp; Friston, K. J. (2012). Canonical Microcircuits for Predictive Coding. Neuron, 76(4), 695–711.<br> Berkes, P., Orban, G., Lengyel, M., &amp; Fiser, J. (2011). Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment. Science, 331(6013), 83–87.<br> Dayan, P., Hinton, G. E., Neal, R. M., &amp; Zemel, R. S. (1995). The Helmholtz Machine. Neural Computation, 7(5), 889–904.<br> Ouden, den, H. E. M. (2012). How prediction errors shape perception, attention, and motivation, 1–12.<br> Orban, G., Pietro Berkes, Fiser, J., &amp; Lengyel, M. (2016). Neural Variability and Sampling-Based Probabilistic Representations in the Visual Cortex. Neuron, 92(2), 530–543.<br> MacKay, D. M. (1956). Towards an information-flow model of human behaviour. British Journal of Psychology (London, England : 1953), 47(1), 30–43.<br> Lake, B. M., Salakhutdinov, R., &amp; Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350(6266), 1332–1338. <a href=http://doi.org/10.1126/science.aab3050>http://doi.org/10.1126/science.aab3050</a><br> LeCun, Y., Bengio, Y., &amp; Hinton, G. (2015). Deep learning. Nature, 521(7553), 436–444. <a href=http://doi.org/10.1038/nature14539>http://doi.org/10.1038/nature14539</a><br> McDermott, Josh H., and Andrew J. Oxenham. “Spectral Completion of Partially Masked Sounds.” Proceedings of the National Academy of Sciences 105, no. 15 (2008): 5939–5944.Mumford, D. (1992). On the computational architecture of the neocortex. Biological Cybernetics, 66(3), 241–251.<br> Mumford, D. (1994). Pattern theory: a unifying perspective, 187–224.<br> Rao, R. P. N., &amp; Ballard, D. H. (1999). Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nature Neuroscience, 2, 79–87.<br> Tu, Z., Chen, X., Yuille, A. L., &amp; Zhu, S.-C. (2005). Image parsing: Unifying segmentation, detection, and recognition. International Journal of Computer Vision, 63(2), 113–140.<br> Yuille, A., &amp; Kersten, D. (2006). Vision as Bayesian inference: analysis by synthesis? Trends in Cognitive Sciences, 10(7), 301–308.<br> Richards, W. (1971). The Fortification Illusions of Migraines, Scientific American, 1–10.<br> Zhu, S.-C., &amp; Mumford, D. (2006). Quest for a stochastic grammar of images. Foundations and Trends® in Computer Graphics and Vision, 2(4), 259–362. <a href=http://doi.org/10.1561/0600000018>http://doi.org/10.1561/0600000018</a></p> <h3 id=shallow-generative-models-texture-synthesis><strong>Shallow generative models</strong>: <strong>Texture synthesis</strong><a class=headerlink href=#shallow-generative-models-texture-synthesis title="Permanent link">&para;</a></h3> <p>Freeman, J., &amp; Simoncelli, E. P. (2011). Metamers of the ventral stream. Nature Publishing Group, 14(9), 1195–1201. <a href=http://doi.org/10.1038/nn.2889>http://doi.org/10.1038/nn.2889</a><br> McDermott, J. H., Schemitsch, M., &amp; Simoncelli, E. P. (2013). Summary statistics in auditory perception. Nature Publishing Group, 16(4), 493–498.<br> McDermott, J. H., &amp; Simoncelli, E. P. (2011). Sound Texture Perception via Statistics of the Auditory Periphery: Evidence from Sound Synthesis. Neuron, 71(5), 926–940.<br> Zhu, S. C., Wu, Y., &amp; Mumford, D. (1998). Filters, random fields and maximum entropy (FRAME): Towards a unified theory for texture modeling. International Journal of Computer Vision, 27(2), 107–126.</p> <h3 id=hierarchical-deep-data-driven-generative-models>Hierarchical (deep) data-driven generative models<a class=headerlink href=#hierarchical-deep-data-driven-generative-models title="Permanent link">&para;</a></h3> <p>Chen, X., Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., &amp; Abbeel, P. (2016). InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets, 2172–2180.<br> Goodfellow, I. (2016, December 31). NIPS 2016 Tutorial: Generative Adversarial Networks.<br> Kulkarni, T. D., Whitney, W. F., Kohli, P., &amp; Tenenbaum, J. (2015). Deep Convolutional Inverse Graphics Network, 2539–2547.<br> Rock, J., Issaranon, T., Deshpande, A., &amp; Forsyth, D. (2016, December 5). Authoring image decompositions with generative models.<br> Varol, G., Romero, J., Martin, X., Mahmood, N., Black, M. J., Laptev, I., &amp; Schmid, C. (2017, January 5). Learning from Synthetic Humans.<br> Xie, J., Zhu, S.-C., &amp; Wu, Y. N. (2016, June 3). Synthesizing Dynamic Patterns by Spatial-Temporal Generative ConvNet.<br> Yosinski, J., Clune, J., Nguyen, A., Fuchs, T., &amp; Lipson, H. (2015, June 22). Understanding Neural Networks Through Deep Visualization.<br> Zhang, H., Xu, T., Li, H., Zhang, S., Wang, X., Huang, X., &amp; Metaxas, D. (2016, December 10). StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks.</p> <h3 id=hypnagogic-imagery>Hypnagogic imagery<a class=headerlink href=#hypnagogic-imagery title="Permanent link">&para;</a></h3> <p>Gurstelle, E. B., &amp; de Oliveira, J. L. (2004). Daytime parahypnagogia: a state of consciousness that occurs when we almost fall asleep. Medical Hypotheses, 62(2), 166–168. <a href=http://doi.org/10.1016/S0306-9877(03)00306-2>http://doi.org/10.1016/S0306-9877(03)00306-2</a><br> Holmes, E. A., James, E. L., Coode-Bate, T., &amp; Deeprose, C. (2009). Can Playing the Computer Game “Tetris” Reduce the Build-Up of Flashbacks for Trauma? A Proposal from Cognitive Science. PLoS ONE, 4(1), e4153. <a href=http://doi.org/10.1371/journal.pone.0004153.t004>http://doi.org/10.1371/journal.pone.0004153.t004</a><br> Nielsen, T. A. (1995). Describing and modeling hypnagogic imagery using a systematic self-observation procedure. Dreaming, 5(2), 75–94. <a href=http://doi.org/10.1037/h0094426>http://doi.org/10.1037/h0094426</a><br> Nielsen, T. A. (2016). A Self-Observational Study of Spontaneous Hypnagogic Imagery Using the Upright Napping Procedure. Imagination, Cognition and Personality, 11(4), 353–366. <a href=http://doi.org/10.2190/3LVV-L5GY-UR5V-N0TG>http://doi.org/10.2190/3LVV-L5GY-UR5V-N0TG</a><br> *Schacter, D. L. (1976). The hypnagogic state: a critical review of the literature. Psychological Bulletin.<br> Stickgold, R. (2000). Replaying the Game: Hypnagogic Images in Normals and Amnesics. Science, 290(5490), 350–353. <a href=http://doi.org/10.1126/science.290.5490.350>http://doi.org/10.1126/science.290.5490.350</a></p> <h3 id=dreams>Dreams<a class=headerlink href=#dreams title="Permanent link">&para;</a></h3> <p>Band, J. C. Z. F. A., 2016. (n.d.). Animal “Hypnosis” and Waking Nightmares. Anomalistik.De<br> Crick, F., G. Mitchison., 1983. The function of dream sleep. Nature. Springer<br> *Hobson, J. A., &amp; Mccarley, R. W. (197.). The brain as a dream state generator: an activation-synthesis hypothesis of the dream process. The American Journal of Psychiatry.<br> Dresler, M., Koch, S. P., Wehrle, R., Spoormaker, V. I., Holsboer, F., Steiger, A., et al. (2011). Dreamed Movement Elicits Activation in the Sensorimotor Cortex. Current Biology : CB.<br> Stickgold, R., Hobson, J. A., Fosse, R., &amp; Fosse, M. (2001). Sleep, Learning, and Dreams: Off-line Memory Reprocessing. Science, 294(5544), 1052–1057. <a href=http://doi.org/10.1126/science.1063530>http://doi.org/10.1126/science.1063530</a><br> Stickgold, R. (2005). Sleep-dependent memory consolidation. Nature, 437(7063), 1272–1278. <a href=http://doi.org/10.1038/nature04286>http://doi.org/10.1038/nature04286</a><br> Studies, J. H. J. O. C., 2014. (n.d.). Consciousness, dreams, and inference: the cartesian theatre revisited. Ingentaconnect.com </p> <h3 id=hallucinations>Hallucinations<a class=headerlink href=#hallucinations title="Permanent link">&para;</a></h3> <p>Bressloff, P. C., Cowan, J. D., Golubitsky, M., Thomas, P. J., &amp; Wiener, M. C. (2002). What geometric visual hallucinations tell us about the visual cortex. Neural Computation, 14(3), 473–491. <a href=http://doi.org/10.1162/089976602317250861>http://doi.org/10.1162/089976602317250861</a><br> Cummings, J. L., &amp; Miller, B. L. (1987). Visual hallucinations. Clinical occurrence and use in differential diagnosis. The Western Journal of Medicine, 146(1), 46–51.<br> *Ermentrout, G. B., &amp; Cowan, J. D. (1979). A mathematical theory of visual hallucination patterns. Biological Cybernetics, 34(3), 137–150. <a href=http://doi.org/10.1007/BF00336965>http://doi.org/10.1007/BF00336965</a><br> Merabet, L. B., Maguire, D., Warde, A., Alterescu, K., Stickgold, R., &amp; Pascual-Leone, A. (2004). Visual hallucinations during prolonged blindfolding in sighted subjects. Journal of Neuro-Ophthalmology, 24(2), 109–113.<br> Howard, R. J., Brammer, M. J., David, A., Woodruff, P., &amp; Williams, S. (1998). The anatomy of conscious vision: an fMRI study of visual hallucinations. Nature neuroscience, 1(8), 738-742.Seriès, P., Reichert, D. P., &amp; Storkey, A. J. (2010). Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model, 2020–2028.<br> Silverstein, S. M. (2016). Visual Perception Disturbances in Schizophrenia: A Unified Model. In The Neuropsychopathology of Schizophrenia: Molecules, Brain Systems, Motivation, and Cognition (3<sup>rd</sup> ed., Vol. 63, pp. 77–132). Cham: Springer International Publishing. <a href=http://doi.org/10.1007/978-3-319-30596-7_4>http://doi.org/10.1007/978-3-319-30596-7_4</a><br> Kumar, S., Sedley, W., Barnes, G. R., Teki, S., Friston, K. J., &amp; Griffiths, T. D. (2014). A brain basis for musical hallucinations. Cortex, 52(C), 86–97. <a href=http://doi.org/10.1016/j.cortex.2013.12.002>http://doi.org/10.1016/j.cortex.2013.12.002</a></p> <h3 id=imagery-and-imagination>Imagery and imagination<a class=headerlink href=#imagery-and-imagination title="Permanent link">&para;</a></h3> <p>Chetverikov, A., &amp; Kristjánsson, Á. (2016). On the joys of perceiving: Affect as feedback for perceptual predictions. Actpsy, 169(C), 1–10. <a href=http://doi.org/10.1016/j.actpsy.2016.05.005>http://doi.org/10.1016/j.actpsy.2016.05.005</a><br> Dijkstra, N., Zeidman, P., Ondobaka, S., Gerven, M. A. J., &amp; Friston, K. (2017). Distinct Top-down and Bottom-up Brain Connectivity During Visual Perception and Imagery. Scientific Reports, 1–9. <a href=http://doi.org/10.1038/s41598-017-05888-8>http://doi.org/10.1038/s41598-017-05888-8</a><br> Friston, K. J., Lin, M., Frith, C. D., Pezzulo, G., Hobson, J. A., &amp; Ondobaka, S. (2017). Active Inference, Curiosity and Insight. Neural Computation, 29(10), 2633–2683. <a href=http://doi.org/10.1162/neco_a_00999>http://doi.org/10.1162/neco_a_00999</a><br> Kosslyn, S. M., &amp; Thompson, W. L. (2003). When is early visual cortex activated during visual mental imagery? Psychological Bulletin, 129(5), 723–746. <a href=http://doi.org/10.1037/0033-2909.129.5.723>http://doi.org/10.1037/0033-2909.129.5.723</a><br> Kosslyn, S. M., Alpert, N. M., Thompson, W. L., Maljkovic, V., Weise, S. B., Chabris, C. F., et al. (1993). Visual Mental Imagery Activates Topographically Organized Visual Cortex: PET Investigations. Journal of Cognitive Neuroscience, 5(3), 263–287. <a href=http://doi.org/10.1162/jocn.1993.5.3.263>http://doi.org/10.1162/jocn.1993.5.3.263</a><br> Kosslyn, S., &amp; Ganis, G. (2000). Neural foundations of imagery. Nature Reviews ….<br> Pearson, J., Naselaris, T., Holmes, E. A., &amp; Kosslyn, S. M. (2015). Mental Imagery: Functional Mechanisms and Clinical Applications. Trends in Cognitive Sciences, 19(10), 590–602. <a href=http://doi.org/10.1016/j.tics.2015.08.003>http://doi.org/10.1016/j.tics.2015.08.003</a><br> Riecke, L., A. J. van Opstal, R. Goebel, and E. Formisano. “Hearing Illusory Sounds in Noise: Sensory-Perceptual Transformations in Primary Auditory Cortex.” Journal of Neuroscience 27, no. 46 (November 14, 2007): 12684–89. <a href=https://doi.org/10.1523/JNEUROSCI.2713-07.2007>https://doi.org/10.1523/JNEUROSCI.2713-07.2007</a>.<br> Schacter, D. L., Addis, D. R., Hassabis, D., Martin, V. C., Spreng, R. N., &amp; Szpunar, K. K. (2012). The Future of Memory: Remembering, Imagining, and the Brain. Neuron, 76(4), 677–694. <a href=http://doi.org/10.1016/j.neuron.2012.11.001>http://doi.org/10.1016/j.neuron.2012.11.001</a><br> Zatorre, R. J., &amp; Halpern, A. R. (2005). Mental Concerts: Musical Imagery and Auditory Cortex. Neuron, 47(1), 9–12. <a href=http://doi.org/10.1016/j.neuron.2005.06.013>http://doi.org/10.1016/j.neuron.2005.06.013</a></p> <h3 id=imagery-and-memory>Imagery and memory<a class=headerlink href=#imagery-and-memory title="Permanent link">&para;</a></h3> <p>Albers, A. M., Kok, P., Toni, I., Dijkerman, H. C., &amp; de Lange, F. P. (2013). Shared Representations for Working Memory and Mental Imagery in Early Visual Cortex. Curbio, 23(15), 1427–1431. <a href=http://doi.org/10.1016/j.cub.2013.05.065>http://doi.org/10.1016/j.cub.2013.05.065</a><br> Christophel, T. B., Klink, P. C., Spitzer, B., Roelfsema, P. R., &amp; Haynes, J.-D. (2017). The Distributed Nature of Working Memory. Trends in Cognitive Sciences, 1–15. <a href=http://doi.org/10.1016/j.tics.2016.12.007>http://doi.org/10.1016/j.tics.2016.12.007</a><br> Naselaris, T., Olman, C. A., Stansbury, D. E., Ugurbil, K., &amp; Gallant, J. L. (2015). A voxel-wise encoding model for early visual areas decodes mental images of remembered scenes. NeuroImage, 105(C), 215–228. <a href=http://doi.org/10.1016/j.neuroimage.2014.10.018>http://doi.org/10.1016/j.neuroimage.2014.10.018</a><br> Self, M. W., van Kerkoerle, T., &amp; Roelfsema, P. R. (2016). Layer-specificity in the effects of attention and working memory on activity in primary visual cortex. Nature Communications, 8, 1–12. <a href=http://doi.org/10.1038/ncomms13804>http://doi.org/10.1038/ncomms13804</a><br> Stickgold, R. (2005). Sleep-dependent memory consolidation. Nature, 437(7063), 1272–1278. <a href=http://doi.org/10.1038/nature04286>http://doi.org/10.1038/nature04286</a></p> <p><font size=-1><a href=http://privacy.umn.edu/ >Privacy Statement</a></font></p> </article> </div> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2020 Computational Vision Lab, Department of Psychology, University of Minnesota </div> </div> <div class=md-footer-social> <link rel=stylesheet href=../../assets/fonts/font-awesome.css> <a href="https://scholar.google.com/citations?user=6j1ZjJsAAAAJ&hl=en&oi=ao" target=_blank rel=noopener title=google class="md-footer-social__link fa fa-google"></a> <a href=https://github.com/danielkersten/ target=_blank rel=noopener title=github class="md-footer-social__link fa fa-github"></a> </div> </div> </div> </footer> </div> <script src=../../assets/javascripts/application.44c2b1c1.js></script> <script>app.initialize({version:"1.1",url:{base:"../.."}})</script> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script> </body> </html>