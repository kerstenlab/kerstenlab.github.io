<!DOCTYPE html>
<html class="no-js" lang="en"> <head><meta charset="utf-8"/><meta content="width=device-width,initial-scale=1" name="viewport"/><meta content="ie=edge" http-equiv="x-ua-compatible"/><meta content="The Computational Vision Lab combines computational theory with behavioral and brain image experiments to understand how we see the world around us." name="description"/><meta content="Daniel Kersten" name="author"/><meta content="Copy to clipboard" name="lang:clipboard.copy"/><meta content="Copied to clipboard" name="lang:clipboard.copied"/><meta content="en" name="lang:search.language"/><meta content="True" name="lang:search.pipeline.stopwords"/><meta content="True" name="lang:search.pipeline.trimmer"/><meta content="No matching documents" name="lang:search.result.none"/><meta content="1 matching document" name="lang:search.result.one"/><meta content="# matching documents" name="lang:search.result.other"/><meta content="[\s\-]+" name="lang:search.tokenizer"/><link href="/assets/images/favicon.ico" rel="shortcut icon"/><meta content="mkdocs-1.1, mkdocs-material-4.6.3" name="generator"/><title>PSY8036SP2018 - Computational Vision Lab</title><link href="../../assets/stylesheets/application.87b292c3.css" rel="stylesheet"/><link href="../../assets/stylesheets/application-palette.b246af5e.css" rel="stylesheet"/><script src="../../assets/javascripts/modernizr.eca31fed.js"></script><link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/><link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,400i,700%7CRoboto+Mono&amp;display=fallback" rel="stylesheet"/><style>body,input{font-family:"Open Sans","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style><link href="../../assets/fonts/material-icons.css" rel="stylesheet"/></head> <body class="psy8036sp2018" data-md-color-accent="umn-gold" data-md-color-primary="umn-maroon" dir="ltr"> <svg class="md-svg"> <defs> </defs> </svg> <input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/> <input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/> <label class="md-overlay" data-md-component="overlay" for="__drawer"></label> <a class="md-skip" href="#data-driven-generative-models-for-perception-dreaming-and-imagining" tabindex="0"> Skip to content </a> <header class="md-header" data-md-component="header"> <nav class="md-header-nav md-grid"> <div class="md-flex"> <div class="md-flex__cell md-flex__cell--shrink"> <a aria-label="University of Minnesota homepage" class="md-header-nav__button md-logo" href="https://twin-cities.umn.edu" title="University of Minnesota homepage"> <img alt="logo" height="38" src="/assets/images/D2D-gld-wht.svg" width="288"/> </a> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label> </div> <div class="md-flex__cell md-flex__cell--shrink"> <a aria-label="University of Minnesota homepage" class="block-m" href="https://twin-cities.umn.edu" title="University of Minnesota homepage"> <img alt="logo" height="24" src="/assets/images/block-m-gold.svg"/> </a> </div> <div class="md-flex__cell md-flex__cell--stretch"> <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title"> <span class="md-header-nav__topic"> <a aria-label="Department of Psychology" class="md-header-nav__parentunit" href="https://psych.umn.edu" title="Department of Psychology"> <small>Department of Psychology</small> </a><br/> <a aria-label="Computational Vision Lab" class="md-header-nav__site-name" href="../.." title="Computational Vision Lab"> Computational Vision Lab </a> </span> <span class="md-header-nav__topic"> <a aria-label="Computational Vision Lab" class="md-header-nav__site-name-title" href="../.." title="Computational Vision Lab"> <small>Computational Vision Lab</small> </a> <br/> <strong> PSY8036SP2018 </strong> </span> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label> <div class="md-search" data-md-component="search" role="dialog"> <label class="md-search__overlay" for="__search"></label> <div class="md-search__inner" role="search"> <form class="md-search__form" name="search"> <input aria-label="search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="query" data-md-state="active" name="query" placeholder="Search" spellcheck="false" type="text"/> <label class="md-icon md-search__icon" for="__search"></label> <button class="md-icon md-search__icon" data-md-component="reset" tabindex="-1" type="reset">  </button> </form> <div class="md-search__output"> <div class="md-search__scrollwrap" data-md-scrollfix=""> <div class="md-search-result" data-md-component="result"> <div class="md-search-result__meta"> Type to start searching </div> <ol class="md-search-result__list"></ol> </div> </div> </div> </div> </div> </div> </div> </nav> </header> <div class="md-container"> <main class="md-main" role="main"> <div class="md-main__inner md-grid" data-md-component="container"> <div class="md-sidebar md-sidebar--primary" data-md-component="navigation"> <div class="md-sidebar__scrollwrap"> <div class="md-sidebar__inner"> <nav class="md-nav md-nav--primary" data-md-level="0"> <label class="md-nav__title md-nav__title--site" for="__drawer"> <a class="md-nav__button md-logo" href="../.." title="Computational Vision Lab"> <img alt="logo" height="28" src="/assets/images/D2D-gld-wht.svg"/> </a> Computational Vision Lab </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../.." title="Home"> Home </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../publications/" title="Publications"> Publications </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../people/" title="People"> People </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../research/" title="Research"> Research </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input checked="" class="md-toggle md-nav__toggle" data-md-toggle="nav-5" id="nav-5" type="checkbox"/> <label class="md-nav__link" for="nav-5"> Courses </label> <nav class="md-nav" data-md-component="collapsible" data-md-level="1"> <label class="md-nav__title" for="nav-5"> Courses </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../PSY5036F2019/" title="PSY5036F2019"> PSY5036F2019 </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../PSY8036SP2019/" title="PSY8036SP2019"> PSY8036SP2019 </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../PSY5038F2018/" title="PSY5038F2018"> PSY5038F2018 </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-toggle md-nav__toggle" data-md-toggle="toc" id="__toc" type="checkbox"/> <a class="md-nav__link md-nav__link--active" href="./" title="PSY8036SP2018"> PSY8036SP2018 </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../PSY5036F2017/" title="PSY5036F2017"> PSY5036F2017 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" id="nav-6" type="checkbox"/> <label class="md-nav__link" for="nav-6"> Demos </label> <nav class="md-nav" data-md-component="collapsible" data-md-level="1"> <label class="md-nav__title" for="nav-6"> Demos </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../demos/lightness-shape/" title="Lightness and Shape"> Lightness and Shape </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../demos/matte-shiny/" title="Shiny or Matte?"> Shiny or Matte? </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../demos/retinotopy/" title="Retinotopy"> Retinotopy </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../demos/shadows/" title="Shadows"> Shadows </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../demos/transparency/" title="Transparency"> Transparency </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../images/BlojKerstenHurlbertDemo99.pdf" title="Color and Mutual Illumination"> Color and Mutual Illumination </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7" id="nav-7" type="checkbox"/> <label class="md-nav__link" for="nav-7"> Data sets </label> <nav class="md-nav" data-md-component="collapsible" data-md-level="1"> <label class="md-nav__title" for="nav-7"> Data sets </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../../datasets/camouflage/camouflage/" title="Camouflage"> Camouflage </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../contact/" title="Contact"> Contact </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component="toc"> <div class="md-sidebar__scrollwrap"> <div class="md-sidebar__inner"> <nav class="md-nav md-nav--secondary"> </nav> </div> </div> </div> <div class="md-content"> <article class="md-content__inner md-typeset"><a class="md-icon md-content__icon" download href="PSY8036SP2018.pdf" title="PDF Export"></a> <h3 id="data-driven-generative-models-for-perception-dreaming-and-imagining">Data-driven generative models for perception, dreaming, and imagining<a class="headerlink" href="#data-driven-generative-models-for-perception-dreaming-and-imagining" title="Permanent link">¶</a></h3> <p>University of Minnesota, Spring Semester, 2018</p> <h3 id="topics-in-computational-vision">**Topics in Computational Vision<a class="headerlink" href="#topics-in-computational-vision" title="Permanent link">¶</a></h3> <p>**Psy 8036 (Kersten)<br/> Psy 5993 Section 034 (Schrater) </p> <p><font size="-1"><a href="http://courses.kersten.org">http://courses.kersten.org</a></font></p> <h3 id="httpsay17moodleumneducourseviewphpid8619section-11"><a href="https://ay17.moodle.umn.edu/course/view.php?id=8619#section-11">https://ay17.moodle.umn.edu/course/view.php?id=8619#section-11</a><a class="headerlink" href="#httpsay17moodleumneducourseviewphpid8619section-11" title="Permanent link">¶</a></h3> <p><strong>Instructors:</strong><br/> Dan Kersten (kersten@umn.edu)<br/> Paul Schrater (schrater@umn.edu) </p> <p><strong>Summary</strong> </p> <p>It has been proposed that perception is fundamentally a process of “analysis-by-synthesis” in which the sensory input is analyzed bottom-up, with perceptual interpretations tested and refined by top-down predictions of the input, through synthesis. However, while the computational and neural study of the analysis component is well-developed, less is known about the principles and mechanisms that underly synthesis. This seminar will explore recent advances using “deep” learning algorithms to discover hierarchical statistical regularities in large datasets of natural patterns, and the relevance of the learning results to models of human perception and recognition. These algorithms also provide the basis for the stochastic synthesis of novel, yet familiar patterns, which raises the question of whether the human experiences of dreams and hallucinations, and the ability to imagine, reflect the same statistical regularities that are discoverable using machine learning. The class format will include short introductory lectures by the instructors, and weekly student presentations of current literature. The short lectures will provide historical context as well as tutorials on machine learning (e.g. TensorFlow for neural network simulations).</p> <p><font color="#660033"><strong><font color="#FF0033">Meeting time</font></strong></font><font color="#FF0033">:</font> First meeting Tuesday, Jan 16<sup>th</sup>, 3:00 pm.<br/> <strong><font color="#FF0033">Place:</font> Elliott</strong> <strong>N227</strong></p> <p><span id="yui_3_17_2_1_1513968723300_1232">Students can sign up for either </span>Topics in Computational Vision Psy 8036 (Kersten) <span id="yui_3_17_2_1_1513968723300_2047">or </span>Psy 5993 Section 034 (Schrater) .</p> <p><strong>Background<br/> </strong><br/> There is a long history of theories of perception in which the brain “explains” sensory input in terms of external, behaviorally relevant causes. A current hypothesis is that this process is implemented in part by cortical feedback mechanisms that synthesize predictions of early data representations in order to test how well the brain's current interpretation of the world corresponds with the sensory data. In this view, perception involves a cycle in which the incoming data triggers a set of explanations, i.e. hypotheses, which are used to measure how far the expected sensory input differs from the actual input. From a computational perspective, such generative models of perceptual inference have a number of advantages over strictly bottom-up inference. A generative model can incorporate measures of "goodness-of-fit" to decide whether to accept or reject an interpretation--some explanations are better than others. Discrepancies between sensory data and predictions may also be used to direct attentional resources and signal whether more complex combinations of hypotheses are needed. Further, with sufficient structure, a generative model could provide the basis for the perceptual interpretation of sensory input outside the range of past experience.</p> <p>While computational theories for bottom-up neural mechanisms for perception have received considerable scientific attention, much less is known about top-down mechanisms. This seminar will explore the idea that the brain has hierarchically structured mechanisms that can synthesize patterns of input representations with the following constraints: 1) the mechanisms build on inductive structural biases that are innate; 2) the mechanisms reflect the statistical regularities induced by the physical causes of sensory experience, i.e. they are "data-driven"; 3) the need for cognitive processes to access semantic, perceptual content over levels of abstraction. Assumptions 1) and 2) constrain the class of generative models to be "data-driven", i.e. models that can be learned from sensory data.</p> <p>Recent computational methods for data-driven pattern synthesis (e.g. VAE, InfoGAN, Adversarial Bayes, StackGAN) will be covered in this seminar.  We will also explore the proposal that the same circuitry that may underly feedback in perception is used during imagery, dreams, and hallucinations. </p> <blockquote> <h1 id="tentative-syllabus"><strong><em>Tentative Syllabus</em></strong><a class="headerlink" href="#tentative-syllabus" title="Permanent link">¶</a></h1> </blockquote> <table border="1" width="876"> <tbody> <tr> <td width="79"> <div align="center">**Week**</div> </td> <td width="154"> <div align="center"> **Topics** </div> </td> <td width="304">**Background material**</td> <td width="311">**Discussion topics and papers**</td> </tr> <tr> <td>1: Jan 16</td> <td align="center"> Background Models of perception </td> <td>Yuille, A., &amp; Kersten, D. (2006). Vision as Bayesian inference: analysis by synthesis? Trends in Cognitive Sciences, 10(7), 301–308\.</td> <td> </td> </tr> <tr> <td>2: Jan 23</td> <td align="center"> Overview of machine learning </td> <td>Ackley, D. H., Hinton, G. E., &amp; Sejnowski, T. J. (1985). A learning algorithm for Boltzmann machines. Cognitive Science, 9(1), 147–169.</td> <td> </td> </tr> <tr> <td>3: Jan 30</td> <td align="center"> Shallow image models, textures </td> <td> Zhu, S. C., Wu, Y., &amp; Mumford, D. (1998). Filters, random fields and maximum entropy (FRAME): Towards a unified theory for texture modeling. International Journal of Computer Vision, 27(2), 107–126\. McDermott, J. H., Schemitsch, M., &amp; Simoncelli, E. P. (2013). Summary statistics in auditory perception. Nature Publishing Group, 16(4), 493–498\. </td> <td></td> </tr> <tr> <td>4: Feb 6</td> <td align="center"> Hierarchical image models, deep learning </td> <td>Zhu, S.-C., &amp; Mumford, D. (2006). Quest for a stochastic grammar of images. Foundations and Trends® in Computer Graphics and Vision, 2(4), 259–362\.</td> <td>Topic preview: Visual imagery</td> </tr> <tr> <td>5: Feb 13</td> <td align="center"> Hierarchical image models, deep learning </td> <td> </td> <td>Topic preview: Auditory imagery</td> </tr> <tr> <td>6: Feb 20</td> <td align="center"> Hierarchical image models, deep learning </td> <td> </td> <td>Topic preview: Hypnagogic imagery</td> </tr> <tr> <td>7: Feb 27</td> <td align="center"> Dynamic textures, patterns </td> <td> Xie, J., &amp; Zhu, S. C. (n.d.). Synthesizing Dynamic Patterns by Spatial-Temporal Generative ConvNet. arXiv.org. Vondrick, C., Pirsiavash, H., &amp; Torralba, A. (2016). Generating Videos with Scene Dynamics. Advances in Neural Information Processing Systems NIPS, 613–621. </td> <td>Topic preview: Dreams</td> </tr> <tr> <td>8: Mar 6</td> <td align="center">Visual imagery</td> <td> Christophel, T. B., Klink, P. C., Spitzer, B., Roelfsema, P. R., &amp; Haynes, J.-D. (2017). The Distributed Nature of Working Memory. Trends in Cognitive Sciences, 1–15\. Dijkstra, N., Zeidman, P., Ondobaka, S., Gerven, M. A. J., &amp; Friston, K. (2017). Distinct Top-down and Bottom-up Brain Connectivity During Visual Perception and Imagery. Scientific Reports, 1–9\. </td> <td>Topic preview: Lucid dreaming</td> </tr> <tr> <td>Mar 13</td> <td align="center"> Spring Break </td> <td> </td> <td> </td> </tr> <tr> <td>9: Mar 20</td> <td align="center">Auditory, musical imagery</td> <td> Zatorre, R. J., &amp; Halpern, A. R. (2005). Mental Concerts: Musical Imagery and Auditory Cortex. Neuron, 47(1), 9–12. Riecke, L., A. J. van Opstal, R. Goebel, and E. Formisano. “Hearing Illusory Sounds in Noise: Sensory-Perceptual Transformations in Primary Auditory Cortex.” Journal of Neuroscience 27, no. 46 (November 14, 2007): 12684–89\. McDermott, Josh H., and Andrew J. Oxenham. “Spectral Completion of Partially Masked Sounds.” Proceedings of the National Academy of Sciences 105, no. 15 (2008): 5939–5944. </td> <td>Topic overview: Hallucinations &amp; psychedelics</td> </tr> <tr> <td>10: Mar 27</td> <td align="center">Hypnagogic imagery</td> <td>Schacter, D. L. (1976). The hypnagogic state: a critical review of the literature. Psychological Bulletin.</td> <td>Topic preview: Hallucinations &amp; schizophrenia</td> </tr> <tr> <td>11: Apr 3</td> <td align="center">Dreams</td> <td> Stickgold, R., Hobson, J. A., Fosse, R., &amp; Fosse, M. (2001). Sleep, Learning, and Dreams: Off-line Memory Reprocessing. Science, 294(5544), 1052–1057\. Crick, F., G. Mitchison., 1983\. The function of dream sleep. Nature. Springer </td> <td>Topic preview: Imagination</td> </tr> <tr> <td>12: Apr 10</td> <td align="center"> Lucid dreaming </td> <td>Voss, U., Holzmann, R., Tuin, I., , J. A. Hobson., 2009\. Lucid dreaming: a state of consciousness with features of both waking and non-lucid dreaming. Sleep.</td> <td> </td> </tr> <tr> <td>13: Apr 17</td> <td align="center">Hallucinations</td> <td> Seriès, P., Reichert, D. P., &amp; Storkey, A. J. (2010). Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model, 2020–2028.  Ermentrout, G. B., &amp; Cowan, J. D. (1979). A mathematical theory of visual hallucination patterns. Biological Cybernetics, 34(3), 137–150 Howard, R. J., Brammer, M. J., David, A., Woodruff, P., &amp; Williams, S. (1998). The anatomy of conscious vision: an fMRI study of visual hallucinations. Nature neuroscience, 1(8), 738-742. </td> <td> </td> </tr> <tr> <td>14: Apr 24</td> <td align="center">Hallucinations</td> <td>Kumar, S., Sedley, W., Barnes, G. R., Teki, S., Friston, K. J., &amp; Griffiths, T. D. (2014). A brain basis for musical hallucinations. Cortex, 52(C), 86–97</td> <td> </td> </tr> <tr> <td>15: May 1</td> <td align="center"> Imagination, art and design </td> <td>Friston, K. J., Lin, M., Frith, C. D., Pezzulo, G., Hobson, J. A., &amp; Ondobaka, S. (2017). Active Inference, Curiosity and Insight. Neural Computation, 29(10), 2633–2683.</td> <td> </td> </tr> <tr> <td>16: May 8</td> <td align="center">Finals week</td> <td> </td> <td>FINAL PROJECT PRESENTATIONS</td> </tr> <tr> <td> </td> <td align="center"> </td> <td> </td> <td> </td> </tr> </tbody> </table> <hr/> <h1 id="sample-readings-under-construction"><strong><em>Sample Readings (under construction)</em></strong><a class="headerlink" href="#sample-readings-under-construction" title="Permanent link">¶</a></h1> <h3 id="background">Background<a class="headerlink" href="#background" title="Permanent link">¶</a></h3> <p>Ackley, D. H., Hinton, G. E., &amp; Sejnowski, T. J. (1985). A learning algorithm for Boltzmann machines. Cognitive Science, 9(1), 147–169.<br/> Bastos, A. M., Usrey, W. M., Adams, R. A., Mangun, G. R., Fries, P., &amp; Friston, K. J. (2012). Canonical Microcircuits for Predictive Coding. Neuron, 76(4), 695–711.<br/> Berkes, P., Orban, G., Lengyel, M., &amp; Fiser, J. (2011). Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment. Science, 331(6013), 83–87.<br/> Dayan, P., Hinton, G. E., Neal, R. M., &amp; Zemel, R. S. (1995). The Helmholtz Machine. Neural Computation, 7(5), 889–904.<br/> Ouden, den, H. E. M. (2012). How prediction errors shape perception, attention, and motivation, 1–12.<br/> Orban, G., Pietro Berkes, Fiser, J., &amp; Lengyel, M. (2016). Neural Variability and Sampling-Based Probabilistic Representations in the Visual Cortex. Neuron, 92(2), 530–543.<br/> MacKay, D. M. (1956). Towards an information-flow model of human behaviour. British Journal of Psychology (London, England : 1953), 47(1), 30–43.<br/> Lake, B. M., Salakhutdinov, R., &amp; Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350(6266), 1332–1338. http://doi.org/10.1126/science.aab3050<br/> LeCun, Y., Bengio, Y., &amp; Hinton, G. (2015). Deep learning. Nature, 521(7553), 436–444. http://doi.org/10.1038/nature14539<br/> McDermott, Josh H., and Andrew J. Oxenham. “Spectral Completion of Partially Masked Sounds.” Proceedings of the National Academy of Sciences 105, no. 15 (2008): 5939–5944.Mumford, D. (1992). On the computational architecture of the neocortex. Biological Cybernetics, 66(3), 241–251.<br/> Mumford, D. (1994). Pattern theory: a unifying perspective, 187–224.<br/> Rao, R. P. N., &amp; Ballard, D. H. (1999). Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nature Neuroscience, 2, 79–87.<br/> Tu, Z., Chen, X., Yuille, A. L., &amp; Zhu, S.-C. (2005). Image parsing: Unifying segmentation, detection, and recognition. International Journal of Computer Vision, 63(2), 113–140.<br/> Yuille, A., &amp; Kersten, D. (2006). Vision as Bayesian inference: analysis by synthesis? Trends in Cognitive Sciences, 10(7), 301–308.<br/> Richards, W. (1971). The Fortification Illusions of Migraines, Scientific American, 1–10.<br/> Zhu, S.-C., &amp; Mumford, D. (2006). Quest for a stochastic grammar of images. Foundations and Trends® in Computer Graphics and Vision, 2(4), 259–362. http://doi.org/10.1561/0600000018</p> <h3 id="shallow-generative-models-texture-synthesis"><strong>Shallow generative models</strong>: <strong>Texture synthesis</strong><a class="headerlink" href="#shallow-generative-models-texture-synthesis" title="Permanent link">¶</a></h3> <p>Freeman, J., &amp; Simoncelli, E. P. (2011). Metamers of the ventral stream. Nature Publishing Group, 14(9), 1195–1201. http://doi.org/10.1038/nn.2889<br/> McDermott, J. H., Schemitsch, M., &amp; Simoncelli, E. P. (2013). Summary statistics in auditory perception. Nature Publishing Group, 16(4), 493–498.<br/> McDermott, J. H., &amp; Simoncelli, E. P. (2011). Sound Texture Perception via Statistics of the Auditory Periphery: Evidence from Sound Synthesis. Neuron, 71(5), 926–940.<br/> Zhu, S. C., Wu, Y., &amp; Mumford, D. (1998). Filters, random fields and maximum entropy (FRAME): Towards a unified theory for texture modeling. International Journal of Computer Vision, 27(2), 107–126.</p> <h3 id="hierarchical-deep-data-driven-generative-models">Hierarchical (deep) data-driven generative models<a class="headerlink" href="#hierarchical-deep-data-driven-generative-models" title="Permanent link">¶</a></h3> <p>Chen, X., Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., &amp; Abbeel, P. (2016). InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets, 2172–2180.<br/> Goodfellow, I. (2016, December 31). NIPS 2016 Tutorial: Generative Adversarial Networks.<br/> Kulkarni, T. D., Whitney, W. F., Kohli, P., &amp; Tenenbaum, J. (2015). Deep Convolutional Inverse Graphics Network, 2539–2547.<br/> Rock, J., Issaranon, T., Deshpande, A., &amp; Forsyth, D. (2016, December 5). Authoring image decompositions with generative models.<br/> Varol, G., Romero, J., Martin, X., Mahmood, N., Black, M. J., Laptev, I., &amp; Schmid, C. (2017, January 5). Learning from Synthetic Humans.<br/> Xie, J., Zhu, S.-C., &amp; Wu, Y. N. (2016, June 3). Synthesizing Dynamic Patterns by Spatial-Temporal Generative ConvNet.<br/> Yosinski, J., Clune, J., Nguyen, A., Fuchs, T., &amp; Lipson, H. (2015, June 22). Understanding Neural Networks Through Deep Visualization.<br/> Zhang, H., Xu, T., Li, H., Zhang, S., Wang, X., Huang, X., &amp; Metaxas, D. (2016, December 10). StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks.</p> <h3 id="hypnagogic-imagery">Hypnagogic imagery<a class="headerlink" href="#hypnagogic-imagery" title="Permanent link">¶</a></h3> <p>Gurstelle, E. B., &amp; de Oliveira, J. L. (2004). Daytime parahypnagogia: a state of consciousness that occurs when we almost fall asleep. Medical Hypotheses, 62(2), 166–168. http://doi.org/10.1016/S0306-9877(03)00306-2<br/> Holmes, E. A., James, E. L., Coode-Bate, T., &amp; Deeprose, C. (2009). Can Playing the Computer Game “Tetris” Reduce the Build-Up of Flashbacks for Trauma? A Proposal from Cognitive Science. PLoS ONE, 4(1), e4153. http://doi.org/10.1371/journal.pone.0004153.t004<br/> Nielsen, T. A. (1995). Describing and modeling hypnagogic imagery using a systematic self-observation procedure. Dreaming, 5(2), 75–94. http://doi.org/10.1037/h0094426<br/> Nielsen, T. A. (2016). A Self-Observational Study of Spontaneous Hypnagogic Imagery Using the Upright Napping Procedure. Imagination, Cognition and Personality, 11(4), 353–366. http://doi.org/10.2190/3LVV-L5GY-UR5V-N0TG<br/> *Schacter, D. L. (1976). The hypnagogic state: a critical review of the literature. Psychological Bulletin.<br/> Stickgold, R. (2000). Replaying the Game: Hypnagogic Images in Normals and Amnesics. Science, 290(5490), 350–353. http://doi.org/10.1126/science.290.5490.350</p> <h3 id="dreams">Dreams<a class="headerlink" href="#dreams" title="Permanent link">¶</a></h3> <p>Band, J. C. Z. F. A., 2016. (n.d.). Animal “Hypnosis” and Waking Nightmares. Anomalistik.De<br/> Crick, F., G. Mitchison., 1983. The function of dream sleep. Nature. Springer<br/> *Hobson, J. A., &amp; Mccarley, R. W. (197.). The brain as a dream state generator: an activation-synthesis hypothesis of the dream process. The American Journal of Psychiatry.<br/> Dresler, M., Koch, S. P., Wehrle, R., Spoormaker, V. I., Holsboer, F., Steiger, A., et al. (2011). Dreamed Movement Elicits Activation in the Sensorimotor Cortex. Current Biology : CB.<br/> Stickgold, R., Hobson, J. A., Fosse, R., &amp; Fosse, M. (2001). Sleep, Learning, and Dreams: Off-line Memory Reprocessing. Science, 294(5544), 1052–1057. http://doi.org/10.1126/science.1063530<br/> Stickgold, R. (2005). Sleep-dependent memory consolidation. Nature, 437(7063), 1272–1278. http://doi.org/10.1038/nature04286<br/> Studies, J. H. J. O. C., 2014. (n.d.). Consciousness, dreams, and inference: the cartesian theatre revisited. Ingentaconnect.com </p> <h3 id="hallucinations">Hallucinations<a class="headerlink" href="#hallucinations" title="Permanent link">¶</a></h3> <p>Bressloff, P. C., Cowan, J. D., Golubitsky, M., Thomas, P. J., &amp; Wiener, M. C. (2002). What geometric visual hallucinations tell us about the visual cortex. Neural Computation, 14(3), 473–491. http://doi.org/10.1162/089976602317250861<br/> Cummings, J. L., &amp; Miller, B. L. (1987). Visual hallucinations. Clinical occurrence and use in differential diagnosis. The Western Journal of Medicine, 146(1), 46–51.<br/> *Ermentrout, G. B., &amp; Cowan, J. D. (1979). A mathematical theory of visual hallucination patterns. Biological Cybernetics, 34(3), 137–150. http://doi.org/10.1007/BF00336965<br/> Merabet, L. B., Maguire, D., Warde, A., Alterescu, K., Stickgold, R., &amp; Pascual-Leone, A. (2004). Visual hallucinations during prolonged blindfolding in sighted subjects. Journal of Neuro-Ophthalmology, 24(2), 109–113.<br/> Howard, R. J., Brammer, M. J., David, A., Woodruff, P., &amp; Williams, S. (1998). The anatomy of conscious vision: an fMRI study of visual hallucinations. Nature neuroscience, 1(8), 738-742.Seriès, P., Reichert, D. P., &amp; Storkey, A. J. (2010). Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model, 2020–2028.<br/> Silverstein, S. M. (2016). Visual Perception Disturbances in Schizophrenia: A Unified Model. In The Neuropsychopathology of Schizophrenia: Molecules, Brain Systems, Motivation, and Cognition (3<sup>rd</sup> ed., Vol. 63, pp. 77–132). Cham: Springer International Publishing. http://doi.org/10.1007/978-3-319-30596-7_4<br/> Kumar, S., Sedley, W., Barnes, G. R., Teki, S., Friston, K. J., &amp; Griffiths, T. D. (2014). A brain basis for musical hallucinations. Cortex, 52(C), 86–97. http://doi.org/10.1016/j.cortex.2013.12.002</p> <h3 id="imagery-and-imagination">Imagery and imagination<a class="headerlink" href="#imagery-and-imagination" title="Permanent link">¶</a></h3> <p>Chetverikov, A., &amp; Kristjánsson, Á. (2016). On the joys of perceiving: Affect as feedback for perceptual predictions. Actpsy, 169(C), 1–10. http://doi.org/10.1016/j.actpsy.2016.05.005<br/> Dijkstra, N., Zeidman, P., Ondobaka, S., Gerven, M. A. J., &amp; Friston, K. (2017). Distinct Top-down and Bottom-up Brain Connectivity During Visual Perception and Imagery. Scientific Reports, 1–9. http://doi.org/10.1038/s41598-017-05888-8<br/> Friston, K. J., Lin, M., Frith, C. D., Pezzulo, G., Hobson, J. A., &amp; Ondobaka, S. (2017). Active Inference, Curiosity and Insight. Neural Computation, 29(10), 2633–2683. http://doi.org/10.1162/neco_a_00999<br/> Kosslyn, S. M., &amp; Thompson, W. L. (2003). When is early visual cortex activated during visual mental imagery? Psychological Bulletin, 129(5), 723–746. http://doi.org/10.1037/0033-2909.129.5.723<br/> Kosslyn, S. M., Alpert, N. M., Thompson, W. L., Maljkovic, V., Weise, S. B., Chabris, C. F., et al. (1993). Visual Mental Imagery Activates Topographically Organized Visual Cortex: PET Investigations. Journal of Cognitive Neuroscience, 5(3), 263–287. http://doi.org/10.1162/jocn.1993.5.3.263<br/> Kosslyn, S., &amp; Ganis, G. (2000). Neural foundations of imagery. Nature Reviews ….<br/> Pearson, J., Naselaris, T., Holmes, E. A., &amp; Kosslyn, S. M. (2015). Mental Imagery: Functional Mechanisms and Clinical Applications. Trends in Cognitive Sciences, 19(10), 590–602. http://doi.org/10.1016/j.tics.2015.08.003<br/> Riecke, L., A. J. van Opstal, R. Goebel, and E. Formisano. “Hearing Illusory Sounds in Noise: Sensory-Perceptual Transformations in Primary Auditory Cortex.” Journal of Neuroscience 27, no. 46 (November 14, 2007): 12684–89. https://doi.org/10.1523/JNEUROSCI.2713-07.2007.<br/> Schacter, D. L., Addis, D. R., Hassabis, D., Martin, V. C., Spreng, R. N., &amp; Szpunar, K. K. (2012). The Future of Memory: Remembering, Imagining, and the Brain. Neuron, 76(4), 677–694. http://doi.org/10.1016/j.neuron.2012.11.001<br/> Zatorre, R. J., &amp; Halpern, A. R. (2005). Mental Concerts: Musical Imagery and Auditory Cortex. Neuron, 47(1), 9–12. http://doi.org/10.1016/j.neuron.2005.06.013</p> <h3 id="imagery-and-memory">Imagery and memory<a class="headerlink" href="#imagery-and-memory" title="Permanent link">¶</a></h3> <p>Albers, A. M., Kok, P., Toni, I., Dijkerman, H. C., &amp; de Lange, F. P. (2013). Shared Representations for Working Memory and Mental Imagery in Early Visual Cortex. Curbio, 23(15), 1427–1431. http://doi.org/10.1016/j.cub.2013.05.065<br/> Christophel, T. B., Klink, P. C., Spitzer, B., Roelfsema, P. R., &amp; Haynes, J.-D. (2017). The Distributed Nature of Working Memory. Trends in Cognitive Sciences, 1–15. http://doi.org/10.1016/j.tics.2016.12.007<br/> Naselaris, T., Olman, C. A., Stansbury, D. E., Ugurbil, K., &amp; Gallant, J. L. (2015). A voxel-wise encoding model for early visual areas decodes mental images of remembered scenes. NeuroImage, 105(C), 215–228. http://doi.org/10.1016/j.neuroimage.2014.10.018<br/> Self, M. W., van Kerkoerle, T., &amp; Roelfsema, P. R. (2016). Layer-specificity in the effects of attention and working memory on activity in primary visual cortex. Nature Communications, 8, 1–12. http://doi.org/10.1038/ncomms13804<br/> Stickgold, R. (2005). Sleep-dependent memory consolidation. Nature, 437(7063), 1272–1278. http://doi.org/10.1038/nature04286</p> <p><font size="-1"><a href="http://privacy.umn.edu/">Privacy Statement</a></font></p> </article> </div> </div> </main> <footer class="md-footer"> <div class="md-footer-nav"> <nav class="md-footer-nav__inner md-grid"> <a class="md-flex md-footer-nav__link md-footer-nav__link--prev" href="../PSY5038F2018/" rel="prev" title="PSY5038F2018"> <div class="md-flex__cell md-flex__cell--shrink"> <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i> </div> <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"> <span class="md-flex__ellipsis"> <span class="md-footer-nav__direction"> Previous </span> PSY5038F2018 </span> </div> </a> <a class="md-flex md-footer-nav__link md-footer-nav__link--next" href="../PSY5036F2017/" rel="next" title="PSY5036F2017"> <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"> <span class="md-flex__ellipsis"> <span class="md-footer-nav__direction"> Next </span> PSY5036F2017 </span> </div> <div class="md-flex__cell md-flex__cell--shrink"> <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class="md-footer-copyright"> <div class="md-footer-copyright__highlight"> © 2020 Regents of the University of Minnesota. All rights reserved. The University of Minnesota is an equal opportunity educator and employer. <br/> <a href="http://privacy.umn.edu">Privacy Statement</a> </div> </div> <div class="md-footer-social"> <link href="../../assets/fonts/font-awesome.css" rel="stylesheet"/> <a class="md-footer-social__link fa fa-google" href="https://scholar.google.com/citations?user=6j1ZjJsAAAAJ&amp;hl=en&amp;oi=ao" rel="noopener" target="_blank" title="google"></a> <a class="md-footer-social__link fa fa-github" href="https://github.com/kerstenlab" rel="noopener" target="_blank" title="github"></a> </div> </div> </div> </footer> </div> <script src="../../assets/javascripts/application.21234377.js"></script> <script>app.initialize({version:"1.1",url:{base:"../.."}})</script> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script> </body> </html>