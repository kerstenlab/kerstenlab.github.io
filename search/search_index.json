{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Kersten Computational Vision Lab \u00b6 Lab Summary The Computational Vision Lab combines computational theory with behavioral and brain image experiments to understand how we see the world around us. Upcoming Events \u00b6 Recent Publications \u00b6","title":"Home"},{"location":"#kersten-computational-vision-lab","text":"Lab Summary The Computational Vision Lab combines computational theory with behavioral and brain image experiments to understand how we see the world around us.","title":"Kersten Computational Vision Lab"},{"location":"#upcoming-events","text":"","title":"Upcoming Events"},{"location":"#recent-publications","text":"","title":"Recent Publications"},{"location":"contact/","text":"kersten@umn.edu Lab Location N13 Elliott Hall 75 East River Road Minneapolis, MN 55455 Call Lab Phone: 612-625-1337 for access. Once in Elliott Hall, take the elevator on the North end of the building to the basement. The lab is in room N13.","title":"Contact"},{"location":"people/","text":"People \u00b6 Director \u00b6 Daniel J Kersten, PhD Department of Psychology N218 Elliott Hall kersten@umn.edu scholar | homepage Graduate Students \u00b6 Doug Addleman Department of Psychology N218 Elliott Hall addle005@umn.edu scholar | homepage Alexander Bratch Department of Psychology N218 Elliott Hall bratc006@umn.edu scholar Yijun Ge Department of Psychology N218 Elliott Hall gexxx119@umn.edu Subhankar Ghosh Computer Science & Engineering ghosh117@umn.edu Jiaqi Liu liu00687@umn.edu Siyun Liu Department of Psychology N218 Elliott Hall liux4433@umn.edu Ziwei Liu Department of Psychology N218 Elliott Hall liu00964@umn.edu Link Swanson Cognitive Science S309 Elliott Hall link@umn.edu scholar | homepage Undergraduates \u00b6 Yixiong Chen chen5256@umn.edu Anusha Duggirala duggi008@umn.edu Lab Alumni \u00b6 Academic genealogy of past and current lab members at Neurotree .","title":"People"},{"location":"people/#people","text":"","title":"People"},{"location":"people/#director","text":"Daniel J Kersten, PhD Department of Psychology N218 Elliott Hall kersten@umn.edu scholar | homepage","title":"Director"},{"location":"people/#graduate-students","text":"Doug Addleman Department of Psychology N218 Elliott Hall addle005@umn.edu scholar | homepage Alexander Bratch Department of Psychology N218 Elliott Hall bratc006@umn.edu scholar Yijun Ge Department of Psychology N218 Elliott Hall gexxx119@umn.edu Subhankar Ghosh Computer Science & Engineering ghosh117@umn.edu Jiaqi Liu liu00687@umn.edu Siyun Liu Department of Psychology N218 Elliott Hall liux4433@umn.edu Ziwei Liu Department of Psychology N218 Elliott Hall liu00964@umn.edu Link Swanson Cognitive Science S309 Elliott Hall link@umn.edu scholar | homepage","title":"Graduate Students"},{"location":"people/#undergraduates","text":"Yixiong Chen chen5256@umn.edu Anusha Duggirala duggi008@umn.edu","title":"Undergraduates"},{"location":"people/#lab-alumni","text":"Academic genealogy of past and current lab members at Neurotree .","title":"Lab Alumni"},{"location":"publications/","text":"126 Vizioli, L., De Martino, F., Petro, L. S., Kersten, D., Ugurbil, K., Yacoub, E., & Muckli, L. (2019). Multivoxel Pattern of Blood Oxygen Level Dependent Activity can be sensitive to stimulus specific fine scale responses [Preprint]. Neuroscience. https://doi.org/10.1101/798306 127 Peterson, L. M., Kersten, D. J., & Mannion, D. J. (2018). Surface curvature from kinetic depth can affect lightness. Journal of Experimental Psychology: Human Perception and Performance, 44(12), 1856\u20131864. https://doi.org/10.1037/xhp0000575 126 Morgenstern, Y., & Kersten, D. J. (2017). The perceptual dimensions of natural dynamic flow. Journal of Vision, 17(12), 7\u20137. https://doi.org/10.1167/17.12.7 125 Thompson, W. B., Legge, G. E., Kersten, D. J., Shakespeare, R. A., & Lei, Q. (2017). Simulating visibility under reduced acuity and contrast sensitivity. JOSA A, 34(4), 583\u2013593. https://doi.org/10.1364/JOSAA.34.00058 3 124 Fan, X., Wang, L., Shao, H., Kersten, D., & He, S. (2016). Temporally flexible feedback signal to foveal cortex for peripheral object recognition. Proc Natl Acad Sci U S A, 201606137\u20136. http://doi.org/10.1073/pnas.1606137113 123 Qiu, C., Burton, P. C., Kersten, D., & Olman, C. A. (2016). Responses in early visual areas to contour integration are context dependent. Journal of Vision, 16(8), 19\u201318. http://doi.org/10.1167/16.8.19 122 Green, C. S., Kattner, F., Siegel, M. H., Kersten, D., & Schrater, P. R. (2015). Differences in perceptual learning transfer as a function of training task. Journal of Vision, 15(10):5, 1\u201314. doi:10.1167/15.10.5. 121 Mannion, Damien J., Daniel J. Kersten, and Cheryl A. Olman. (2015) \"Scene coherence can affect the local response to natural images in human V1.\" European Journal of Neuroscience 42 (11), 2895-2903. 120 Kam, T.-E., Mannion, D. J., Lee, S.-W., Doerschner, K., & Kersten, D. J. (2015). Human visual cortical responses to specular and matte motion flows. Frontiers in Human Neuroscience, 9, 1\u201313. http://doi.org/10.3389/fnhum.2015.00579 119 Yuille, A.L. & Kersten D (in press) Early Vision. In From Neuron to Cognition via Computational Neuroscience, M.A. Arbib, James J. Bonaiuto Editors, Cambridge MA: The MIT Press. 118 Kersten D. & Mamassian, P. (2017) Cast Shadow Illusions. Oxford Compendium of Visual Illusions. Arthur G. Shapiro and Dejan Todorovic, Editors. (pdf draft ) 117 Mannion, D. J., Kersten, D. J., & Olman, C. A. (2014) Regions of mid-level human visual cortex sensitive to the global coherence of local image patches. Journal of Cognitive Neuroscience. 6 (8), 1764-1774. ( pdf ) 116 Kersten D. & Yuille, A.L.(2014) Inferential Models of the Visual Cortical Hierarchy. The New Cognitive Neurosciences, 5 th Edition. Michael S. Gazzaniga and George R. Mangun (editors) ( draft pdf) ( MIT press link ) 115 Akin, B., Ozdem, C., Eroglu, S., Keskin, D. T., Fang, F., Doerschner, K., et al. (2014). Attention modulates neuronal correlates of interhemispheric integration and global motion perception. Journal of Vision, 14(12), 30\u201330. http://doi.org/10.1167/14.12.30 ( pdf ) 114 Kersten D. & Yuille, A.L.(2013) Vision: Bayesian Inference and Beyond. The New Visual Neurosciences. John S. Werner and Leo M. Chalupa (Editors) MIT Press. Cambridge MA. ( book pdf) ( MIT press link ) 113 Qiu, Cheng, Kersten D., Olman, C.A. (2013) Segmentation decreases the magnitude of the tilt illusion. Journal of Vision, 13(13): 19, 1-17; doi:10.1167/13.13.19. (pdf ) 112 Kersten D., Shakespeare R., and Thompson W. (2013). Predicting Visibility in Designs of Public Spaces. University of Utah Computer Sciences Technical Report. UUCS 13-001 ( pdf ). 111 Mannion, D. J., Kersten, D. J., & Olman, C. A. (2013). Consequences of polar form coherence for fMRI responses in human visual cortex. NeuroImage, 78(C), 152\u2013158. doi:10.1016/j.neuroimage.2013.04.036 (link) 110 McMenamin, B. W., Radue, J., Trask, J., Huskamp, K., Kersten, D., & Marsolek, C. J. (2012). The diagnosticity of color for emotional objects. Motivation and Emotion. doi:10.1007/s11031-012-9319-0 ( link ) 109 He, D., Kersten, D., & Fang, F. (2012). Opposite modulation of high- and low-level visual aftereffects by perceptual grouping. Current biology : CB, 22(11), 1040\u20131045. doi:10.1016/j.cub.2012.04.026 ( link ) 108 Hegd\u00e9, J., Thompson, S., Brady, M., & Kersten, D. (2012). Object Recognition in Clutter: Cortical Responses Depend on the Type of Learning. Frontiers in Human Neuroscience. doi:10.3389/fnhum.2012.00170/abstract (pdf) 107 Hauffen, K., Bart, E., Brady, M., Kersten, D., & Hegd\u00e9, J. (2012). Creating Objects and Object Categories for Studying Perception and Perceptual Learning. Journal of Visualized Experiments, (69). doi:10.3791/3358 (link ) 106 Doerschner, K., Fleming, R. W., Yilmaz, O., Schrater, P. R., Hartung, B., & Kersten, D. (2011). Visual Motion and the Perception of Surface Material. Current Biology, 21(23), 2010\u20132016. doi:10.1016/j.cub.2011.10.036 ( link ) 105 Battaglia P, Kersten D, Schrater PR (2011) How Haptic Size Sensations Improve Distance Perception. PLoS Comput Biol 7(6): e1002080. doi:10.1371/journal.pcbi.1002080 (pdf ) 104 Doerschner, K., Kersten, D., & Schrater, P. R. (2011). Rapid classification of specular and diffuse reflection from image velocities. Pattern Recognition, 44(9), 1874\u20131884. doi:10.1016/j.patcog.2010.09.007 ( pdf ) 103 Boyaci, H., Fang, F., Murray, S. O., & Kersten, D. (2010). Perceptual grouping-dependent lightness processing in human early visual cortex. Journal of Vision, 10(9). http://jwww.journalofvision.org/content/10/9/4.full 102 Green, C. S., Benson, C., Kersten, D., & Schrater, P. (2010). Alterations in choice behavior by manipulations of world model. Proceedings of the National Academy of Sciences, 107(37), 16401-16406.( pdf ) 101 Hegde, J., & Kersten, D. (2010). A link between visual disambiguation and visual memory. J Neurosci, 30(45), 15124-15133. (pdf ) 100 Battaglia P., Kersten D., & Schrater P (2011) The role of generative knowledge in object perception. Sensory Cue Integration, Trommersh\u00e4user, Landy, & K\u00f6rding, (Eds). Oxford University Press. ( amazon.com ) 99 Battaglia, P. W., Di Luca, M., Ernst, M. O., Schrater, P. R., Machulla, T., & Kersten, D. (2010). Within- and cross-modal distance information disambiguate visual size-change perception. PLoS Comput Biol, 6(3), e1000697. 98 Kersten, D., & Murray, S. O. (2010). Vision: when does looking bigger mean seeing better? Curr Biol, 20(9), R398-399. 96 Gold JM , Abbey C , Tjan BS , and Kersten D (2009) Ideal Observers and Efficiency: Commemorating 50 Years of Tanner and Birdsall: Introduction. JOSA A, Vol. 26, Issue 11, pp. IO1-IO2 doi:10.1364/JOSAA.26.000IO1 95 Doerschner K, Kersten D, & Schrater P. (2009) Rapid Classification of Surface Reflectance from Image Velocities. Computer Analysis of Images and Patterns, Lecture Notes in Computer Science, Springer Berlin / Heidelberg, volume 5702, pp. 856-864. 94 Fang, F., Boyaci, H., & Kersten, D. (2009). Border ownership selectivity in human early visual cortex and its modulation by attention. J Neurosci, 29(2), 460-465. ( link ) 93 Kersten, D & Mamassian, P (2009) Ideal Observer Theory. In: Squire LR (ed.) Encyclopedia of Neuroscience, volume 5, pp. 89-95. Oxford: Academic Press. pdf preprint 92 Fang, F., Boyaci, H., Kersten, D., & Murray, S. O. (2008). Attention-dependent representation of a size illusion in human V1. Curr Biol, 18(21), 1707-1712. pdf 91 Hegde, J., Bart, E., & Kersten, D. (2008). Fragment-Based Learning of Visual Object Categories. Curr Biol. 18, 597-601. http://download.current-biology.com/pdfs/0960-9822/PIIS096098220800448X.pdf 90 Fang F, Kersten & Murray SO (2008) Perceptual grouping and inverse fMRI activity patterns in human visual cortex. Journal of Vision, 8(7):2, 1-9, http://journalofvision.org/8/7/2/, doi:10.1167/8.7.2.( pdf ) 89 Hegd\u00e9 J, Fang F, Murray SO & Kersten D (2008) Preferential responses to occluded objects in the human visual cortex. Journal of Vision. 8 (4), 1-16. http://journalofvision.org/8/4/16/ ( pdf ) 88 Boyaci, H., Fang, F., Murray, S. O., & Kersten, D. (2007). Responses to lightness variations in early human visual cortex. Curr Biol, 17(11), 989-993. ( pdf ) 87 Yuille, A., & Kersten, D. (2006). Vision as Bayesian inference: analysis by synthesis? Trends Cogn Sci, 10(7), 301-308. (pub med pdf ) ( pdf ) 86 Murray, S. O., Boyaci, H., & Kersten, D. (2006). The representation of perceived angular size in human primary visual cortex. Nature Neuroscience. Online : 05 February 2006 | doi:10.1038/nn1641 85 Murray, S. O., Olman, C. A., & Kersten, D. (2006). Spatially specific fMRI repetition effects in human visual cortex. Journal of Neurophysiology. ( journal link pdf ) 84 Battaglia, P. W., Schrater, P., & Kersten, D. (2005). Auxiliary object knowledge influences visually-guided interception behavior. Paper presented at the Symposium on Applied Perception, Graphics and Visualization, A Coru\u00f1a, Spain. August 26-28. ( pdf ) 83 Fang, F., Murray, S. O., Kersten, D. J., & He, S. (2005). Orientation-tuned fMRI adaptation in human visual cortex. J Neurophysiol. 94: 4188 - 4195 ( journal link pdf ) 82 Hartung, B., P. Schrater, H. B\u00fclthoff, D. Kersten and V. Franz (2005): Is prior knowledge of object geometry used in visually guided reaching? Journal of Vision 5(6), 504-514. ( pdf ) 81 Murray, S. O., Schrater, P., & Kersten, D. (2004). Perceptual grouping and the interactions between visual cortical areas. Neural Netw, 17(5-6), 695-705. (pdf ) 80 Olman, C. A., & Kersten, D. (2004). Classification objects, ideal observers & generative models. Cognitive Science, 28, 227-239.( pdf ) 79 Yuille, A. L., Fang, F., Schrater, P., & Kersten, D. (2004). Human and Ideal Observers for Detecting Image Curves. In S. Thrun, L. Saul & B. Schoelkopf (Eds.), Advances in Neural Information Processing Systems 16. Cambridge, MA: MIT Press.( pdf ) 78 Olman, C., Ugurbil, K., Schrater, P., & Kersten, D. (2004). BOLD fMRI and psychophysical measurements of contrast response to broadband images. Vision Research, 44(7), 669-683.( pdf ) 77 Knill, D. C., & Kersten, D. (2004). Visuomotor sensitivity to visual information about surface orientation. J Neurophysiol, 91(3), 1350-1366. ( journal link ) (pdf preprint ) 76 Kersten, D., Mamassian, P., & Yuille, A. (2004). Object perception as Bayesian Inference. Annual Review of Psychology, 55, 271-304. ( Annual Reviews html and pdf link ) ( local pdf ) 75 Liu, Z., & Kersten, D. (2003). Three-dimensional symmetric shapes are discriminated more efficiently than asymmetric ones. J Opt Soc Am A Opt Image Sci Vis, 20(7), 1331-1340. ( preprint ) 74 Brady, M. J., & Kersten, D. (2003). Bootstrapped learning of novel objects. J Vis, 3(6), 413-422.( pdf ) (http://journalofvision.org//3/6/2/) . 73 Kersten, D., & Yuille, A. (2003). Bayesian models of object perception. Current Opinion in Neurobiology, 13(2). ( pdf ) 72 Naor-Raz, G., Tarr, M. J., & Kersten, D. (2003). Is color an intrinsic property of object representation? Perception, 32(6), 667-680. ( pdf ) **71**Murray, S. O., Kersten, D., Olshausen, B. A., Schrater, P., & Woods, D. L. (2002). Shape perception reduces activity in human primary visual cortex. Proc Natl Acad Sci U S A, 99, 15164-15169. ( pdf ) 70 Kersten, D. (2002) Object perception: Generative Image Models and Bayesian Inference. In Biologically Motivated Computer Vision. Second International Workshop, BMCV 2002, T\u00fcbingen, Germany, November, 2002. Proceedings. H.H. B\u00fclthoff, S.-W. Lee, T.A. Poggio, C. Wallraven (Eds.). Lecture Notes in Computer Science 2525. Springer. ( pdf ) 69 Wilson S. Geisler and Daniel Kersten (2002) Illusions, perception and Bayes.Nature Neuroscience, 5 (6), 508-510. ( pdf ) 68 Schrater, P. & Kersten, D. (2002). Vision, Psychophysics, and Bayes. In R. P. N. Rao, B. A. Olshausen, & M. S. Lewicki (Ed.), Statistical Theories of the Brain. Cambridge, Massachusetts: MIT Press.( pdf ) 67 Schrater P. R., Khuu T., & Kersten D. (unpublished manuscript) Noise Induced Perceptual Completion. ( pdf) 66 d'Avossa, G., & Kersten, D. Invariant spatial transformations of the optic flow for heading estimation. 65 Madison, C., Thompson, W., Kersten, D., Shirley, P. & Smits, B. (2001). Use of interreflection and shadow for surface contact. Perception and Psychophysics, 63, 187-194. 64 Schrater, P. R. & Kersten, D. (2000). How optimal depth cue integration depends on the task. International Journal of Computer Vision, 40, 73-91. ( draft pdf ) 63 Bloj, M., Kersten, D., & Hurlbert, A. C. (1999). 3D Shape Perception Influences Colour Perception via Mutual Illumination. Nature . ( pdf ). See too: Gegenfurtner's news & views ( pdf ). 62 Kersten, D. & Schrater, P. R., (2002). Pattern Inference Theory: A Probabilistic Approach to Vision. In R. Mausfeld, & D. Heyer (Ed.), Perception and the Physical World. Chichester: John Wiley & Sons, Ltd. ( Draft pdf ) ( postscript ) 61 Schrater, P. R., & Kersten, D. (1999). Statistical structure and task dependence in visual cue integration. Submitted to: Workshop on Statistical and Computational Theories of Vision -- Modeling, Learning, Computing, and Sampling. Fort Collins, Colorado, June 1999. ( pdf ) 60 Troje, N. F. and Kersten, D. (1999) Viewpoint dependent recognition of familiar faces. Perception ., 28, (4), 483 - 487. ( pdf preprint ) 59 d'Avossa, G., Yacoub, E., Kersten D., Xioaping, H. Direction dependent occipital and parietal activity during the perception of optic flows simulating eccentric headings. Draft PDF 58 Kersten, D. (1998) Computational Vision: Principles of Perceptual Inference. Notes for Neural Information Processing Tutorial , Denver, CO, December. (Tutorial Notes PDF) (Bibliography) (Yuille, Coughlan, Kersten ) 57 Braje, W. L., Legge, G. E. & Kersten, D. (2000). Invariant recognition of natural objects in the presence of shadows. Perception, 29, 383-98. (earlier version: pre-print PDF ) 56 Mamassian, P., Knill, D.C. & Kersten, D. (1998) The Perception of Cast Shadows. Trends in Cognitive Sciences. 2 (8), 288-295. ( pdf ) 55 Kersten, D. High-level vision as statistical inference. (1999) ( pdf preprint ) The New Cognitive Neurosciences , 2 nd Edition, Gazzaniga (Ed.). MIT Press. 54 Braje, W.L., Kersten, D., Tarr, M.J. and Troje, N.F. Illumination effects in face recognition. (1998) Psychobiology . 26 (4), 371-380. ( pdf preprint ) 53 Liu, Z., Kersten, D. And Knill, D.C. (1999) Stimulus information or internal representation?--a case study in human object recognition. Vision Research . 39, 603-612. ( pdf ) 52 Liu, Z. and Kersten, D. (1998) 2D Observers in 3D Object Recognition? Vision Research ., 38 , 2507-2519. ( pdf ) 51 Liu, Z. and Kersten, D. (1998) 2D Affine Transformations are Unlikely to Account for Human 3D Object Recognition. Proceedings of the International Conference on Computer Vision (ICCV 98). 50 Liu, Z. and Kersten, D. (1998) 2D Observers in 3D Object Recognition? Advances in Neural Information Processing Systems 10. MIT Press, Cambridge, Massachusetts. PDF 49 Thompson, W.B., Shirley, P., Smits, B., Kersten, D. J., Madison, C. (1998) . Visual glue. University of Utah Technical Report UUCS-98-007. ( pdf ) or http://www.cs.utah.edu/vissim/papers/glue2/glue.pdf 48 Troje, N. F. and Kersten, D. (1998) Viewer-centered recognition of familiar faces. Max Planck Institute for Biological Cybernetics , Technical Report No. 55. Work also appears in Perception (60, above). 47 Kersten, D. (1997) Perceptual categories for spatial layout. The Philosophical Transactions of the Royal Society . B , 352 (1358), 1155-1163. PDF **46**Tarr, M. J., Kersten, D., & B\u00fclthoff, H. H. (1998). Why the visual system might encode the effects of illumination. Vision Research , 38 , 2259-2275. ( pdf ) 45 Knill, D. C., Mamassian, P. & Kersten, D. (1997) The geometry of shadows Journal of the Optical Society of America A . 14 (12), 3216 - 3232. 44 Kersten, D. (1997). Inverse 3-D graphics: A metaphor for visual perception. Behavior Research Methods, Instruments, and Computers ., 29 , 37-46. (pdf) 43 Kersten, D., Troje, N. F. & B\u00fclthoff, H. H. Phenomenal competition for poses of the human head. Perception , 25 (1996), 367. (pdf ) 42 Kersten, D., Mamassian, P. & Knill, D.C. (1997) Moving cast shadows induce apparent motion in depth. Perception ., 26 (2), 171-192 ( pdf) ( pdf pre-print ). 41 Liu, Z., Kersten D. & Knill, D.C. Structural organization improves object discrimination. (Manuscript, see 53 above for journal publication) 40 d'Avossa, G., & Kersten, D. (1996). Evidence in human subjects for independent coding of azimuth and elevation for direction of heading from optic flow. Vision Research , 36 (18), 2915-2924. ( pdf) 39 Kersten, D., Knill, D. C., Mamassian, P. and B\u00fclthoff, I. (1996) Illusory motion from shadows. Nature ., 279 , (6560), 31. ( pdf) 38 Mamassian P & Kersten D. (1996) Illumination, shading and the perception of orientation. Vision Research ., 36 , 2351-2367. 37 Mamassian, P., Kersten, D.; Knill, D. C. Categorical Local Shape Perception. Perception , 25 (1996), 95-107. PDF 36 Knill D. C. , Kersten D. & Mamassian, P. (1996) The Bayesian framework for visual information processing: Implications for Psychophysics. Chap. 6. In: Perception as Bayesian Inference . David C. Knill and Whitman Richards (eds). Cambridge University Press. 35 Knill D.C., Kersten D. and Yuille A. (1996) A Bayesian formulation of visual perception. Chap. 0. In: Perception as Bayesian Inference. David C. Knill and Whitman Richards (eds). Cambridge University Press. 34 Kersten, D. (1996) Veridicality, utility, and completeness in vision modeling: A commentary on \"Bayesian Decision Theory and Psychophysics\" In: Perception as Bayesian Inference . David C. Knill and Whitman Richards (eds). Cambridge University Press. 33 Kersten, D. (1996) Commentary on: Pattern Theory: A Unifying Perspective. In: Perception as Bayesian Inference . David C. Knill and Whitman Richards (eds). Cambridge University Press. 32 Tjan B., Braje, W., Legge, G.E. & Kersten, D. (1995) Human efficiency for recognizing 3-D objects in luminance noise. Vision Research , 35 , 3053-3069. 31 Mamassian P., B\u00fclthoff H.H. & Kersten D. (1995) Eye-hand coordination for 3-D oriented objects. Max Planck Institute for Biological Cybernetics, Technical Report 12 . http://mpik-tueb.mpg.de:4711/projects/TechReport/list.html 30 Kersten, D. & Madarasmi, S. (1995) The Visual Perception of Surfaces, their Properties, and Relationships. In Partitioning Data Sets: With applications to psychology, vision and TARGET tracking , Edited by I. J. Cox, P. Hansen and B. Julesz, AMS. 29 Liu, Z., Knill, D. C., & Kersten, D. (1995). Object Classification for Human and Ideal Observers. Vision Research , 35 , 549-568. ( pdf ) 28 Kersten D., Mamassian P., Knill D.C. (1994) Moving cast shadows and the perception of relative depth. Max Planck Institute for Biological Cybernetics, Technical Report 6 . ( pdf ) 27.5 Madarasmi, S., Pong, T.-C., & Kersten, D. (1994). Illusory contour detection using MRF models (Vol. 7, pp. 4343\u20134348). Presented at the Neural Networks, 1994. IEEE World Congress on Computational Intelligenc., IEEE.( pdf ) 27 Madarasmi S., Pong T.C. & Kersten D. (1993) An energy minimization approach to surface segmentation using a multi-layer representation. Army High Performance Computing Research Center, Preprint 93-083. 26 Knill, D. C., Mamassian, P. & Kersten, D. (1993) The geometry of shadows . University of Minnesota. Computer and Information Sciences, TR 93-47. 25 Madarasmi S., Kersten, D., & Pong, T.C. (1993) Multi-layer surface segmentation using energy minimization. IEEE Computer Vision & Pattern Recognition. 774-775. (abstract ) ( pdf ) 24 Madarasmi, S., Kersten, D., & Pong, T. C. (1993). The computation of stereo disparity for transparent and for opaque surfaces. In C. L. Giles, S. J. Hanson, & J. D. Cowan (Ed.), Advances in Neural Information Processing Systems 5. San Mateo, CA: Morgan Kaufmann Publishers. pp. 385-392. 23 Madarasmi, S., Kersten, D., & Pong, T. C. (1993). The computation of stereo disparity for transparent and for opaque surfaces. Army High Performance Computing Research Center, Preprint 93-084. (URL: http://www.arc.umn.edu/publications/preprints/abstracts93.html#93-084) 22 Kersten, D., B\u00fclthoff, H. H., Schwartz, B., & Kurtz, K. (1992) Interaction between transparency and structure from motion. Neural Computation , 4 , 573-589. ( pdf ) 21 O'Toole A. J. and Kersten, D. (1992) Learning to see random-dot stereograms. Perception , 21 , 227-243. ( pdf ) 20 Thompson, W. B., Kersten, D., & Knecht, W. R. (1992) Structure-from-motion based on information at surface boundaries. Biological Cybernetics , 66 , 327-333. 19 Levin, S. A., Guckenheimer, J., Kersten, D., Kingsbury, D. T., Mangel, M., Reed, M., & Silk, W. (Eds.) (1992). Mathematics and Biology: The Interface, Challenges, and Opportunities. Berkeley, California: Lawrence Berkeley Laboratory. 18 Kersten, D. (1991) Transparency and the cooperative computation of scene attributes. Computational Models of Visual Processing , M.I.T. Press, Landy M and Movshon A., Eds.. 17 Kersten, D. and B\u00fclthoff, H. (1991) Transparency affects perception of structure from motion. Massachusetts Institute of Technology, Center for Biological Information Processing Tech. Memo , 36 . 16 Knill, D.C. and Kersten, D. (1991) Ideal Perceptual Observers for Computation, Ps>chophysics, and Neural Networks. Vision and Visual Dysfunction , Cronly-Dillon, Gen. Editor, Vol. 14 , Roger Watt Editor, MacMillan Press. 15 Knill, D. C., & Kersten, D. (1991) Apparent surface curvature affects lightness perception. Nature , 351 , 228-229. ( pdf 1.1Mb) 14 Knill D.C., Field, D. and Kersten, D. (1990) Human discrimination of fractal images. Journal of the Optical Society of America , A, 7 , 1113-1123. (pdf ) 13 Knill, D. C. and Kersten, D. (1990) Learning a near-optimal estimator for surface shape from shading. Computer Vision, Graphics and Image Processing , 50 , 75-100. ( pdf ) 12 Kersten, D. Statistical limits to image understanding. (1990) Vision: Coding and Efficiency, (Blakemore, C. ed.), Cambridge University Press, chapter 3, pp. 32-44. 11 Sereno M.E., Kersten D. and Anderson J. A. (1989) A neural network model of an aspect of motion perception. Science at the John von Neumann National Supercomputer Center: Annual Research Report--1988 , pp. 165-170 10 Kersten, D., Hess, R.F. and Plant, G.T. (1988) Assessing contrast sensitivity behind cloudy media. Clinical Vision Sciences , 2 , 143-158. ( pdf ) 9 Kersten, D., O'Toole A., Sereno, M., Knill D., Anderson, J.A. (1987) Associative learning of scene parameters from images. Applied Optics , 26 , 4999-5006. (pdf ) 8 Kersten, D. Predictability and redundancy of natural images. (1987) Journal of the Optical Society of America A, 4 , 2395-2400. Reprinted in: Image Compression, Rabbani, M. (Ed.), SPIE-The International Society for Optical Engineering. 1992. ( pdf ) 7 Legge, G.E. & Kersten, D. (1987) Contrast discrimination in peripheral vision. Journal of the Optical Society of America A, 4 , 1594-1598. 6 Legge, G.E., Kersten, D. and Burgess, A.E. (1987) Contrast discrimination in noise. Journal of the Optical Society of America A , 4 , 391-404. 5 Kersten, D. Statistical efficiency for the detection of visual noise. (1987) Vision Research , 27 , 1029-1040. ( pdf ) 4 Kersten, D. Spatial summation in visual noise. (1984) Vision Research , 24 , 1977-1990. ( pdf ) 3 Burkhardt, D.A., Gottesman, J., Kersten, D. and Legge, G.E. (1984) Symmetry and constancy in the perception of negative and positive luminance contrast. Journal of the Optical Society of America A , 1 , 309-316. 2 Legge, G.E. and Kersten, D. (1983) Light and dark bars: contrast discrimination. Vision Research , 5 , 473-483. 1 Kersten, D. and Legge, G.E. (1983) Convergence accommodation. Journal of the Optical Society of America , 73 , 332-338. ( pdf ) 0 Kersten, D. (1983) A Comparison of Human and Ideal Performance for the Detection of Visual Pattern. Ph.D. Thesis, University of Minnesota. Minneapolis, Minnesota. Introduction (pdf, 560K) , Chapter 3: Spatial Frequency Summation in Visual Noise (pdf, 2.5M), Chapter 4 Aspects of Phase in Visual Detection (pdf, 3.6M) .","title":"Publications"},{"location":"research/","text":"Research \u00b6 Bayesian models of vision \u00b6 Analysis-by-synthesis \u00b6 Signatures of \u00b6 Object recognition \u00b6 Intermediate-level vision \u00b6 Cooperative computation & explaining away \u00b6 Material perception \u00b6","title":"Research"},{"location":"research/#research","text":"","title":"Research"},{"location":"research/#bayesian-models-of-vision","text":"","title":"Bayesian models of vision"},{"location":"research/#analysis-by-synthesis","text":"","title":"Analysis-by-synthesis"},{"location":"research/#signatures-of","text":"","title":"Signatures of"},{"location":"research/#object-recognition","text":"","title":"Object recognition"},{"location":"research/#intermediate-level-vision","text":"","title":"Intermediate-level vision"},{"location":"research/#cooperative-computation-explaining-away","text":"","title":"Cooperative computation &amp; explaining away"},{"location":"research/#material-perception","text":"","title":"Material perception"},{"location":"courses/PSY5036F2017/","text":"Computational Vision \u00b6 courses.kersten.org Psychology Department , University of Minnesota Psy 5036W, Fall 2017, 3 credits #34359 08:15 A.M. - 9:30 A.M. Mondays and Wednesdays Elliott Hall N668 Instructor : Daniel Kersten. Office : S212 Elliott Hall. Phone : 612 625-2589 email : kersten@umn.edu Office hours : Mondays 9:30-10:30 am or by appointment. The visual perception of what is in the world is accomplished continually, instantaneously, and usually without conscious thought. The very effortlessness of perception disguises the underlying richness of the problem. We can gain insight into the processes and functions of human vision by studying the relationship between neural mechanisms and visual behavior through computer analysis and simulation. Students will learn about the anatomy and neurophysiology of vision and how they relate to the phenomona of perception. An underlying theme will be to treat vision as a process of statistical inference. There will be in-class programming exercises using the language Mathematica. No prior programming experience is required; however, some familiarity with probability, vector calculus and linear algebra is helpful. Readings \u00b6 Main \u00b6 Lecture notes, Main Readings & Supplementary Material are online. Additional readings \u00b6 Math and vision \u00b6 ( EV ) Early Vision. Yuille and Kersten. In From Neuron to Cognition via Computational Neuroscience , M.A. Arbib, James J. Bonaiuto Editors, Cambridge MA: The MIT Press. Understanding Vision: Theory, Models, and Data. Li Zhaoping. 2014.( publisher page ) ( author's web outline ) Functional human vision \u00b6 ( FV ) Foundations of Vision . Wandell ( web ) Neurophysiology \u00b6 ( NVN ) The New Visual Neurosciences . John S. Werner and Leo M. Chalupa, edts. 2014. Software \u00b6 Mathematica \u00b6 Mathematica is the primary programming environment for this course. Students who have registered for the course will have Google Docs access through the Psychology Department's site license. Alternatives: Mathematica is available in several labs on campus, go to http://www.oit.umn.edu/computer-labs/software/index.htm You may wish to purchase Mathematica for Students see http://www.wolfram.com/products/student/mathforstudents/index.html . You can also access Mathematica on the CLA servers: mac (Note: you may have to change the forward slash to a back slash) windows If you never programmed before go here . If you have programming experience, go here . For user help on using Mathematica, see: http://mathematica.stackexchange.com Python/IPython \u00b6 http://ipython.org http://jupyter-notebook-beginner-guide.readthedocs.org/en/latest/index.html http://www.scipy.org For an online course in using Python and PsychoPy for research in human vision see: http://nbviewer.ipython.org/github/gestaltrevision/python_for_visres/blob/master/index.ipynb Writing \u00b6 Gopen, G. D., & Swan, J. A., 1990. The Science of Scientific Writing. American Scientist , 78 , 550-558. Supplementary: The Sense of Style: The Thinking Person's Guide to Writing in the 21 st Century (2014), Pinker, Steven. ( amazon link ) Penrose, A. M., & Katz, S. B. (1998). Writing in the Sciences: Exploring Conventions of Scientific Discourse . New York: St. Martin's Press, Inc. American Psychological Association. (2009). Publication manual of the American Psychological Association (6 th ed.). Washington, DC: American Psychological Association Writing assistance. THE CENTER FOR WRITING offers free one-to-one writing assistance to undergraduate and graduate students, with appointments up to 45 minutes. Nonnative speaker specialists are available. For more information, see http://writing.umn.edu . Psychology department resources: http://writing.psych.umn.edu/student-resources **Grade Requirements ** There will be programming assignments and a final project . The grade weights are: Exercise/programming assignments: 55% Final project presentations: 5 % Final project : 40% (four parts: 2%+5%+5%+28%) The programming assignments will use the Mathematica programming environment. No prior experience with Mathematica is necessary. Assignment due By the midnight on the day due. _** Late Policy : Assignments turned in within 24 hours following the due date will have 15% deducted from the assignment score. Assignments turned in between 24 and 48 hours following the due date will have 30% deducted from the score. Assignments more than 48 hours late will receive a score of zero.**_ Lectures \u00b6 Check this section before each class for recent additions and revisions. (5036W Course material from 2015) Lecture notes are in Mathematica Notebook and pdf format. You can download the Mathematica notebook files below to view with Mathematica or Wolfram CDF Player (which is free). [University Calendar](http://onestop.umn.edu/onestop/calendar.html) **Date** **Lecture** _**Main Readings**_ **Supplementary Material** **Assignments due** **I. Introduction** Sep 6 1\\. Introduction to Computational Vision _[1.IntroToComputationalVision.nb](Lectures/1_MultidisciplinaryStudy/1.IntroToComputationalVision.nb) ([pdf](Lectures/1_MultidisciplinaryStudy/1.IntroToComputationalVision.nb.pdf))_ Olshausen, B. A. (2013). Perception as an Inference Problem. In M. Gazzaniga (Ed.), The New Cognitive Neurosciences, 5th Edition (pp. 1\u00e2\u20ac\u201c22). MIT Press. (pp. 1\u00e2\u20ac\u201c18). MIT Press. ([pdf](../../coursepapers/Olshausen2013Perception_as_an_Inference_Problem.pdf)) Screencast: [http://www.wolfram.com/broadcast/screencasts/handsonstart/](http://www.wolfram.com/broadcast/screencasts/handsonstart/) (WITH AUDIO)[ ](Lectures/1_MultidisciplinaryStudy/FoxApertures2.mov)Check out demos under: **Life Sciences/Cognitive Science/Perception** and **Engineering & Technology/Image Processing** on the Mathematica Demonstrations site: [http://demonstrations.wolfram.com/](http://demonstrations.wolfram.com/) _Kersten, D., & Yuille, A. (2003). Bayesian models of object perception. Current Opinion in Neurobiology, 13(2), 1-9\\. ([pdf](../../coursepapers/KerstenYuilleCurrOpinNeu2003.pdf))_ [EV: Section 1](../../papers/YuilleKerstenFinalChapter2016.pdf) Sep 11 2.Limits to Vision _[2.LimitsToVision.nb](Lectures/2_Limits to Vision/2_LimitsToVision.nb) [(pdf)](Lectures/2_Limits to Vision/2_LimitsToVision.nb.pdf)__ Hecht, S., Shlaer, S., & Pirenne, M. H. (1942). Energy, quanta, and vision. Journal of General Physiology, 25, 819-840\\. ([pdf](../../coursepapers/hecht+al_42.pdf))_ Barlow, H. B. (1981). Critical Limiting Factors in the Design of the Eye and Visual Cortex. Proc. Roy. Soc. Lond. B, 212, 1-34\\. ([pdf](../../coursepapers/barlow_81.pdf)) Baylor, D. A., Lamb, T. D., & Yau, K. W. (1979). Responses of retinal rods to single photons. Journal of Physiology, Lond., 288, 613-634\\. ([pdf](../../coursepapers/baylor+al_79b.pdf)) Tinsley, J. N., Molodtsov, M. I., Prevedel, R., Wartmann, D., Pons, J. E. E., Lauwers, M., & Vaziri, A. (2016). Direct detection of a single photon by humans. Nature Communications, 7, 1\u20139\\. [http://doi.org/10.1038/ncomms12172](http://doi.org/10.1038/ncomms12172) ([pdf)](../../coursepapers/Tinsley16.pdf) Sep 13 3\\. The Ideal Observer _[3.TheIdealObserver.nb](Lectures/3_TheIdealObserver/3_TheIdealObserver.nb) [(pdf)](Lectures/3_TheIdealObserver/3_TheIdealObserver.nb.pdf)_ [ProbabilityOverview.nb](Lectures/3_TheIdealObserver/ProbabilityOverview2017.nb) [(pdf)](Lectures/3_TheIdealObserver/ProbabilityOverview2017.nb.pdf) Griffiths, T. L., & Yuille, A. (2008). A primer on probabilistic inference. In M. Oaksford and N. Chater (Eds.). The probabilistic mind: Prospects for rational models of cognition. Oxford: Oxford University Press [(pdf](../../coursepapers/GriffithsYuilleProbPrimerTICsmmc1.pdf)). Try your luck against an ideal discriminator of dot density [YesNoDotDiscriminationDemo.nb](Lectures/3_TheIdealObserver/YesNoDotDiscriminationDemo.nb) Upload Assignment #1 to [Moodle ](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Assignment_1_Mathematica.nb](Grading, Exercises & Exams/Assignments_due/Problem_Set_1.nb) Sep 18 4\\. Ideal observer analysis: Humans vs. ideals. Neurons vs. ideals _[4.IdealObserverAnalysis.nb](Lectures/4_Ideal Observer Analysis/4_IdealObserverAnalysis.nb)_ ([pdf](Lectures/4_Ideal Observer Analysis/4_IdealObserverAnalysis.nb.pdf)) Kersten and Mamassian (2008), Ideal observer theory. The New Encyclopedia of Neuroscience, Squire et al., editors ([pdf](../../coursepapers/KerstenMamassian2009IdealObsTheory.pdf)). Geisler, W. S. (2011). Contributions of ideal observer theory to vision research. Vision Research, 51(7), 771\u2013781.[(pdf)](../../coursepapers/Geisler2011Contributions_of_ideal_observer_theory_to_vision_research.pdf) Burgess, A. E., Wagner, R. F., Jennings, R. J., & Barlow, H. B. (1981)_. Efficiency of human visual signal discrimination. Science, 214(4516), 93-94. [(pdf)](../../coursepapers/BurgessScience1981.pdf)_ Deneve, S., Latham, P. E., & Pouget, A. (1999). Reading population codes: a neural implementation of ideal observers. Nature Neuroscience, 2(8), 740\u2013745\\. [(pdf)](../../coursepapers/Deneve1999Reading_population_codes_a_neural_implementation_of_ideal_observers.pdf) Measure your absolute efficiency to discriminate dot density using a 2AFC task [2AFCDotDiscriminationDemo.nb](Lectures/4_Ideal%20Observer%20Analysis/2AFCDotDiscriminationDemo.nb) **II. Image formation, pattern synthesis** Sep 20 5.Psychophysics: tools & techniques _[5.Psychophysics.nb](Lectures/5_PsychophysicsSKEobserver/5_Psychophysics.nb)[](Lectures/5_PsychophysicsSKEobserver/5_Psychophysics.nb) [(pdf)](Lectures/5_PsychophysicsSKEobserver/5_Psychophysics.nb.pdf) _ [SKEDetection2AFCInLineDisplay.nb](Lectures/5_PsychophysicsSKEobserver/SKEDetection2AFCInLineDisplay.nb) Farell, B. & Pelli, D. G. (1999) Psychophysical methods, or how to measure a threshold and why. In R. H. S. Carpenter & J. G. Robson (Eds.), Vision Research: A Practical Guide to Laboratory Methods, New York: Oxford University ([pdf](../../coursepapers/farell1999chapter.pdf)) Press.http://psych.nyu.edu/pelli/ Morgenstern, Y., & Elder, J. H. (2012). Local Visual Energy Mechanisms Revealed by Detection of Global Patterns. Journal of Neuroscience, 32(11), 3679\u20133696\\. For a free Matlab psychophysics package, see: [http://psychotoolbox.org](http://psychtoolbox.org/) For a free Python psychophysics package, see: [http://www.psychopy.org](http://www.psychopy.org) Sep 25 6\\. Bayesian decision theory & perception _[6.BayesDecisionTheory.nb](Lectures/6_BayesDecisionTheory/6_BayesDecisionTheory.nb.pdf) [(pdf)](Lectures/6_BayesDecisionTheory/6_BayesDecisionTheory.nb.pdf)_ _Geisler, W. S., & Kersten, D. (2002). Illusions, perception and Bayes. Nat Neurosci, 5(6), 508-510\\. ([pdf](http://gandalf.psych.umn.edu/%7Ekersten/kersten-lab/papers/GeislerKerstennn0602-508.pdf))_ [EV Section 3](../../coursepapers/YuilleKerstenFinalChapter2016.pdf#3) Sep 27 7\\. Limits to spatial resolution, image modeling, introduction to linear systems _[7.ImageModelLinearSystems.nb](Lectures/7.ImageModelingLinearSystems/7.ImageModelLinearSystems.nb) [(pdf)](Lectures/7.ImageModelingLinearSystems/7.ImageModelLinearSystems.nb.pdf)_ _Campbell, F. W., & Green, D. (1965). Optical and retinal factors affecting visual resolution. Journal of Physiology (Lond.), 181, 576-593\\. ([pdf](../../coursepapers/CampbellGreen_JP1965.pdf))_ Williams, D. R. (1986). Seeing through the photoreceptor mosaic. 9(5), 193-197\\. ([pdf](../../coursepapers/williams86.pdf)) [LinearAlgebraReview.nb](Lectures/7.ImageModelingLinearSystems/LinearAlgebraReview.nb) [Convolutions_Tutorial.nb](Lectures/7.ImageModelingLinearSystems/Convolutions_Tutorial.nb) [IPython convolutions notebook](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/2a.Convolution.ipynb) Upload Assignment #2 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Problem_Set_2.nb](Grading, Exercises & Exams/Assignments_due/Problem_Set_2.nb) (correction 10/4/17) **III. Early visual coding** Oct 2 8\\. Linear systems analysis _[8.LinearSystemsOptics.nb](Lectures/8\\. Spatial filters/8.LinearSystemsOptics.nb) [(pdf)](Lectures/8\\. Spatial filters/8.LinearSystemsOptics.nb.pdf) _ [EV: Section 2](../../papers/YuilleKerstenFinalChapter2016.pdf) _[CSF.gif](Lectures/8\\. Spatial filters/CSF.gif)_ Tutorials: [Fourier_neural_image.nb](Lectures/8\\. Spatial filters/Fourier_neural_image.nb) Oct 4 9\\. Features and filters. Spatial filter models of early human vision _[9.NeuralSpatialFiltering.nb](Lectures/9\\. Multi-scale analysis/9.NeuralSpatialFiltering.nb) [(pdf)](Lectures/9\\. Multi-scale analysis/9.NeuralSpatialFiltering.nb.pdf)_ Campbell, F. W., & Robson, J. R. (1968). Application of Fourier Analysis to the Visibility of Gratings. Journal of Physiology 197, 551-566\\. ([pdf](../../coursepapers/CampbellRobson_JP1968.pdf)) De Valois, R. L., Albrecht, D. G., & Thorell, L. G. (1982). Spatial frequency selectivity of cells in macaque visual cortex. Vision Res, 22(5), 545-559\\. ([pdf](../../coursepapers/DeValoisAlbrechtThorell1982.pdf)) Watson, A. B. (1987). Efficiency of a model human image code. J Opt Soc Am A, 4(12), 2401-2417\\. ([pdf)](http://vision.arc.nasa.gov/publications/Efficiency.pdf) [IPython demo of gabor filtering](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/2b.Gabor.ipynb) Steerable pyramids: [http://www.cns.nyu.edu/~eero/steerpyr/](http://www.cns.nyu.edu/%7Eeero/steerpyr/) Oct 9 10\\. Features and filters. Local processing & image analysis _[10.ImageProcessing.nb](Lectures/10.ImageManipulations/10.ImageProcessing.nb) [(pdf)](Lectures/10.ImageManipulations/10.ImageProcessing.nb.pdf)_ Gollisch, T., & Meister, M. (2010). Eye Smarter than Scientists Believed: Neural Computations in Circuits of the Retina. Neuron, 65(2), 150\u2013164\\. ([pdf](../../coursepapers/Gollisch2010Eye_Smarter_than_Scientists_Believed_Neural_Computations_in_Circuits_of_the_Retina.pdf)) Albrecht, D. G., De Valois, R. L., & Thorell, L. G. (1980). Visual cortical neurons: are bars or gratings the optimal stimuli? Science, 207(4426), 88-90.[(pdf)](../../coursepapers/AlbrechtDeValoisThorellScience1980.pdf) Adelson, E. H., & Bergen, J. R. (1991). The plenoptic function and the elements of early vision. In M. S. Landy & J. A. Movshon (Eds.), Computational Models of Visual Processing. Cambridge, MA: The MIT Press: A Bradford Book.[(pdf](../../coursepapers/AdelsonBergenPlenopticelements91.pdf)[)](../../coursepapers/adelson-bergen-85.pdf) ClassificationImage demo ([ReverseCorrelation.nb](Reverse%20correlation/ReverseCorrelation.nb)) Ahumada, A. J., Jr. (2002). Classification image weights and internal noise level estimation. J Vis, 2(1), 121-131. ([pdf)](Reverse%20correlation/Ahumada-2002-jov-2-1-8.pdf) Upload Assignment 3 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Problem_Set_3.nb](Grading, Exercises & Exams/Assignments_due/Problem_Set_3.nb) [](Grading,%20Exercises%20&%20Exams/Assignments_due/Assignmt_2_Convolve.nb) Oct 11 11\\. Coding efficiency: Retina _[11.CodingEfficiency.nb](Lectures/11\\. Efficient coding/11.CodingEfficiency.nb) [(pdf)](Lectures/11\\. Efficient coding/11.CodingEfficiency.nb.pdf)_ Geisler, W. S. (2008). Visual perception and the statistical properties of natural scenes. Annu Rev Psychol, 59, 167-192\\. [(pdf)](../../coursepapers/Geisler2008annurev.psych.58.110405.085632.pdf) Laughlin, S. (1981). A simple coding procedure enhances a neuron's information capacity. Z Naturforsch [C], 36(9-10), 910-912.([pdf](../../coursepapers/Laughlin1981.pdf)) Atick, J. J., & Redlich, A. N. (1992). What does the retina know about natural scenes? Neural Computation, 4(2), 196\u2013210\\. Meister, M., & Berry, M. J., 2nd. (1999). The neural code of the retina. Neuron, 22(3), 435-450.[(pdf](../../coursepapers/meister+berry_99.pdf)) Srinivasan, M. V., Laughlin, S. B., & Dubs, A. (1982). Predictive coding: a fresh view of inhibition in the retina. Proc R Soc Lond B Biol Sci, 216(1205), 427-459.([pdf](../../coursepapers/srinivasan+al_82.pdf)) [IPython demo of natural image statistics](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/3a.Natural%20Image%20Statistics.ipynb) Oct 16 12\\. Coding efficiency: Cortex _[12.SpatialCodingEfficiency.nb](Lectures/12\\. Efficent coding Spatial/12.SpatialCodingEfficiency.nb) [(pdf)](Lectures/12\\. Efficent coding Spatial/12.SpatialCodingEfficiency.nb.pdf)_ _Simoncelli, E. P., & Olshausen, B. A. (2001). Natural image statistics and neural representation. Annu Rev Neurosci, 24, 1193-1216.[(pdf](../../coursepapers/SimoncelliOlshausenAnnRev1999.pdf))_ [ContrastNormalizationNotes.nb](Lectures/12\\. Efficent coding Spatial/ContrasNormalizationNotes.nb) Laughlin, S. B., de Ruyter van Steveninck, R. R., & Anderson, J. C. (1998). The metabolic cost of neural information. Nat Neurosci, 1(1), 36-41.([pdf)](../../coursepapers/laughlin+al_98.pdf) Lennie, P. (2003). The cost of cortical computation. Curr Biol, 13(6), 493-497. [(pdf)](../../coursepapers/LennieCurBio2003.pdf) Multi-resolution, image pyramids, and efficient coding: [JepsonFleet2005pyramids_notes.pdf ](../../coursepapers/JepsonFleet2005pyramids_notes.pdf)[AdelsonPyramidRCA84.pdf](../../coursepapers/AdelsonPyramidRCA84.pdf) **IV. Intermediate-level vision, integration, grouping** Oct 18 13\\. Edge detection [13.EdgeDetection.nb](Lectures/13\\. Edges/13.EdgeDetection.nb) [(pdf)](Lectures/13\\. Edges/13.EdgeDetection.nb.pdf) Hubel, D. H., & Wiesel, T. N. (1977). Ferrier lecture. Functional architecture of macaque monkey visual cortex. Proc R Soc Lond B Biol Sci, 198(1130), 1-59\\. [(pdf)](../../coursepapers/HubelWieselFerrier1977.pdf) [IPython demo of statistical edge detection](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/3b.Statistical%20Edge%20Detection.ipynb) Oct 23 14. Objects and scenes from images. The visual cortical pathways and hierarchy. _[14.ScenesfromImages.nb](Lectures/14.Scenes from images/14.ScenesfromImages.nb) [(pdf)](Lectures/14.Scenes from images/14.ScenesfromImages.nb.pdf)__ von der Heydt R (2003) Image parsing mechanisms of the visual cortex. In: The Visual Neurosciences (Werner JS, Chalupa LM, eds.), pp 1139-1150\\. Cambridge, Mass.: MIT press.[(pdf](../../coursepapers/VonderHeydt_ImageParsing_neuroscience.pdf))_ Kersten, D. J., & Yuille, A. L. (2014). Inferential Models of the Visual Cortical Hierarchy. In M. S. Gazzaniga & G. R. Mangun (Eds.), The New Cognitive Neurosciences, 5th Edition (pp. 1\u00e2\u20ac\u201c22). MIT Press. [(pdf)](http://vision.psych.umn.edu/users/kersten//kersten-lab/coursepapers/KerstenYuilleNewCogNeuro2014.pdf) Zhou H, Friedman HS, von der Heydt R (2000) Coding of border ownership in monkey visual cortex. J Neuroscience 20: 6594-6611\\. ([pdf](../../coursepapers/ZhouFriedmanVonDerHeydt_2000_6594.pdf)) Oct 25 15\\. Scene-based generative models _[15.SurfaceGeometryDepth.nb](Lectures/15\\. Surfacegeometrydepth/15.SurfaceGeometryDepth.nb) [(pdf)](Lectures/15\\. Surfacegeometrydepth/15.SurfaceGeometryDepth.nb.pdf)_ _Kersten, D., Mamassian, P., & Yuille, A. (2004). Object perception as Bayesian Inference. Annual Review of Psychology, 55, 271-304\\. ([pdf](../../coursepapers/KerstenMamassianYuille_2004_annurev.psych.55.090902.142005.pdf))_ Oct 30 16\\. Shape-from-X _[16.ShapeFromX.nb](Lectures/16\\. Shape-from-X/16.ShapeFromX.nb) [(pdf)](Lectures/16\\. Shape-from-X/16.ShapeFromX.nb.pdf)_ Reflectance map: Shape from shading: Horn BKP (1986) Robot Vision. Cambridge MA: MIT Press. Ch 11 ([pdf)](../../coursepapers/ch11_Shape_from_Shading.pdf). Barron, J. T., & Malik, J. (2015). Shape, Illumination, and Reflectance from Shading. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(8), 1670\u00e2\u20ac\u201c1687. http://doi.org/10.1109/TPAMI.2014.2377712 [(pdf)](../../coursepapers/BarronMalik2015IEEE_Transactions_on_Pattern_Analysis_and_Machine_Intelligence.pdf) Belhumeur, P. N., Kriegman, D. J., & Yuille, A. (1997). The Bas-Relief Ambiguity. ([pdf](https://pdfs.semanticscholar.org/71ac/0dc7634e4a56fd41dfac270ec5883fcbb44f.pdf)) Johnson, M. K., & Adelson, E. H. (2011). Shape Estimation in Natural Illumination. Computer Vision and Pattern Recognition (CVPR), 2553\u20132560. Muryy, A. A., Welchman, A. E., Blake, A., & Fleming, R. W. (2013). Specular reflections and the estimation of shape from binocular disparity. Proceedings of the National Academy of Sciences of the United States of America, 110(6), 2413\u20132418\\. [(link](http://www.pnas.org/content/110/6/2413.short)) [cube.mov](../../coursepapers/cube.mp4) [random.mov](../../coursepapers/random.mp4) Upload Assignment #4 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Problem_Set_4.nb ](Grading, Exercises & Exams/Assignments_due/Problem_Set_4.nb)[(pdf)](Grading, Exercises & Exams/Assignments_due/Problem_Set_4.nb.pdf) [bluradaptationdemo](../../coursepapers/WebsterGeorgeBlurAdnn906-S1.mp4) [(Webster et al. pdf)](../../coursepapers/WebsterGeorgesonBlurAdaptationnn906.pdf) [motion-induced-blindness demo](../../coursepapers/BasicBonnehYellowDisksBlueDots.gif) [(Bonneh et al. pdf)](../../coursepapers/BonnehCoopemanSagiNature2001411798.pdf) Nov 1 17\\. Shape from shading Overview of python/ipython for computational vision [ ](https://wakari.io/sharing/bundle/kersten/Lect_19Intro_Python) _[17. Shape from shading.nb](Lectures/17.Shape from shading/17.ShapeFromShading.nb)_ [(pdf)](Lectures/17.Shape from shading/17.ShapeFromShading.nb.pdf) [Lect_17Intro_Python.ipynb](Lectures/17_PythonForVision/Lect_17Intro_Python.ipynb) (source) ([pdf](Lectures/17_PythonForVision/Lect_17Intro_Python.pdf)) _[17\\. IPython notebook](http://nbviewer.jupyter.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2017/Lectures/17_PythonForVision/Lect_17Intro_Python.ipynb)_ [Demos](Lectures/17_PythonForVision/Demos/index.html) by Weichao Qiu and Dan Kersten, supplement to _**Early Vision**._ Yuille and Kersten. A chapter in _From Neuron to Cognition via Computational Neuroscience_, M.A. Arbib, James J. Bonaiuto Editors, Cambridge MA: The MIT Press, in 2016 [Anaconda](https://store.continuum.io/cshop/anaconda/) python installation recommended. We will use [Juypter/IPython](http://ipython.org), a browser-based notebook interface for python. See [here](http://nbviewer.ipython.org/github/ipython/ipython/blob/1.x/examples/notebooks/Part%205%20-%20Rich%20Display%20System.ipynb) for illustrations of IPython cell types, and [here](https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks) for a collection of sample notebooks. Look [here](http://iacs-courses.seas.harvard.edu/courses/am207/blog/installing-python.html) for some good tips on installation, as well as the parent directory for excellent ipython-based course material on scientific computing using Monte Carlo methods. For a quick start to scientific programming, see: [http://nbviewer.ipython.org/gist/rpmuller/5920182](http://nbviewer.ipython.org/gist/rpmuller/5920182) For a comphrensive coverage of scientific python see[:https://scipy-lectures.github.io](https://scipy-lectures.github.io) And for a ground-up set of tutorials on python see: [http://learnpythonthehardway.org/book/](http://learnpythonthehardway.org/book/) Switching from matlab to python? [http://wiki.scipy.org/NumPy_for_Matlab_User](http://mathesaurus.sourceforge.net/matlab-numpy.html) [ProjectIdeasF2015.nb](Grading,%20Exercises%20&%20Exams/FinalProjectIdeasF2015.nb) [(pdf)](Grading,%20Exercises%20&%20Exams/FinalProjectIdeasF2015.nb.pdf) Nov 6 18\\. Motion: optic flow _[18.MotionOpticFlow.nb](Lectures/18.MotionOpticFlow/18.MotionOpticFlow.nb) [(pdf)](Lectures/18.MotionOpticFlow/18.MotionOpticFlow.nb.pdf)_ _OpenCV python demo:_ [OpticFlowSparse.ipynb](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/Lectures/18.MotionOpticFlow/OpticFlowSparse.ipynb) needs: [648aa10.avi](Lectures/17_PythonForVision/648aa10.avi) Horn, B. K. P., & Schunck, B. G. (1981). Determining Optical Flow. Artificial Intelligence, 17, 185-203\\. ([pdf](../../coursepapers/Optical_Flow_OPT.pdf)) Optic Flow (2013) Florian Raudies, Scholarpedia, 8(7):30724\\. doi:10.4249/scholarpedia.30724 ([link](http://www.scholarpedia.org/article/Optic_flow)) (with available matlab code) Optic flow matlab code from Michael Black's lab. ([link](http://cs.brown.edu/people/black/code.html)) Borst, A. (2007). Correlation versus gradient type motion detectors: the pros and cons. Philos Trans R Soc Lond B Biol Sci, 362(1479), 369-374\\. [pdf](../../coursepapers/Borst2007rstb20061964.pdf)) [http://web.mit.edu/persci/people/adelson/illusions_demos.html](http://web.mit.edu/persci/people/adelson/illusions_demos.html) [IPython aperture demo](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/Lectures/17_PythonForVision/Aperture%20demo.ipynb) EV: Section 2.4 FV: Chapter 10 Nov 8 19\\. Motion: biological, human perception _[19.MotionHumanPerception.nb](Lectures/19.MotionIllusionsBayes/19.MotionHumanPerception.nb) [(pdf)](Lectures/19.MotionIllusionsBayes/19.MotionHumanPerception.nb.pdf)_ _Weiss, Y., Simoncelli, E. P., & Adelson, E. H. (2002). Motion illusions as optimal percepts. Nat Neurosci, 5(6), 598-604. ([pdf](../../coursepapers/WeissSimonAdelNatNeu2002.pdf))_ Heeger, D. J., Simoncelli, E. P., & Movshon, J. A. (1996). Computational models of cortical visual processing. Proc Natl Acad Sci U S A, 93(2), 623-627\\. ([pdf](../../coursepapers/Heeger96-reprint%20PNAS.pdf)) [http://demonstrations.wolfram.com/DisappearingDotIllusion/](http://demonstrations.wolfram.com/DisappearingDotIllusion/) [http://www.biomotionlab.ca/Demos/BMLwalker.html](http://www.biomotionlab.ca/Demos/BMLwalker.html) EV: Section 4.4 FV: Chapter 10 Nov 13 20\\. Material perception _[20.SurfaceMaterial.nb](Lectures/20\\. Surface material/20.SurfaceMaterial.nb) [(pdf)](Lectures/20\\. Surface material/20.SurfaceMaterial.nb.pdf)_ V1 and lightness ([pdf](Lectures/20.%20Surface%20material/V1Lightness.pdf)) Doerschner, K., Fleming, R. W., Yilmaz, O., Schrater, P. R., Hartung, B., & Kersten, D. (2011). Visual motion and the perception of surface material. Current Biology, 21(23), 2010\u20132016\\. ([pdf](../../coursepapers/Doerschner2011Doerschner2011CURRENT-BIOLOGY-S-11-00953-3.pdf)) Fleming, R. W., Dror, R. O., & Adelson, E. H. (2003). Real-world illumination and the perception of surface reflectance properties. J Vis, 3(5), 347-368\\. [(link](http://journalofvision.org/3/5/3/)) _Adelson, E. H. (1993). Perceptual organization and the judgment of brightness. Science, 262, 2042-2044 ([pdf](../../coursepapers/AdelsonScience1993.pdf))_ Boyaci, H., Fang, F., Murray, S. O., & Kersten, D. (2007). Responses to lightness variations in early human visual cortex. Curr Biol, 17(11), 989-993 ([pdf](../../coursepapers/BoyaciCurrBiol2007.pdf))_[http://www.bilkent.edu.tr/~hboyaci/Vision/](http://www.bilkent.edu.tr/%7Ehboyaci/Vision/)_ [http://web.mit.edu/persci/people/adelson/checkershadow_illusion.html](http://web.mit.edu/persci/people/adelson/checkershadow_illusion.html) [http://gandalf.psych.umn.edu/users/kersten/kersten-lab/demos/transparency.html](http://gandalf.psych.umn.edu/users/kersten/kersten-lab/demos/transparency.html) [http://gandalf.psych.umn.edu/~kersten/kersten-lab/demos/MatteOrShiny.html](http://gandalf.psych.umn.edu/%7Ekersten/kersten-lab/demos/MatteOrShiny.html) Upload Assignment 5 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [texture_classification_plot_gabor.ipynb](Grading, Exercises & Exams/Assignments_due/texture_classification_plot_gabor.ipynb) [(view)](http://nbviewer.jupyter.org/url/vision.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5036W2017/Grading, Exercises & Exams/Assignments_due/texture_classification_plot_gabor.ipynb) Upload Final project title & paragraph outline to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) Nov 15 21\\. Texture. _[21.Texture.nb](Lectures/21\\. Texture/21.Texture.nb) [(pdf)](Lectures/21\\. Texture/21.Texture.nb.pdf)_ Freeman, J., & Simoncelli, E. P. (2011). Metamers of the ventral stream. Nature Publishing Group, 14(9), 1195-1201\\. http://doi.org/10.1038/nn.2889 ([pdf](../../coursepapers/Freeman2011Metamers_of_the_ventral_stream.pdf)) Heeger DJ and Bergen JR, Pyramid Based Texture Analysis/Synthesis, Computer Graphics Proceedings, p. 229-238, 1995\\. ([pdf)](../../coursepapers/heeger-siggraph95.pdf). [EfrosTextureSynthesis.ipynb](Lectures/21\\. Texture/EfrosTextureSynthesis.ipynb) From: [https://github.com/rbaravalle/efros](https://github.com/rbaravalle/efros) [img2.png](Lectures/21\\. Texture/img2.png) A sample: [out2.png](Lectures/21\\. Texture/out2.png) Nov 20 22.Science writing (Thanksgiving week) _[22.ScienceWriting.nb](Lectures/22\\. Science Writing/22.ScienceWriting.nb) [(pdf)](Lectures/22\\. Science Writing/22.ScienceWriting.nb.pdf)_ Gopen & Swan, 1990. [UM Psychology](http://writing.psych.umn.edu/student-resources) [Denis Pelli's advice for scientific writing](http://psych.nyu.edu/pelli/style.html) Nov 22 23.Perceptual integration _[23.PerceptualIntegration.nb](Lectures/23.PerceptualIntegration/23.PerceptualIntegration.nb) [(pdf)](Lectures/23.PerceptualIntegration/23.PerceptualIntegration.nb.pdf) _ McDermott, J., Weiss, Y., & Adelson, E. H. (2001). Beyond junctions: nonlocal form constraints on motion interpretation. Perception, 30(8), 905-923\\. ([pdf](../../coursepapers/McDermottbeyond_junctions.pdf)) [http://www.perceptionweb.com/perception/perc0801/square.html](http://www.perceptionweb.com/perception/perc0801/square.html) Hillis, J. M., Ernst, M. O., Banks, M. S., & Landy, M. S. (2002). Combining sensory information: mandatory fusion within, but not between, senses. Science, 298(5598), 1627-1630.([pdf](../../coursepapers/HillisErnstBanksLandyscience02.pdf)) Ernst, M. O., & Banks, M. S. (2002). Humans integrate visual and haptic information in a statistically optimal fashion. Nature, 415(6870), 429-433\\. ([pdf](../../coursepapers/ErnstBanks2002.pdf)) Stocker, A. A., & Simoncelli, E. (2008). A Bayesian model of conditioned perception. Advances in Neural Information Processing Systems, 20, 1409-1416\\. ([pdf](http://papers.nips.cc/paper/3369-a-bayesian-model-of-conditioned-perception.pdf)) [IPython demo of ideal integration](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/5.Cue%20Combination.ipynb) EV: Section 5 **V. High-level vision** Nov 27 24. Object recognition I _[24.ObjectRecognition.nb](Lectures/24\\. ObjectRecognition_I/24.ObjectRecognition.nb) [(pdf)](Lectures/24\\. ObjectRecognition_I/24.ObjectRecognition.nb.pdf)_ _DiCarlo, J. J., Zoccolan, D., & Rust, N. C. (2012). How does the brain solve visual object recognition? Neuron, 73(3), 415\u2013434\\._ ([pdf](../../coursepapers/DiCarlo2012How_does_the_brain_solve_visual_object_recognition-2.pdf)) Liu, Z., Knill, D. C., & Kersten, D. (1995). Object Classification for Human and Ideal Observers. Vision Research, 35(4), 549-568\\. ([pdf)](../../papers/LiuKnillKersten95.pdf) Tjan, B., Braje, W., Legge, G. E., & Kersten, D. (1995). Human efficiency for recognizing 3-D objects in luminance noise. Vision Research, 35(21), 3053-3069\\. ([pdf](../../coursepapers/Tjan1995.pdf)) Tanaka K (2003) Columns for complex visual object features in the inferotemporal cortex: clustering of cells with similar but slightly different stimulus selectivities. Cerebral cortex 13:90-99.([pdf](../../coursepapers/Tanaka2003.pdf)) Serre, T., Oliva, A., & Poggio, T. (2007). A feedforward architecture accounts for rapid categorization. Proc Natl Acad Sci U S A, 104(15), 6424-6429\\. ([pdf](../../coursepapers/SerreOlivaPoggioPNAS2007.pdf)) Yamins, D. L. K., Hong, H., Cadieu, C. F., Solomon, E. A., Seibert, D., & DiCarlo, J. J. (2014). Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proceedings of the National Academy of Sciences of the United States of America, 111(23), 8619-8624\\. ([pdf](http://www.pnas.org/content/111/23/8619.full.pdf)) Nov 29 25\\. Object recognition II feeforward architectures _25_Bidirectional_I.key.pdf ([pdf](Lectures/25\\. ObjectRecognition_II/25_Bidirectional_I.pdf)) __ Ullman, S., Vidal-Naquet, M., & Sali, E. (2002). Visual features of intermediate complexity and their use in classification. Nat Neurosci, 5(7), 682-687\\. ([pdf](../../coursepapers/UllmanNatureNeuro2002.pdf)) _ Grill-Spector, K. (2003). The neural basis of object perception. Curr Opin Neurobiol, 13(2), 159-166.([pdf](../../coursepapers/GrillSpector_CurrOpinNeuroB2003.pdf)) Rao, R. P., & Ballard, D. H. (1999). Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat Neurosci, 2(1), 79-87\\. ([pdf](../../coursepapers/RaoBallard99.pdf)) Bullier, J. (2001). Integrated model of visual processing. Brain Res Brain Res Rev, 36(2-3), 96-107\\. ([pdf](../../coursepapers/bullier2001.pdf)) Tenenbaum JB: Bayesian modeling of human concept learning. In Advances in Neural Information Processing Systems. Edited by Kearns MSS, Solla A, Cohn DA: Cambridge, MA: MIT Press: 1999.([pdf)](../../coursepapers/JoshTenenbaumbayes.pdf) Upload Assignment 6 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Problem_Set_6 .nb](Grading, Exercises & Exams/Assignments_due/Problem_Set_6.nb) Dec 4 26. Object recognition III feedback architectures _26_BidirectionalFeedback.key.pdf_ [(pdf](Lectures/26\\. ObjectRecognition_III/26_BidirectionalFeedback.pdf)) Torralba, A., Oliva, A., Castelhano, M. S., & Henderson, J. M. (2006). Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search. Psychol Rev, 113(4), 766-786\\. [(pdf](../../coursepapers/Torralba-etal-PsychRev-06.pdf)) Chikkerur, S., Serre, T., Tan, C., & Poggio, T. (2010). What and where: A Bayesian inference theory of attention. Vision Research, 50(22), 2233\u20132247. Dec 6 27. Empirical evidence for bidirectional computations 27.EmpiricalEvidenceBidirectionalProcessing([pdf](Lectures/27\\. EmpiricalEvidenceBidirectionalProcessing/27\\. EmpiricalEvidenceBidirectionalProcessing.pdf)) Longuet-Higgins, H. C., & Prazdny, K. (1980). The Interpretation of a Moving Retinal Image. Proceedings of the Royal Society of London B, 208, 385-397\\. ([pdf](../../coursepapers/LonguetHigginsPrazdnyProcRoySoc1980.pdf)) Horn BKP (1986) Robot Vision. Cambridge MA: MIT Press., chapter 17 ([pdf](../../coursepapers/Hornch17_Structure_From_Motion.pdf)) Schrater PR, Kersten D (2000) How optimal depth cue integration depends on the task. International Journal of Computer Vision 40:73-91\\. ([pdf](../../coursepapers/SchraterKerstenIJCV2000.pdf)) Upload a complete DRAFT of FINAL PROJECT to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) by _**Wednesday December** __**6th, 5 PM.**_ Dec 11 28\\. Vision for action, spatial layout, heading. Homegeneous coordinates. _[28.SpatialLayoutScenes.nb](Lectures/28\\. SpatialLayoutScenes/28.SpatialLayoutScenes.nb) [(pdf](Lectures/28\\. SpatialLayoutScenes/28.SpatialLayoutScenes.nb.pdf))_ _Kalman filter notes ([pdf](http://vision.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/Lectures/27\\. SpatialLayoutScenes/kalman.pdf))_ Upload your peer comments to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) by Monday Dec 11th Dec 13 (Last day of class) _In Class Project Presentations_ Drafts returned to you with Instructor comments Dec 21 Upload Final Revised Draft of Project to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) Final Project Assignment . Goal: This course integrates the behavioral, neural and computational principles of perception. Students often find the interdisciplinary integration to be the most challenging aspect of the course. Through writing, you will learn to synthesize results from diverse and typically isolated disciplines. By writing about your project work, you will learn to think through the broader implications of your project, and to effectively communicate the rationale and results of your contribution in words. You will do a final page research report in which you will describe, in the form of a scientific paper, the results of an original computer program on a topic in computational vision. Your final project will involve: 1) a computer program and; 2) a 2000-3000 word final paper describing your project. For your computer project, you will do one of the following: 1) Write a program to simulate a model from the computer vision literature ; 2) Design and program a method for solving some problem in perception. 3) Design and program a psychophysical experiment to study an aspect of human visual perception. The results of your final project should be written up in the form of a short scientific paper or Mathematica Notebook, describing the motivation, methods, results, and interpretation. If you choose to write your program in Mathematica, your paper and program can be combined can be formated as a Mathematica notebook. See: Books and Tutorials on Notebooks. If you do your final project using Python, you can turn your paper in as a Jupyter notebook. Your paper will be critiqued and returned for you to revise and resubmit in final form. You should write for an audience consisting of your class peers. Completing the final paper involves 4 steps. Each step requires that you email a document to the teaching assistant. Outline (2% of grade)** .** You will submit a working title and paragraph outline by the deadline noted in the syllabus. These outlines will be critiqued in order to help you find an appropriate focus for your papers. (Consult with the instructor or TA for ideas well ahead of time). Complete draft (5% of grade). A double-spaced, complete draft of the paper must be turned in by the deadline noted in the syllabus. Papers should be between 2000 and 3000 words. In addition to the title, author and date lines, papers must include the following sections: Abstract, Introduction, Methods, Results, Discussion, and Bibliography. Use citations to motivate your problem and to justify your claims. Cite authors by name and date, e.g. (Marr & Poggio, 1979). Citations should be original sources, not wikipedia. Use a standard citation format, such as APA. (The UM library has information on style guides , and in particular APA style .) Papers must be typed, with a page number on each page. Figures should be numbered and have figure captions. This draft will be reviewed by your instructor and one of you class peers. The point break down for the total 5% is: 2 pts for completing Introduction, 2 pts for completing Methods, 1 pt for completing Discussion) Peer commentary (5% of grade) . You will submit a written commentary (200 to 500 words) on a complete draft of one of your class peers. The project drafts and commentaries will be anonymous. The commentary should provide feedback to improve the quality and clarity of the writing. Final draft (20% of grade) and \"Cover letter\" (8% of grade). The final draft must be turned in by the date noted on the syllabus. The \"Cover letter\" should describe how your revision addressed comments from your peer evaluator and from your instructor. It should itemize key criticisms together with a brief description of the changes you made to your draft manuscript. Some Resources: Student Writing Support: Center for Writing, 306b Lind Hall and satellite locations (612.625.1893) http://writing.umn.edu . NOTE: Plagiarism, a form of scholastic dishonesty and a disciplinary offense, is described by the Regents as follows: Scholastic dishonesty means plagiarizing; cheating on assignments or examinations; engaging in unauthorized collaboration on academic work; taking, acquiring, or using test materials without faculty permission; submitting false or incomplete records of academic achievement; acting alone or in cooperation with another to falsify records or to obtain dishonestly grades, honors, awards, or professional endorsement; altering, forging, or misusing a University academic record; or fabricating or falsifying data, research procedures, or data analysis. http://www1.umn.edu/regents/policies/academic/Code_of_Conduct.html. See too: http://writing.umn.edu/tww/plagiarism/ and http://writing.umn.edu/tww/plagiarism/definitions.html Privacy Statement","title":"PSY5036F2017"},{"location":"courses/PSY5036F2017/#computational-vision","text":"courses.kersten.org Psychology Department , University of Minnesota Psy 5036W, Fall 2017, 3 credits #34359 08:15 A.M. - 9:30 A.M. Mondays and Wednesdays Elliott Hall N668 Instructor : Daniel Kersten. Office : S212 Elliott Hall. Phone : 612 625-2589 email : kersten@umn.edu Office hours : Mondays 9:30-10:30 am or by appointment. The visual perception of what is in the world is accomplished continually, instantaneously, and usually without conscious thought. The very effortlessness of perception disguises the underlying richness of the problem. We can gain insight into the processes and functions of human vision by studying the relationship between neural mechanisms and visual behavior through computer analysis and simulation. Students will learn about the anatomy and neurophysiology of vision and how they relate to the phenomona of perception. An underlying theme will be to treat vision as a process of statistical inference. There will be in-class programming exercises using the language Mathematica. No prior programming experience is required; however, some familiarity with probability, vector calculus and linear algebra is helpful.","title":"Computational Vision"},{"location":"courses/PSY5036F2017/#readings","text":"","title":"Readings"},{"location":"courses/PSY5036F2017/#main","text":"Lecture notes, Main Readings & Supplementary Material are online.","title":"Main"},{"location":"courses/PSY5036F2017/#additional-readings","text":"","title":"Additional readings"},{"location":"courses/PSY5036F2017/#math-and-vision","text":"( EV ) Early Vision. Yuille and Kersten. In From Neuron to Cognition via Computational Neuroscience , M.A. Arbib, James J. Bonaiuto Editors, Cambridge MA: The MIT Press. Understanding Vision: Theory, Models, and Data. Li Zhaoping. 2014.( publisher page ) ( author's web outline )","title":"Math and vision"},{"location":"courses/PSY5036F2017/#functional-human-vision","text":"( FV ) Foundations of Vision . Wandell ( web )","title":"Functional human vision"},{"location":"courses/PSY5036F2017/#neurophysiology","text":"( NVN ) The New Visual Neurosciences . John S. Werner and Leo M. Chalupa, edts. 2014.","title":"Neurophysiology"},{"location":"courses/PSY5036F2017/#software","text":"","title":"Software"},{"location":"courses/PSY5036F2017/#mathematica","text":"Mathematica is the primary programming environment for this course. Students who have registered for the course will have Google Docs access through the Psychology Department's site license. Alternatives: Mathematica is available in several labs on campus, go to http://www.oit.umn.edu/computer-labs/software/index.htm You may wish to purchase Mathematica for Students see http://www.wolfram.com/products/student/mathforstudents/index.html . You can also access Mathematica on the CLA servers: mac (Note: you may have to change the forward slash to a back slash) windows If you never programmed before go here . If you have programming experience, go here . For user help on using Mathematica, see: http://mathematica.stackexchange.com","title":"Mathematica"},{"location":"courses/PSY5036F2017/#pythonipython","text":"http://ipython.org http://jupyter-notebook-beginner-guide.readthedocs.org/en/latest/index.html http://www.scipy.org For an online course in using Python and PsychoPy for research in human vision see: http://nbviewer.ipython.org/github/gestaltrevision/python_for_visres/blob/master/index.ipynb","title":"Python/IPython"},{"location":"courses/PSY5036F2017/#writing","text":"Gopen, G. D., & Swan, J. A., 1990. The Science of Scientific Writing. American Scientist , 78 , 550-558. Supplementary: The Sense of Style: The Thinking Person's Guide to Writing in the 21 st Century (2014), Pinker, Steven. ( amazon link ) Penrose, A. M., & Katz, S. B. (1998). Writing in the Sciences: Exploring Conventions of Scientific Discourse . New York: St. Martin's Press, Inc. American Psychological Association. (2009). Publication manual of the American Psychological Association (6 th ed.). Washington, DC: American Psychological Association Writing assistance. THE CENTER FOR WRITING offers free one-to-one writing assistance to undergraduate and graduate students, with appointments up to 45 minutes. Nonnative speaker specialists are available. For more information, see http://writing.umn.edu . Psychology department resources: http://writing.psych.umn.edu/student-resources **Grade Requirements ** There will be programming assignments and a final project . The grade weights are: Exercise/programming assignments: 55% Final project presentations: 5 % Final project : 40% (four parts: 2%+5%+5%+28%) The programming assignments will use the Mathematica programming environment. No prior experience with Mathematica is necessary. Assignment due By the midnight on the day due. _** Late Policy : Assignments turned in within 24 hours following the due date will have 15% deducted from the assignment score. Assignments turned in between 24 and 48 hours following the due date will have 30% deducted from the score. Assignments more than 48 hours late will receive a score of zero.**_","title":"Writing"},{"location":"courses/PSY5036F2017/#lectures","text":"Check this section before each class for recent additions and revisions. (5036W Course material from 2015) Lecture notes are in Mathematica Notebook and pdf format. You can download the Mathematica notebook files below to view with Mathematica or Wolfram CDF Player (which is free). [University Calendar](http://onestop.umn.edu/onestop/calendar.html) **Date** **Lecture** _**Main Readings**_ **Supplementary Material** **Assignments due** **I. Introduction** Sep 6 1\\. Introduction to Computational Vision _[1.IntroToComputationalVision.nb](Lectures/1_MultidisciplinaryStudy/1.IntroToComputationalVision.nb) ([pdf](Lectures/1_MultidisciplinaryStudy/1.IntroToComputationalVision.nb.pdf))_ Olshausen, B. A. (2013). Perception as an Inference Problem. In M. Gazzaniga (Ed.), The New Cognitive Neurosciences, 5th Edition (pp. 1\u00e2\u20ac\u201c22). MIT Press. (pp. 1\u00e2\u20ac\u201c18). MIT Press. ([pdf](../../coursepapers/Olshausen2013Perception_as_an_Inference_Problem.pdf)) Screencast: [http://www.wolfram.com/broadcast/screencasts/handsonstart/](http://www.wolfram.com/broadcast/screencasts/handsonstart/) (WITH AUDIO)[ ](Lectures/1_MultidisciplinaryStudy/FoxApertures2.mov)Check out demos under: **Life Sciences/Cognitive Science/Perception** and **Engineering & Technology/Image Processing** on the Mathematica Demonstrations site: [http://demonstrations.wolfram.com/](http://demonstrations.wolfram.com/) _Kersten, D., & Yuille, A. (2003). Bayesian models of object perception. Current Opinion in Neurobiology, 13(2), 1-9\\. ([pdf](../../coursepapers/KerstenYuilleCurrOpinNeu2003.pdf))_ [EV: Section 1](../../papers/YuilleKerstenFinalChapter2016.pdf) Sep 11 2.Limits to Vision _[2.LimitsToVision.nb](Lectures/2_Limits to Vision/2_LimitsToVision.nb) [(pdf)](Lectures/2_Limits to Vision/2_LimitsToVision.nb.pdf)__ Hecht, S., Shlaer, S., & Pirenne, M. H. (1942). Energy, quanta, and vision. Journal of General Physiology, 25, 819-840\\. ([pdf](../../coursepapers/hecht+al_42.pdf))_ Barlow, H. B. (1981). Critical Limiting Factors in the Design of the Eye and Visual Cortex. Proc. Roy. Soc. Lond. B, 212, 1-34\\. ([pdf](../../coursepapers/barlow_81.pdf)) Baylor, D. A., Lamb, T. D., & Yau, K. W. (1979). Responses of retinal rods to single photons. Journal of Physiology, Lond., 288, 613-634\\. ([pdf](../../coursepapers/baylor+al_79b.pdf)) Tinsley, J. N., Molodtsov, M. I., Prevedel, R., Wartmann, D., Pons, J. E. E., Lauwers, M., & Vaziri, A. (2016). Direct detection of a single photon by humans. Nature Communications, 7, 1\u20139\\. [http://doi.org/10.1038/ncomms12172](http://doi.org/10.1038/ncomms12172) ([pdf)](../../coursepapers/Tinsley16.pdf) Sep 13 3\\. The Ideal Observer _[3.TheIdealObserver.nb](Lectures/3_TheIdealObserver/3_TheIdealObserver.nb) [(pdf)](Lectures/3_TheIdealObserver/3_TheIdealObserver.nb.pdf)_ [ProbabilityOverview.nb](Lectures/3_TheIdealObserver/ProbabilityOverview2017.nb) [(pdf)](Lectures/3_TheIdealObserver/ProbabilityOverview2017.nb.pdf) Griffiths, T. L., & Yuille, A. (2008). A primer on probabilistic inference. In M. Oaksford and N. Chater (Eds.). The probabilistic mind: Prospects for rational models of cognition. Oxford: Oxford University Press [(pdf](../../coursepapers/GriffithsYuilleProbPrimerTICsmmc1.pdf)). Try your luck against an ideal discriminator of dot density [YesNoDotDiscriminationDemo.nb](Lectures/3_TheIdealObserver/YesNoDotDiscriminationDemo.nb) Upload Assignment #1 to [Moodle ](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Assignment_1_Mathematica.nb](Grading, Exercises & Exams/Assignments_due/Problem_Set_1.nb) Sep 18 4\\. Ideal observer analysis: Humans vs. ideals. Neurons vs. ideals _[4.IdealObserverAnalysis.nb](Lectures/4_Ideal Observer Analysis/4_IdealObserverAnalysis.nb)_ ([pdf](Lectures/4_Ideal Observer Analysis/4_IdealObserverAnalysis.nb.pdf)) Kersten and Mamassian (2008), Ideal observer theory. The New Encyclopedia of Neuroscience, Squire et al., editors ([pdf](../../coursepapers/KerstenMamassian2009IdealObsTheory.pdf)). Geisler, W. S. (2011). Contributions of ideal observer theory to vision research. Vision Research, 51(7), 771\u2013781.[(pdf)](../../coursepapers/Geisler2011Contributions_of_ideal_observer_theory_to_vision_research.pdf) Burgess, A. E., Wagner, R. F., Jennings, R. J., & Barlow, H. B. (1981)_. Efficiency of human visual signal discrimination. Science, 214(4516), 93-94. [(pdf)](../../coursepapers/BurgessScience1981.pdf)_ Deneve, S., Latham, P. E., & Pouget, A. (1999). Reading population codes: a neural implementation of ideal observers. Nature Neuroscience, 2(8), 740\u2013745\\. [(pdf)](../../coursepapers/Deneve1999Reading_population_codes_a_neural_implementation_of_ideal_observers.pdf) Measure your absolute efficiency to discriminate dot density using a 2AFC task [2AFCDotDiscriminationDemo.nb](Lectures/4_Ideal%20Observer%20Analysis/2AFCDotDiscriminationDemo.nb) **II. Image formation, pattern synthesis** Sep 20 5.Psychophysics: tools & techniques _[5.Psychophysics.nb](Lectures/5_PsychophysicsSKEobserver/5_Psychophysics.nb)[](Lectures/5_PsychophysicsSKEobserver/5_Psychophysics.nb) [(pdf)](Lectures/5_PsychophysicsSKEobserver/5_Psychophysics.nb.pdf) _ [SKEDetection2AFCInLineDisplay.nb](Lectures/5_PsychophysicsSKEobserver/SKEDetection2AFCInLineDisplay.nb) Farell, B. & Pelli, D. G. (1999) Psychophysical methods, or how to measure a threshold and why. In R. H. S. Carpenter & J. G. Robson (Eds.), Vision Research: A Practical Guide to Laboratory Methods, New York: Oxford University ([pdf](../../coursepapers/farell1999chapter.pdf)) Press.http://psych.nyu.edu/pelli/ Morgenstern, Y., & Elder, J. H. (2012). Local Visual Energy Mechanisms Revealed by Detection of Global Patterns. Journal of Neuroscience, 32(11), 3679\u20133696\\. For a free Matlab psychophysics package, see: [http://psychotoolbox.org](http://psychtoolbox.org/) For a free Python psychophysics package, see: [http://www.psychopy.org](http://www.psychopy.org) Sep 25 6\\. Bayesian decision theory & perception _[6.BayesDecisionTheory.nb](Lectures/6_BayesDecisionTheory/6_BayesDecisionTheory.nb.pdf) [(pdf)](Lectures/6_BayesDecisionTheory/6_BayesDecisionTheory.nb.pdf)_ _Geisler, W. S., & Kersten, D. (2002). Illusions, perception and Bayes. Nat Neurosci, 5(6), 508-510\\. ([pdf](http://gandalf.psych.umn.edu/%7Ekersten/kersten-lab/papers/GeislerKerstennn0602-508.pdf))_ [EV Section 3](../../coursepapers/YuilleKerstenFinalChapter2016.pdf#3) Sep 27 7\\. Limits to spatial resolution, image modeling, introduction to linear systems _[7.ImageModelLinearSystems.nb](Lectures/7.ImageModelingLinearSystems/7.ImageModelLinearSystems.nb) [(pdf)](Lectures/7.ImageModelingLinearSystems/7.ImageModelLinearSystems.nb.pdf)_ _Campbell, F. W., & Green, D. (1965). Optical and retinal factors affecting visual resolution. Journal of Physiology (Lond.), 181, 576-593\\. ([pdf](../../coursepapers/CampbellGreen_JP1965.pdf))_ Williams, D. R. (1986). Seeing through the photoreceptor mosaic. 9(5), 193-197\\. ([pdf](../../coursepapers/williams86.pdf)) [LinearAlgebraReview.nb](Lectures/7.ImageModelingLinearSystems/LinearAlgebraReview.nb) [Convolutions_Tutorial.nb](Lectures/7.ImageModelingLinearSystems/Convolutions_Tutorial.nb) [IPython convolutions notebook](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/2a.Convolution.ipynb) Upload Assignment #2 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Problem_Set_2.nb](Grading, Exercises & Exams/Assignments_due/Problem_Set_2.nb) (correction 10/4/17) **III. Early visual coding** Oct 2 8\\. Linear systems analysis _[8.LinearSystemsOptics.nb](Lectures/8\\. Spatial filters/8.LinearSystemsOptics.nb) [(pdf)](Lectures/8\\. Spatial filters/8.LinearSystemsOptics.nb.pdf) _ [EV: Section 2](../../papers/YuilleKerstenFinalChapter2016.pdf) _[CSF.gif](Lectures/8\\. Spatial filters/CSF.gif)_ Tutorials: [Fourier_neural_image.nb](Lectures/8\\. Spatial filters/Fourier_neural_image.nb) Oct 4 9\\. Features and filters. Spatial filter models of early human vision _[9.NeuralSpatialFiltering.nb](Lectures/9\\. Multi-scale analysis/9.NeuralSpatialFiltering.nb) [(pdf)](Lectures/9\\. Multi-scale analysis/9.NeuralSpatialFiltering.nb.pdf)_ Campbell, F. W., & Robson, J. R. (1968). Application of Fourier Analysis to the Visibility of Gratings. Journal of Physiology 197, 551-566\\. ([pdf](../../coursepapers/CampbellRobson_JP1968.pdf)) De Valois, R. L., Albrecht, D. G., & Thorell, L. G. (1982). Spatial frequency selectivity of cells in macaque visual cortex. Vision Res, 22(5), 545-559\\. ([pdf](../../coursepapers/DeValoisAlbrechtThorell1982.pdf)) Watson, A. B. (1987). Efficiency of a model human image code. J Opt Soc Am A, 4(12), 2401-2417\\. ([pdf)](http://vision.arc.nasa.gov/publications/Efficiency.pdf) [IPython demo of gabor filtering](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/2b.Gabor.ipynb) Steerable pyramids: [http://www.cns.nyu.edu/~eero/steerpyr/](http://www.cns.nyu.edu/%7Eeero/steerpyr/) Oct 9 10\\. Features and filters. Local processing & image analysis _[10.ImageProcessing.nb](Lectures/10.ImageManipulations/10.ImageProcessing.nb) [(pdf)](Lectures/10.ImageManipulations/10.ImageProcessing.nb.pdf)_ Gollisch, T., & Meister, M. (2010). Eye Smarter than Scientists Believed: Neural Computations in Circuits of the Retina. Neuron, 65(2), 150\u2013164\\. ([pdf](../../coursepapers/Gollisch2010Eye_Smarter_than_Scientists_Believed_Neural_Computations_in_Circuits_of_the_Retina.pdf)) Albrecht, D. G., De Valois, R. L., & Thorell, L. G. (1980). Visual cortical neurons: are bars or gratings the optimal stimuli? Science, 207(4426), 88-90.[(pdf)](../../coursepapers/AlbrechtDeValoisThorellScience1980.pdf) Adelson, E. H., & Bergen, J. R. (1991). The plenoptic function and the elements of early vision. In M. S. Landy & J. A. Movshon (Eds.), Computational Models of Visual Processing. Cambridge, MA: The MIT Press: A Bradford Book.[(pdf](../../coursepapers/AdelsonBergenPlenopticelements91.pdf)[)](../../coursepapers/adelson-bergen-85.pdf) ClassificationImage demo ([ReverseCorrelation.nb](Reverse%20correlation/ReverseCorrelation.nb)) Ahumada, A. J., Jr. (2002). Classification image weights and internal noise level estimation. J Vis, 2(1), 121-131. ([pdf)](Reverse%20correlation/Ahumada-2002-jov-2-1-8.pdf) Upload Assignment 3 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Problem_Set_3.nb](Grading, Exercises & Exams/Assignments_due/Problem_Set_3.nb) [](Grading,%20Exercises%20&%20Exams/Assignments_due/Assignmt_2_Convolve.nb) Oct 11 11\\. Coding efficiency: Retina _[11.CodingEfficiency.nb](Lectures/11\\. Efficient coding/11.CodingEfficiency.nb) [(pdf)](Lectures/11\\. Efficient coding/11.CodingEfficiency.nb.pdf)_ Geisler, W. S. (2008). Visual perception and the statistical properties of natural scenes. Annu Rev Psychol, 59, 167-192\\. [(pdf)](../../coursepapers/Geisler2008annurev.psych.58.110405.085632.pdf) Laughlin, S. (1981). A simple coding procedure enhances a neuron's information capacity. Z Naturforsch [C], 36(9-10), 910-912.([pdf](../../coursepapers/Laughlin1981.pdf)) Atick, J. J., & Redlich, A. N. (1992). What does the retina know about natural scenes? Neural Computation, 4(2), 196\u2013210\\. Meister, M., & Berry, M. J., 2nd. (1999). The neural code of the retina. Neuron, 22(3), 435-450.[(pdf](../../coursepapers/meister+berry_99.pdf)) Srinivasan, M. V., Laughlin, S. B., & Dubs, A. (1982). Predictive coding: a fresh view of inhibition in the retina. Proc R Soc Lond B Biol Sci, 216(1205), 427-459.([pdf](../../coursepapers/srinivasan+al_82.pdf)) [IPython demo of natural image statistics](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/3a.Natural%20Image%20Statistics.ipynb) Oct 16 12\\. Coding efficiency: Cortex _[12.SpatialCodingEfficiency.nb](Lectures/12\\. Efficent coding Spatial/12.SpatialCodingEfficiency.nb) [(pdf)](Lectures/12\\. Efficent coding Spatial/12.SpatialCodingEfficiency.nb.pdf)_ _Simoncelli, E. P., & Olshausen, B. A. (2001). Natural image statistics and neural representation. Annu Rev Neurosci, 24, 1193-1216.[(pdf](../../coursepapers/SimoncelliOlshausenAnnRev1999.pdf))_ [ContrastNormalizationNotes.nb](Lectures/12\\. Efficent coding Spatial/ContrasNormalizationNotes.nb) Laughlin, S. B., de Ruyter van Steveninck, R. R., & Anderson, J. C. (1998). The metabolic cost of neural information. Nat Neurosci, 1(1), 36-41.([pdf)](../../coursepapers/laughlin+al_98.pdf) Lennie, P. (2003). The cost of cortical computation. Curr Biol, 13(6), 493-497. [(pdf)](../../coursepapers/LennieCurBio2003.pdf) Multi-resolution, image pyramids, and efficient coding: [JepsonFleet2005pyramids_notes.pdf ](../../coursepapers/JepsonFleet2005pyramids_notes.pdf)[AdelsonPyramidRCA84.pdf](../../coursepapers/AdelsonPyramidRCA84.pdf) **IV. Intermediate-level vision, integration, grouping** Oct 18 13\\. Edge detection [13.EdgeDetection.nb](Lectures/13\\. Edges/13.EdgeDetection.nb) [(pdf)](Lectures/13\\. Edges/13.EdgeDetection.nb.pdf) Hubel, D. H., & Wiesel, T. N. (1977). Ferrier lecture. Functional architecture of macaque monkey visual cortex. Proc R Soc Lond B Biol Sci, 198(1130), 1-59\\. [(pdf)](../../coursepapers/HubelWieselFerrier1977.pdf) [IPython demo of statistical edge detection](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/3b.Statistical%20Edge%20Detection.ipynb) Oct 23 14. Objects and scenes from images. The visual cortical pathways and hierarchy. _[14.ScenesfromImages.nb](Lectures/14.Scenes from images/14.ScenesfromImages.nb) [(pdf)](Lectures/14.Scenes from images/14.ScenesfromImages.nb.pdf)__ von der Heydt R (2003) Image parsing mechanisms of the visual cortex. In: The Visual Neurosciences (Werner JS, Chalupa LM, eds.), pp 1139-1150\\. Cambridge, Mass.: MIT press.[(pdf](../../coursepapers/VonderHeydt_ImageParsing_neuroscience.pdf))_ Kersten, D. J., & Yuille, A. L. (2014). Inferential Models of the Visual Cortical Hierarchy. In M. S. Gazzaniga & G. R. Mangun (Eds.), The New Cognitive Neurosciences, 5th Edition (pp. 1\u00e2\u20ac\u201c22). MIT Press. [(pdf)](http://vision.psych.umn.edu/users/kersten//kersten-lab/coursepapers/KerstenYuilleNewCogNeuro2014.pdf) Zhou H, Friedman HS, von der Heydt R (2000) Coding of border ownership in monkey visual cortex. J Neuroscience 20: 6594-6611\\. ([pdf](../../coursepapers/ZhouFriedmanVonDerHeydt_2000_6594.pdf)) Oct 25 15\\. Scene-based generative models _[15.SurfaceGeometryDepth.nb](Lectures/15\\. Surfacegeometrydepth/15.SurfaceGeometryDepth.nb) [(pdf)](Lectures/15\\. Surfacegeometrydepth/15.SurfaceGeometryDepth.nb.pdf)_ _Kersten, D., Mamassian, P., & Yuille, A. (2004). Object perception as Bayesian Inference. Annual Review of Psychology, 55, 271-304\\. ([pdf](../../coursepapers/KerstenMamassianYuille_2004_annurev.psych.55.090902.142005.pdf))_ Oct 30 16\\. Shape-from-X _[16.ShapeFromX.nb](Lectures/16\\. Shape-from-X/16.ShapeFromX.nb) [(pdf)](Lectures/16\\. Shape-from-X/16.ShapeFromX.nb.pdf)_ Reflectance map: Shape from shading: Horn BKP (1986) Robot Vision. Cambridge MA: MIT Press. Ch 11 ([pdf)](../../coursepapers/ch11_Shape_from_Shading.pdf). Barron, J. T., & Malik, J. (2015). Shape, Illumination, and Reflectance from Shading. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(8), 1670\u00e2\u20ac\u201c1687. http://doi.org/10.1109/TPAMI.2014.2377712 [(pdf)](../../coursepapers/BarronMalik2015IEEE_Transactions_on_Pattern_Analysis_and_Machine_Intelligence.pdf) Belhumeur, P. N., Kriegman, D. J., & Yuille, A. (1997). The Bas-Relief Ambiguity. ([pdf](https://pdfs.semanticscholar.org/71ac/0dc7634e4a56fd41dfac270ec5883fcbb44f.pdf)) Johnson, M. K., & Adelson, E. H. (2011). Shape Estimation in Natural Illumination. Computer Vision and Pattern Recognition (CVPR), 2553\u20132560. Muryy, A. A., Welchman, A. E., Blake, A., & Fleming, R. W. (2013). Specular reflections and the estimation of shape from binocular disparity. Proceedings of the National Academy of Sciences of the United States of America, 110(6), 2413\u20132418\\. [(link](http://www.pnas.org/content/110/6/2413.short)) [cube.mov](../../coursepapers/cube.mp4) [random.mov](../../coursepapers/random.mp4) Upload Assignment #4 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Problem_Set_4.nb ](Grading, Exercises & Exams/Assignments_due/Problem_Set_4.nb)[(pdf)](Grading, Exercises & Exams/Assignments_due/Problem_Set_4.nb.pdf) [bluradaptationdemo](../../coursepapers/WebsterGeorgeBlurAdnn906-S1.mp4) [(Webster et al. pdf)](../../coursepapers/WebsterGeorgesonBlurAdaptationnn906.pdf) [motion-induced-blindness demo](../../coursepapers/BasicBonnehYellowDisksBlueDots.gif) [(Bonneh et al. pdf)](../../coursepapers/BonnehCoopemanSagiNature2001411798.pdf) Nov 1 17\\. Shape from shading Overview of python/ipython for computational vision [ ](https://wakari.io/sharing/bundle/kersten/Lect_19Intro_Python) _[17. Shape from shading.nb](Lectures/17.Shape from shading/17.ShapeFromShading.nb)_ [(pdf)](Lectures/17.Shape from shading/17.ShapeFromShading.nb.pdf) [Lect_17Intro_Python.ipynb](Lectures/17_PythonForVision/Lect_17Intro_Python.ipynb) (source) ([pdf](Lectures/17_PythonForVision/Lect_17Intro_Python.pdf)) _[17\\. IPython notebook](http://nbviewer.jupyter.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2017/Lectures/17_PythonForVision/Lect_17Intro_Python.ipynb)_ [Demos](Lectures/17_PythonForVision/Demos/index.html) by Weichao Qiu and Dan Kersten, supplement to _**Early Vision**._ Yuille and Kersten. A chapter in _From Neuron to Cognition via Computational Neuroscience_, M.A. Arbib, James J. Bonaiuto Editors, Cambridge MA: The MIT Press, in 2016 [Anaconda](https://store.continuum.io/cshop/anaconda/) python installation recommended. We will use [Juypter/IPython](http://ipython.org), a browser-based notebook interface for python. See [here](http://nbviewer.ipython.org/github/ipython/ipython/blob/1.x/examples/notebooks/Part%205%20-%20Rich%20Display%20System.ipynb) for illustrations of IPython cell types, and [here](https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks) for a collection of sample notebooks. Look [here](http://iacs-courses.seas.harvard.edu/courses/am207/blog/installing-python.html) for some good tips on installation, as well as the parent directory for excellent ipython-based course material on scientific computing using Monte Carlo methods. For a quick start to scientific programming, see: [http://nbviewer.ipython.org/gist/rpmuller/5920182](http://nbviewer.ipython.org/gist/rpmuller/5920182) For a comphrensive coverage of scientific python see[:https://scipy-lectures.github.io](https://scipy-lectures.github.io) And for a ground-up set of tutorials on python see: [http://learnpythonthehardway.org/book/](http://learnpythonthehardway.org/book/) Switching from matlab to python? [http://wiki.scipy.org/NumPy_for_Matlab_User](http://mathesaurus.sourceforge.net/matlab-numpy.html) [ProjectIdeasF2015.nb](Grading,%20Exercises%20&%20Exams/FinalProjectIdeasF2015.nb) [(pdf)](Grading,%20Exercises%20&%20Exams/FinalProjectIdeasF2015.nb.pdf) Nov 6 18\\. Motion: optic flow _[18.MotionOpticFlow.nb](Lectures/18.MotionOpticFlow/18.MotionOpticFlow.nb) [(pdf)](Lectures/18.MotionOpticFlow/18.MotionOpticFlow.nb.pdf)_ _OpenCV python demo:_ [OpticFlowSparse.ipynb](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/Lectures/18.MotionOpticFlow/OpticFlowSparse.ipynb) needs: [648aa10.avi](Lectures/17_PythonForVision/648aa10.avi) Horn, B. K. P., & Schunck, B. G. (1981). Determining Optical Flow. Artificial Intelligence, 17, 185-203\\. ([pdf](../../coursepapers/Optical_Flow_OPT.pdf)) Optic Flow (2013) Florian Raudies, Scholarpedia, 8(7):30724\\. doi:10.4249/scholarpedia.30724 ([link](http://www.scholarpedia.org/article/Optic_flow)) (with available matlab code) Optic flow matlab code from Michael Black's lab. ([link](http://cs.brown.edu/people/black/code.html)) Borst, A. (2007). Correlation versus gradient type motion detectors: the pros and cons. Philos Trans R Soc Lond B Biol Sci, 362(1479), 369-374\\. [pdf](../../coursepapers/Borst2007rstb20061964.pdf)) [http://web.mit.edu/persci/people/adelson/illusions_demos.html](http://web.mit.edu/persci/people/adelson/illusions_demos.html) [IPython aperture demo](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/Lectures/17_PythonForVision/Aperture%20demo.ipynb) EV: Section 2.4 FV: Chapter 10 Nov 8 19\\. Motion: biological, human perception _[19.MotionHumanPerception.nb](Lectures/19.MotionIllusionsBayes/19.MotionHumanPerception.nb) [(pdf)](Lectures/19.MotionIllusionsBayes/19.MotionHumanPerception.nb.pdf)_ _Weiss, Y., Simoncelli, E. P., & Adelson, E. H. (2002). Motion illusions as optimal percepts. Nat Neurosci, 5(6), 598-604. ([pdf](../../coursepapers/WeissSimonAdelNatNeu2002.pdf))_ Heeger, D. J., Simoncelli, E. P., & Movshon, J. A. (1996). Computational models of cortical visual processing. Proc Natl Acad Sci U S A, 93(2), 623-627\\. ([pdf](../../coursepapers/Heeger96-reprint%20PNAS.pdf)) [http://demonstrations.wolfram.com/DisappearingDotIllusion/](http://demonstrations.wolfram.com/DisappearingDotIllusion/) [http://www.biomotionlab.ca/Demos/BMLwalker.html](http://www.biomotionlab.ca/Demos/BMLwalker.html) EV: Section 4.4 FV: Chapter 10 Nov 13 20\\. Material perception _[20.SurfaceMaterial.nb](Lectures/20\\. Surface material/20.SurfaceMaterial.nb) [(pdf)](Lectures/20\\. Surface material/20.SurfaceMaterial.nb.pdf)_ V1 and lightness ([pdf](Lectures/20.%20Surface%20material/V1Lightness.pdf)) Doerschner, K., Fleming, R. W., Yilmaz, O., Schrater, P. R., Hartung, B., & Kersten, D. (2011). Visual motion and the perception of surface material. Current Biology, 21(23), 2010\u20132016\\. ([pdf](../../coursepapers/Doerschner2011Doerschner2011CURRENT-BIOLOGY-S-11-00953-3.pdf)) Fleming, R. W., Dror, R. O., & Adelson, E. H. (2003). Real-world illumination and the perception of surface reflectance properties. J Vis, 3(5), 347-368\\. [(link](http://journalofvision.org/3/5/3/)) _Adelson, E. H. (1993). Perceptual organization and the judgment of brightness. Science, 262, 2042-2044 ([pdf](../../coursepapers/AdelsonScience1993.pdf))_ Boyaci, H., Fang, F., Murray, S. O., & Kersten, D. (2007). Responses to lightness variations in early human visual cortex. Curr Biol, 17(11), 989-993 ([pdf](../../coursepapers/BoyaciCurrBiol2007.pdf))_[http://www.bilkent.edu.tr/~hboyaci/Vision/](http://www.bilkent.edu.tr/%7Ehboyaci/Vision/)_ [http://web.mit.edu/persci/people/adelson/checkershadow_illusion.html](http://web.mit.edu/persci/people/adelson/checkershadow_illusion.html) [http://gandalf.psych.umn.edu/users/kersten/kersten-lab/demos/transparency.html](http://gandalf.psych.umn.edu/users/kersten/kersten-lab/demos/transparency.html) [http://gandalf.psych.umn.edu/~kersten/kersten-lab/demos/MatteOrShiny.html](http://gandalf.psych.umn.edu/%7Ekersten/kersten-lab/demos/MatteOrShiny.html) Upload Assignment 5 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [texture_classification_plot_gabor.ipynb](Grading, Exercises & Exams/Assignments_due/texture_classification_plot_gabor.ipynb) [(view)](http://nbviewer.jupyter.org/url/vision.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5036W2017/Grading, Exercises & Exams/Assignments_due/texture_classification_plot_gabor.ipynb) Upload Final project title & paragraph outline to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) Nov 15 21\\. Texture. _[21.Texture.nb](Lectures/21\\. Texture/21.Texture.nb) [(pdf)](Lectures/21\\. Texture/21.Texture.nb.pdf)_ Freeman, J., & Simoncelli, E. P. (2011). Metamers of the ventral stream. Nature Publishing Group, 14(9), 1195-1201\\. http://doi.org/10.1038/nn.2889 ([pdf](../../coursepapers/Freeman2011Metamers_of_the_ventral_stream.pdf)) Heeger DJ and Bergen JR, Pyramid Based Texture Analysis/Synthesis, Computer Graphics Proceedings, p. 229-238, 1995\\. ([pdf)](../../coursepapers/heeger-siggraph95.pdf). [EfrosTextureSynthesis.ipynb](Lectures/21\\. Texture/EfrosTextureSynthesis.ipynb) From: [https://github.com/rbaravalle/efros](https://github.com/rbaravalle/efros) [img2.png](Lectures/21\\. Texture/img2.png) A sample: [out2.png](Lectures/21\\. Texture/out2.png) Nov 20 22.Science writing (Thanksgiving week) _[22.ScienceWriting.nb](Lectures/22\\. Science Writing/22.ScienceWriting.nb) [(pdf)](Lectures/22\\. Science Writing/22.ScienceWriting.nb.pdf)_ Gopen & Swan, 1990. [UM Psychology](http://writing.psych.umn.edu/student-resources) [Denis Pelli's advice for scientific writing](http://psych.nyu.edu/pelli/style.html) Nov 22 23.Perceptual integration _[23.PerceptualIntegration.nb](Lectures/23.PerceptualIntegration/23.PerceptualIntegration.nb) [(pdf)](Lectures/23.PerceptualIntegration/23.PerceptualIntegration.nb.pdf) _ McDermott, J., Weiss, Y., & Adelson, E. H. (2001). Beyond junctions: nonlocal form constraints on motion interpretation. Perception, 30(8), 905-923\\. ([pdf](../../coursepapers/McDermottbeyond_junctions.pdf)) [http://www.perceptionweb.com/perception/perc0801/square.html](http://www.perceptionweb.com/perception/perc0801/square.html) Hillis, J. M., Ernst, M. O., Banks, M. S., & Landy, M. S. (2002). Combining sensory information: mandatory fusion within, but not between, senses. Science, 298(5598), 1627-1630.([pdf](../../coursepapers/HillisErnstBanksLandyscience02.pdf)) Ernst, M. O., & Banks, M. S. (2002). Humans integrate visual and haptic information in a statistically optimal fashion. Nature, 415(6870), 429-433\\. ([pdf](../../coursepapers/ErnstBanks2002.pdf)) Stocker, A. A., & Simoncelli, E. (2008). A Bayesian model of conditioned perception. Advances in Neural Information Processing Systems, 20, 1409-1416\\. ([pdf](http://papers.nips.cc/paper/3369-a-bayesian-model-of-conditioned-perception.pdf)) [IPython demo of ideal integration](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/5.Cue%20Combination.ipynb) EV: Section 5 **V. High-level vision** Nov 27 24. Object recognition I _[24.ObjectRecognition.nb](Lectures/24\\. ObjectRecognition_I/24.ObjectRecognition.nb) [(pdf)](Lectures/24\\. ObjectRecognition_I/24.ObjectRecognition.nb.pdf)_ _DiCarlo, J. J., Zoccolan, D., & Rust, N. C. (2012). How does the brain solve visual object recognition? Neuron, 73(3), 415\u2013434\\._ ([pdf](../../coursepapers/DiCarlo2012How_does_the_brain_solve_visual_object_recognition-2.pdf)) Liu, Z., Knill, D. C., & Kersten, D. (1995). Object Classification for Human and Ideal Observers. Vision Research, 35(4), 549-568\\. ([pdf)](../../papers/LiuKnillKersten95.pdf) Tjan, B., Braje, W., Legge, G. E., & Kersten, D. (1995). Human efficiency for recognizing 3-D objects in luminance noise. Vision Research, 35(21), 3053-3069\\. ([pdf](../../coursepapers/Tjan1995.pdf)) Tanaka K (2003) Columns for complex visual object features in the inferotemporal cortex: clustering of cells with similar but slightly different stimulus selectivities. Cerebral cortex 13:90-99.([pdf](../../coursepapers/Tanaka2003.pdf)) Serre, T., Oliva, A., & Poggio, T. (2007). A feedforward architecture accounts for rapid categorization. Proc Natl Acad Sci U S A, 104(15), 6424-6429\\. ([pdf](../../coursepapers/SerreOlivaPoggioPNAS2007.pdf)) Yamins, D. L. K., Hong, H., Cadieu, C. F., Solomon, E. A., Seibert, D., & DiCarlo, J. J. (2014). Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proceedings of the National Academy of Sciences of the United States of America, 111(23), 8619-8624\\. ([pdf](http://www.pnas.org/content/111/23/8619.full.pdf)) Nov 29 25\\. Object recognition II feeforward architectures _25_Bidirectional_I.key.pdf ([pdf](Lectures/25\\. ObjectRecognition_II/25_Bidirectional_I.pdf)) __ Ullman, S., Vidal-Naquet, M., & Sali, E. (2002). Visual features of intermediate complexity and their use in classification. Nat Neurosci, 5(7), 682-687\\. ([pdf](../../coursepapers/UllmanNatureNeuro2002.pdf)) _ Grill-Spector, K. (2003). The neural basis of object perception. Curr Opin Neurobiol, 13(2), 159-166.([pdf](../../coursepapers/GrillSpector_CurrOpinNeuroB2003.pdf)) Rao, R. P., & Ballard, D. H. (1999). Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat Neurosci, 2(1), 79-87\\. ([pdf](../../coursepapers/RaoBallard99.pdf)) Bullier, J. (2001). Integrated model of visual processing. Brain Res Brain Res Rev, 36(2-3), 96-107\\. ([pdf](../../coursepapers/bullier2001.pdf)) Tenenbaum JB: Bayesian modeling of human concept learning. In Advances in Neural Information Processing Systems. Edited by Kearns MSS, Solla A, Cohn DA: Cambridge, MA: MIT Press: 1999.([pdf)](../../coursepapers/JoshTenenbaumbayes.pdf) Upload Assignment 6 to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) [Problem_Set_6 .nb](Grading, Exercises & Exams/Assignments_due/Problem_Set_6.nb) Dec 4 26. Object recognition III feedback architectures _26_BidirectionalFeedback.key.pdf_ [(pdf](Lectures/26\\. ObjectRecognition_III/26_BidirectionalFeedback.pdf)) Torralba, A., Oliva, A., Castelhano, M. S., & Henderson, J. M. (2006). Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search. Psychol Rev, 113(4), 766-786\\. [(pdf](../../coursepapers/Torralba-etal-PsychRev-06.pdf)) Chikkerur, S., Serre, T., Tan, C., & Poggio, T. (2010). What and where: A Bayesian inference theory of attention. Vision Research, 50(22), 2233\u20132247. Dec 6 27. Empirical evidence for bidirectional computations 27.EmpiricalEvidenceBidirectionalProcessing([pdf](Lectures/27\\. EmpiricalEvidenceBidirectionalProcessing/27\\. EmpiricalEvidenceBidirectionalProcessing.pdf)) Longuet-Higgins, H. C., & Prazdny, K. (1980). The Interpretation of a Moving Retinal Image. Proceedings of the Royal Society of London B, 208, 385-397\\. ([pdf](../../coursepapers/LonguetHigginsPrazdnyProcRoySoc1980.pdf)) Horn BKP (1986) Robot Vision. Cambridge MA: MIT Press., chapter 17 ([pdf](../../coursepapers/Hornch17_Structure_From_Motion.pdf)) Schrater PR, Kersten D (2000) How optimal depth cue integration depends on the task. International Journal of Computer Vision 40:73-91\\. ([pdf](../../coursepapers/SchraterKerstenIJCV2000.pdf)) Upload a complete DRAFT of FINAL PROJECT to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) by _**Wednesday December** __**6th, 5 PM.**_ Dec 11 28\\. Vision for action, spatial layout, heading. Homegeneous coordinates. _[28.SpatialLayoutScenes.nb](Lectures/28\\. SpatialLayoutScenes/28.SpatialLayoutScenes.nb) [(pdf](Lectures/28\\. SpatialLayoutScenes/28.SpatialLayoutScenes.nb.pdf))_ _Kalman filter notes ([pdf](http://vision.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/Lectures/27\\. SpatialLayoutScenes/kalman.pdf))_ Upload your peer comments to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) by Monday Dec 11th Dec 13 (Last day of class) _In Class Project Presentations_ Drafts returned to you with Instructor comments Dec 21 Upload Final Revised Draft of Project to [Moodle](https://ay17.moodle.umn.edu/course/view.php?id=4100) Final Project Assignment . Goal: This course integrates the behavioral, neural and computational principles of perception. Students often find the interdisciplinary integration to be the most challenging aspect of the course. Through writing, you will learn to synthesize results from diverse and typically isolated disciplines. By writing about your project work, you will learn to think through the broader implications of your project, and to effectively communicate the rationale and results of your contribution in words. You will do a final page research report in which you will describe, in the form of a scientific paper, the results of an original computer program on a topic in computational vision. Your final project will involve: 1) a computer program and; 2) a 2000-3000 word final paper describing your project. For your computer project, you will do one of the following: 1) Write a program to simulate a model from the computer vision literature ; 2) Design and program a method for solving some problem in perception. 3) Design and program a psychophysical experiment to study an aspect of human visual perception. The results of your final project should be written up in the form of a short scientific paper or Mathematica Notebook, describing the motivation, methods, results, and interpretation. If you choose to write your program in Mathematica, your paper and program can be combined can be formated as a Mathematica notebook. See: Books and Tutorials on Notebooks. If you do your final project using Python, you can turn your paper in as a Jupyter notebook. Your paper will be critiqued and returned for you to revise and resubmit in final form. You should write for an audience consisting of your class peers. Completing the final paper involves 4 steps. Each step requires that you email a document to the teaching assistant. Outline (2% of grade)** .** You will submit a working title and paragraph outline by the deadline noted in the syllabus. These outlines will be critiqued in order to help you find an appropriate focus for your papers. (Consult with the instructor or TA for ideas well ahead of time). Complete draft (5% of grade). A double-spaced, complete draft of the paper must be turned in by the deadline noted in the syllabus. Papers should be between 2000 and 3000 words. In addition to the title, author and date lines, papers must include the following sections: Abstract, Introduction, Methods, Results, Discussion, and Bibliography. Use citations to motivate your problem and to justify your claims. Cite authors by name and date, e.g. (Marr & Poggio, 1979). Citations should be original sources, not wikipedia. Use a standard citation format, such as APA. (The UM library has information on style guides , and in particular APA style .) Papers must be typed, with a page number on each page. Figures should be numbered and have figure captions. This draft will be reviewed by your instructor and one of you class peers. The point break down for the total 5% is: 2 pts for completing Introduction, 2 pts for completing Methods, 1 pt for completing Discussion) Peer commentary (5% of grade) . You will submit a written commentary (200 to 500 words) on a complete draft of one of your class peers. The project drafts and commentaries will be anonymous. The commentary should provide feedback to improve the quality and clarity of the writing. Final draft (20% of grade) and \"Cover letter\" (8% of grade). The final draft must be turned in by the date noted on the syllabus. The \"Cover letter\" should describe how your revision addressed comments from your peer evaluator and from your instructor. It should itemize key criticisms together with a brief description of the changes you made to your draft manuscript. Some Resources: Student Writing Support: Center for Writing, 306b Lind Hall and satellite locations (612.625.1893) http://writing.umn.edu . NOTE: Plagiarism, a form of scholastic dishonesty and a disciplinary offense, is described by the Regents as follows: Scholastic dishonesty means plagiarizing; cheating on assignments or examinations; engaging in unauthorized collaboration on academic work; taking, acquiring, or using test materials without faculty permission; submitting false or incomplete records of academic achievement; acting alone or in cooperation with another to falsify records or to obtain dishonestly grades, honors, awards, or professional endorsement; altering, forging, or misusing a University academic record; or fabricating or falsifying data, research procedures, or data analysis. http://www1.umn.edu/regents/policies/academic/Code_of_Conduct.html. See too: http://writing.umn.edu/tww/plagiarism/ and http://writing.umn.edu/tww/plagiarism/definitions.html Privacy Statement","title":"Lectures"},{"location":"courses/PSY5036F2019/","text":"5036WSyllabusF2019 Computational Vision \u00b6 courses.kersten.org Psychology Department , University of Minnesota Psy 5036W, Fall 2019, 3 credits #34359 08:45 A.M. - 10:00 A.M. Mondays and Wednesdays Elliott Hall N227 Instructor : Daniel Kersten. Office : S212 Elliott Hall. Phone : 612 625-2589 email : kersten@umn.edu Office hours : Mondays 10:00-11:00 am or by appointment. The visual perception of what is in the world is accomplished continually, instantaneously, and usually without conscious thought. The very effortlessness of perception disguises the underlying richness of the problem. We can gain insight into the processes and functions of human vision by studying the relationship between neural mechanisms and visual behavior through computer analysis and simulation. Students will learn about the anatomy and neurophysiology of vision and how they relate to the phenomona of perception. An underlying theme will be to treat vision as a process of statistical inference. There will be in-class programming exercises using the language Mathematica. No prior programming experience is required; however, some familiarity with probability, vector calculus and linear algebra is helpful. Readings \u00b6 Main \u00b6 Lecture notes, Main Readings & Supplementary Material are all available online. Additional readings \u00b6 Math and vision \u00b6 ( EV ) Early Vision. Yuille and Kersten. In From Neuron to Cognition via Computational Neuroscience , M.A. Arbib, James J. Bonaiuto Editors, Cambridge MA: The MIT Press, in 2016 ( preprint pdf ) Understanding Vision: Theory, Models, and Data. Li Zhaoping. 2014.( publisher page ) ( author's web outline ) Functional human vision \u00b6 ( FV ) Foundations of Vision . Wandell ( web ) Neurophysiology \u00b6 ( NVN ) The New Visual Neurosciences . John S. Werner and Leo M. Chalupa, edts. 2014. Software \u00b6 Mathematica \u00b6 Mathematica is the primary programming environment for this course. Students who have registered for the course will have access through the Psychology Department's site license. Alternatives: Mathematica is available in several labs on campus, go to http://www.oit.umn.edu/computer-labs/software/index.htm You may wish to purchase Mathematica for Students see http://www.wolfram.com/products/student/mathforstudents/index.html . For help using Mathematica, see: http://mathematica.stackexchange.com Python/IPython \u00b6 http://ipython.org http://jupyter-notebook-beginner-guide.readthedocs.org/en/latest/index.html http://www.scipy.org For an online course in using Python and PsychoPy for research in human vision see: http://nbviewer.ipython.org/github/gestaltrevision/python_for_visres/blob/master/index.ipynb Writing \u00b6 Gopen, G. D., & Swan, J. A., 1990. The Science of Scientific Writing. American Scientist , 78 , 550-558. Supplementary: The Sense of Style: The Thinking Person's Guide to Writing in the 21 st Century (2014), Pinker, Steven. ( amazon link ) Penrose, A. M., & Katz, S. B. (1998). Writing in the Sciences: Exploring Conventions of Scientific Discourse . New York: St. Martin's Press, Inc. American Psychological Association. (2009). Publication manual of the American Psychological Association (6 th ed.). Washington, DC: American Psychological Association Writing assistance. THE CENTER FOR WRITING offers free one-to-one writing assistance to undergraduate and graduate students, with appointments up to 45 minutes. Nonnative speaker specialists are available. For more information, see http://writing.umn.edu . Psychology department resources: http://writing.psych.umn.edu/student-resources **Grade Requirements ** There will be programming assignments and a final project . The grade weights are: Exercise/programming assignments: 55% Final project in-class presentations: 5 % Final project : 40% (five parts: 2% (title and outline) +5%(first draft) +5% (peer commentary) +8% (cover letter response) + 20% (final draft)) The programming assignments will use the Mathematica programming environment. No prior experience with Mathematica is necessary. Assignment due By the 6 am on the day after the nominal due date. _** Late Policy : Assignments turned in within 24 hours following the due date will have 15% deducted from the assignment score. Assignments turned in between 24 and 48 hours following the due date will have 30% deducted from the score. Assignments more than 48 hours late will receive a score of zero.**_ Lectures \u00b6 Check this section before each class for recent additions and revisions. (5036W Course material from 2017) Lecture notes are in Mathematica Notebook and pdf format. You can download the Mathematica notebook files below to view with Mathematica or Wolfram CDF Player (which is free). [University Calendar](http://onestop.umn.edu/onestop/calendar.html) **Date** **Lecture** _**Main Readings**_ **Supplementary Material** **Assignments due** **I. Introduction** Sep 4 1\\. Introduction to Computational Vision _1.IntroToComputationalVision.nb _ Olshausen, B. A. (2013). Perception as an Inference Problem. In M. Gazzaniga (Ed.), The New Cognitive Neurosciences, 5th Edition (pp. 1\u00e2\u20ac\u201c22). MIT Press. (pp. 1\u00e2\u20ac\u201c18). MIT Press. Screencast: [http://www.wolfram.com/broadcast/screencasts/handsonstart/](http://www.wolfram.com/broadcast/screencasts/handsonstart/) (WITH AUDIO)[ ](Lectures/1_MultidisciplinaryStudy/FoxApertures2.mov)Check out demos under: **Life Sciences/Cognitive Science/Perception** and **Engineering & Technology/Image Processing** on the Mathematica Demonstrations site: [http://demonstrations.wolfram.com/](http://demonstrations.wolfram.com/) _Kersten, D., & Yuille, A. (2003). Bayesian models of object perception. Current Opinion in Neurobiology, 13(2), 1-9. _ EV: Section 1 Sep 9 2.Limits to Vision _2.LimitsToVision.nb__ Hecht, S., Shlaer, S., & Pirenne, M. H. (1942). Energy, quanta, and vision. Journal of General Physiology, 25, 819-840. _ Barlow, H. B. (1981). Critical Limiting Factors in the Design of the Eye and Visual Cortex. Proc. Roy. Soc. Lond. B, 212, 1-34. Baylor, D. A., Lamb, T. D., & Yau, K. W. (1979). Responses of retinal rods to single photons. Journal of Physiology, Lond., 288, 613-634. Tinsley, J. N., Molodtsov, M. I., Prevedel, R., Wartmann, D., Pons, J. E. E., Lauwers, M., & Vaziri, A. (2016). Direct detection of a single photon by humans. Nature Communications, 7, 1\u20139. Sep 11 3\\. The Ideal Observer _3.TheIdealObserver.nb _ ProbabilityOverview.nb Griffiths, T. L., & Yuille, A. (2008). A primer on probabilistic inference. In M. Oaksford and N. Chater (Eds.). The probabilistic mind: Prospects for rational models of cognition. Oxford: Oxford University Press [(pdf](../../coursepapers/GriffithsYuilleProbPrimerTICsmmc1.pdf)). Try your luck against an ideal discriminator of dot density YesNoDotDiscriminationDemo.nb Upload Assignment #1 to [Canvas ](/courses/132509/assignments/701580) Assignment_1_Mathematica.nb Sep 16 4\\. Ideal observer analysis: Humans vs. ideals. Neurons vs. ideals _4.IdealObserverAnalysis.nb_ Kersten and Mamassian (2008), Ideal observer theory. The New Encyclopedia of Neuroscience, Squire et al., editors (pdf). Geisler, W. S. (2011). Contributions of ideal observer theory to vision research. Vision Research, 51(7), 771\u2013781. Burgess, A. E., Wagner, R. F., Jennings, R. J., & Barlow, H. B. (1981)_. Efficiency of human visual signal discrimination. Science, 214(4516), 93-94\\._ Deneve, S., Latham, P. E., & Pouget, A. (1999). Reading population codes: a neural implementation of ideal observers. Nature Neuroscience, 2(8), 740\u2013745. Measure your absolute efficiency to discriminate dot density using a 2AFC task 2AFCDotDiscriminationDemo.nb **II. Image formation, pattern synthesis** Sep 18 5.Psychophysics: tools & techniques _5.Psychophysics.nb[](Lectures/5_PsychophysicsSKEobserver/5_Psychophysics.nb) _ SKEDetection2AFCInLineDisplay.nb Farell, B. & Pelli, D. G. (1999) Psychophysical methods, or how to measure a threshold and why. In R. H. S. Carpenter & J. G. Robson (Eds.), Vision Research: A Practical Guide to Laboratory Methods, New York: Oxford University (Press.http://psych.nyu.edu/pelli/ Morgenstern, Y., & Elder, J. H. (2012). Local Visual Energy Mechanisms Revealed by Detection of Global Patterns. Journal of Neuroscience, 32(11), 3679\u20133696\\. For a free Matlab psychophysics package, see: [http://psychotoolbox.org](http://psychtoolbox.org/) For a free Python psychophysics package, see: [http://www.psychopy.org](http://www.psychopy.org) Sep 23 6\\. Bayesian decision theory & perception _6.BayesDecisionTheory.nb _ _Geisler, W. S., & Kersten, D. (2002). Illusions, perception and Bayes. Nat Neurosci, 5(6), 508-510\\. ([pdf](http://gandalf.psych.umn.edu/%7Ekersten/kersten-lab/papers/GeislerKerstennn0602-508.pdf))_ [EV Section 3](../../coursepapers/YuilleKerstenFinalChapter2016.pdf#3) Sep 25 7\\. Limits to spatial resolution, image modeling, introduction to linear systems _7.ImageModelLinearSystems.nb _ _Campbell, F. W., & Green, D. (1965). Optical and retinal factors affecting visual resolution. Journal of Physiology (Lond.), 181, 576-593\\. ([pdf](../../coursepapers/CampbellGreen_JP1965.pdf))_ Williams, D. R. (1986). Seeing through the photoreceptor mosaic. 9(5), 193-197. LinearAlgebraReview.nb Convolutions_Tutorial.nb IPython convolutions notebook Upload Assignment #2 to [Canvas](https://ay17.moodle.umn.edu/course/view.php?id=4100) Problem_Set_2.nb **III. Early visual coding** Sep 30 8\\. Linear systems analysis _8.LinearSystemsOptics.nb _ EV: Section 2 _CSF.gif_ Tutorials: Fourier_neural_image.nb Oct 2 9\\. Features and filters. Spatial filter models of early human vision _9.NeuralSpatialFiltering.nb _ Campbell, F. W., & Robson, J. R. (1968). Application of Fourier Analysis to the Visibility of Gratings. Journal of Physiology 197, 551-566. De Valois, R. L., Albrecht, D. G., & Thorell, L. G. (1982). Spatial frequency selectivity of cells in macaque visual cortex. Vision Res, 22(5), 545-559. Watson, A. B. (1987). Efficiency of a model human image code. J Opt Soc Am A, 4(12), 2401-2417. IPython demo of gabor filtering Steerable pyramids: http://www.cns.nyu.edu/~eero/steerpyr/ Oct 7 10\\. Features and filters. Local processing & image analysis _10.ImageProcessing.nb _ Gollisch, T., & Meister, M. (2010). Eye Smarter than Scientists Believed: Neural Computations in Circuits of the Retina. Neuron, 65(2), 150\u2013164. Albrecht, D. G., De Valois, R. L., & Thorell, L. G. (1980). Visual cortical neurons: are bars or gratings the optimal stimuli? Science, 207(4426), 88-90. Adelson, E. H., & Bergen, J. R. (1991). The plenoptic function and the elements of early vision. In M. S. Landy & J. A. Movshon (Eds.), Computational Models of Visual Processing. Cambridge, MA: The MIT Press: A Bradford Book. ClassificationImage demo ([ReverseCorrelation.nb](Reverse%20correlation/ReverseCorrelation.nb)) Ahumada, A. J., Jr. (2002). Classification image weights and internal noise level estimation. J Vis, 2(1), 121-131\\. ([pdf)](Reverse%20correlation/Ahumada-2002-jov-2-1-8.pdf) Upload Assignment 3 to [Canvas](https://ay17.moodle.umn.edu/course/view.php?id=4100) Problem_Set_3.nb [](Grading,%20Exercises%20&%20Exams/Assignments_due/Assignmt_2_Convolve.nb) Oct 9 11\\. Coding efficiency: Retina _11.CodingEfficiency.nb _ Geisler, W. S. (2008). Visual perception and the statistical properties of natural scenes. Annu Rev Psychol, 59, 167-192\\. Laughlin, S. (1981). A simple coding procedure enhances a neuron's information capacity. Z Naturforsch [C], 36(9-10), 910-912. Atick, J. J., & Redlich, A. N. (1992). What does the retina know about natural scenes? Neural Computation, 4(2), 196\u2013210\\. Meister, M., & Berry, M. J., 2nd. (1999). The neural code of the retina. Neuron, 22(3), 435-450.[(pdf](../../coursepapers/meister+berry_99.pdf)) Srinivasan, M. V., Laughlin, S. B., & Dubs, A. (1982). Predictive coding: a fresh view of inhibition in the retina. Proc R Soc Lond B Biol Sci, 216(1205), 427-459. IPython demo of natural image statistics Oct 14 12\\. Coding efficiency: Cortex _12.SpatialCodingEfficiency.nb _ _Simoncelli, E. P., & Olshausen, B. A. (2001). Natural image statistics and neural representation. Annu Rev Neurosci, 24, 1193-1216._ ContrastNormalizationNotes.nb Laughlin, S. B., de Ruyter van Steveninck, R. R., & Anderson, J. C. (1998). The metabolic cost of neural information. Nat Neurosci, 1(1), 36-41. Lennie, P. (2003). The cost of cortical computation. Curr Biol, 13(6), 493-497.[](../../coursepapers/LennieCurBio2003.pdf) Multi-resolution, image pyramids, and efficient coding: JepsonFleet2005pyramids_notes.pdf AdelsonPyramidRCA84.pdf **IV. Intermediate-level vision, integration, grouping** Oct 16 13\\. Edge detection 13.EdgeDetection.nb Hubel, D. H., & Wiesel, T. N. (1977). Ferrier lecture. Functional architecture of macaque monkey visual cortex. Proc R Soc Lond B Biol Sci, 198(1130), 1-59. IPython demo of statistical edge detection Oct 21 14\\. Objects and scenes from images. The visual cortical pathways and hierarchy. _14.ScenesfromImages.nb __ von der Heydt R (2003) Image parsing mechanisms of the visual cortex. In: The Visual Neurosciences (Werner JS, Chalupa LM, eds.), pp 1139-1150\\. Cambridge, Mass.: MIT press._ Kersten, D. J., & Yuille, A. L. (2014). Inferential Models of the Visual Cortical Hierarchy. In M. S. Gazzaniga & G. R. Mangun (Eds.), The New Cognitive Neurosciences, 5th Edition (pp. 1\u00e2\u20ac\u201c22). MIT Press.[](http://vision.psych.umn.edu/users/kersten//kersten-lab/coursepapers/KerstenYuilleNewCogNeuro2014.pdf) Zhou H, Friedman HS, von der Heydt R (2000) Coding of border ownership in monkey visual cortex. J Neuroscience 20: 6594-6611. Oct 23 15\\. Scene-based generative models _15.SurfaceGeometryDepth.nb _ _Kersten, D., Mamassian, P., & Yuille, A. (2004). Object perception as Bayesian Inference. Annual Review of Psychology, 55, 271-304. _ Oct 28 16\\. Shape-from-X _16.ShapeFromX.nb _ Reflectance map: Shape from shading: Horn BKP (1986) Robot Vision. Cambridge MA: MIT Press. Ch 11 Barron, J. T., & Malik, J. (2015). Shape, Illumination, and Reflectance from Shading. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(8), 1670\u00e2\u20ac\u201c1687\\. http://doi.org/10.1109/TPAMI.2014.2377712 Belhumeur, P. N., Kriegman, D. J., & Yuille, A. (1997). The Bas-Relief Ambiguity. ([pdf](https://pdfs.semanticscholar.org/71ac/0dc7634e4a56fd41dfac270ec5883fcbb44f.pdf)) Johnson, M. K., & Adelson, E. H. (2011). Shape Estimation in Natural Illumination. Computer Vision and Pattern Recognition (CVPR), 2553\u20132560. Muryy, A. A., Welchman, A. E., Blake, A., & Fleming, R. W. (2013). Specular reflections and the estimation of shape from binocular disparity. Proceedings of the National Academy of Sciences of the United States of America, 110(6), 2413\u20132418. cube.mov random.mov Oct 30 17\\. Shape from shading Overview of python/ipython for computational vision[ ](https://wakari.io/sharing/bundle/kersten/Lect_19Intro_Python) _17\\. Shape from shading.nb_ Lect_17Intro_Python.ipynb (source) _17\\. IPython notebook_ Demos by Weichao Qiu and Dan Kersten, supplement to _**Early Vision**._ Yuille and Kersten. A chapter in _From Neuron to Cognition via Computational Neuroscience_, M.A. Arbib, James J. Bonaiuto Editors, Cambridge MA: The MIT Press, in 2016 [Anaconda](https://store.continuum.io/cshop/anaconda/) python installation recommended. We will use [Juypter/IPython](http://ipython.org), a browser-based notebook interface for python. See [here](http://nbviewer.ipython.org/github/ipython/ipython/blob/1.x/examples/notebooks/Part%205%20-%20Rich%20Display%20System.ipynb) for illustrations of IPython cell types, and [here](https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks) for a collection of sample notebooks. Look [here](http://iacs-courses.seas.harvard.edu/courses/am207/blog/installing-python.html) for some good tips on installation, as well as the parent directory for excellent ipython-based course material on scientific computing using Monte Carlo methods. For a quick start to scientific programming, see: [http://nbviewer.ipython.org/gist/rpmuller/5920182](http://nbviewer.ipython.org/gist/rpmuller/5920182) For a comphrensive coverage of scientific python see[:https://scipy-lectures.github.io](https://scipy-lectures.github.io) And for a ground-up set of tutorials on python see: [http://learnpythonthehardway.org/book/](http://learnpythonthehardway.org/book/) Switching from matlab to python? [http://wiki.scipy.org/NumPy_for_Matlab_User](http://mathesaurus.sourceforge.net/matlab-numpy.html) ProjectIdeasF2015.nb Nov 4 18\\. Motion: optic flow _18.MotionOpticFlow.nb _ _OpenCV python demo:_ [OpticFlowSparse.ipynb](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/Lectures/18.MotionOpticFlow/OpticFlowSparse.ipynb) needs: [648aa10.avi](Lectures/17_PythonForVision/648aa10.avi) Horn, B. K. P., & Schunck, B. G. (1981). Determining Optical Flow. Artificial Intelligence, 17, 185-203. Optic Flow (2013) Florian Raudies, Scholarpedia, 8(7):30724\\. doi:10.4249/scholarpedia.30724 (with available matlab code) Optic flow matlab code from Michael Black's lab. Borst, A. (2007). Correlation versus gradient type motion detectors: the pros and cons. Philos Trans R Soc Lond B Biol Sci, 362(1479), 369-374. [http://web.mit.edu/persci/people/adelson/illusions_demos.html](http://web.mit.edu/persci/people/adelson/illusions_demos.html) [IPython aperture demo](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/Lectures/17_PythonForVision/Aperture%20demo.ipynb) EV: Section 2.4 FV: Chapter 10 Nov 6 19\\. Motion: biological, human perception _19.MotionHumanPerception.nb _ _Weiss, Y., Simoncelli, E. P., & Adelson, E. H. (2002). Motion illusions as optimal percepts. Nat Neurosci, 5(6), 598-604. ([pdf](../../coursepapers/WeissSimonAdelNatNeu2002.pdf))_ Heeger, D. J., Simoncelli, E. P., & Movshon, J. A. (1996). Computational models of cortical visual processing. Proc Natl Acad Sci U S A, 93(2), 623-627\\. ([pdf](../../coursepapers/Heeger96-reprint%20PNAS.pdf)) [http://demonstrations.wolfram.com/DisappearingDotIllusion/](http://demonstrations.wolfram.com/DisappearingDotIllusion/) [http://www.biomotionlab.ca/Demos/BMLwalker.html](http://www.biomotionlab.ca/Demos/BMLwalker.html) EV: Section 4.4 FV: Chapter 10 Nov 11 20\\. Material perception _20.SurfaceMaterial.nb _ V1 and lightness Doerschner, K., Fleming, R. W., Yilmaz, O., Schrater, P. R., Hartung, B., & Kersten, D. (2011). Visual motion and the perception of surface material. Current Biology, 21(23), 2010\u20132016. Fleming, R. W., Dror, R. O., & Adelson, E. H. (2003). Real-world illumination and the perception of surface reflectance properties. J Vis, 3(5), 347-368\\. _Adelson, E. H. (1993). Perceptual organization and the judgment of brightness. Science, 262, 2042-2044 _ Boyaci, H., Fang, F., Murray, S. O., & Kersten, D. (2007). Responses to lightness variations in early human visual cortex. Curr Biol, 17(11), 989-993 ([pdf](../../coursepapers/BoyaciCurrBiol2007.pdf))_[http://www.bilkent.edu.tr/~hboyaci/Vision/](http://www.bilkent.edu.tr/%7Ehboyaci/Vision/)_ [http://web.mit.edu/persci/people/adelson/checkershadow_illusion.html](http://web.mit.edu/persci/people/adelson/checkershadow_illusion.html) [http://gandalf.psych.umn.edu/users/kersten/kersten-lab/demos/transparency.html](http://gandalf.psych.umn.edu/users/kersten/kersten-lab/demos/transparency.html) [http://gandalf.psych.umn.edu/~kersten/kersten-lab/demos/MatteOrShiny.html](http://gandalf.psych.umn.edu/%7Ekersten/kersten-lab/demos/MatteOrShiny.html) Upload Assignment 5 to [Canvas](https://ay17.moodle.umn.edu/course/view.php?id=4100) texture_classification_plot_gabor.ipynb Upload Final project title & paragraph outline to [C](https://ay17.moodle.umn.edu/course/view.php?id=4100)anvas Nov 13 21\\. Texture. _21.Texture.nb _ Freeman, J., & Simoncelli, E. P. (2011). Metamers of the ventral stream. Nature Publishing Group, 14(9), 1195-1201\\. http://doi.org/10.1038/nn.2889 Heeger DJ and Bergen JR, Pyramid Based Texture Analysis/Synthesis, Computer Graphics Proceedings, p. 229-238, 1995\\. ([pdf)](../../coursepapers/heeger-siggraph95.pdf). EfrosTextureSynthesis.ipynb From: [https://github.com/rbaravalle/efros](https://github.com/rbaravalle/efros) [img2.png](Lectures/21.%20Texture/img2.png) A sample: [out2.png](Lectures/21.%20Texture/out2.png) Nov 18 22.Science writing (Thanksgiving week) _22.ScienceWriting.nb_ Gopen & Swan, 1990 ([pdf](../../coursepapers/GopenSwan1990.pdf)) [UM Psychology](http://writing.psych.umn.edu/student-resources) Nov 20 23.Perceptual integration _23.PerceptualIntegration.nb _ McDermott, J., Weiss, Y., & Adelson, E. H. (2001). Beyond junctions: nonlocal form constraints on motion interpretation. Perception, 30(8), 905-923\\. ([pdf](../../coursepapers/McDermottbeyond_junctions.pdf)) [http://www.perceptionweb.com/perception/perc0801/square.html](http://www.perceptionweb.com/perception/perc0801/square.html) Hillis, J. M., Ernst, M. O., Banks, M. S., & Landy, M. S. (2002). Combining sensory information: mandatory fusion within, but not between, senses. Science, 298(5598), 1627-1630.([pdf](../../coursepapers/HillisErnstBanksLandyscience02.pdf)) Ernst, M. O., & Banks, M. S. (2002). Humans integrate visual and haptic information in a statistically optimal fashion. Nature, 415(6870), 429-433. Stocker, A. A., & Simoncelli, E. (2008). A Bayesian model of conditioned perception. Advances in Neural Information Processing Systems, 20, 1409-1416. [IPython demo of ideal integration](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/5.Cue%20Combination.ipynb) EV: Section 5 **V. High-level vision** Nov 25 24\\. Object recognition I _24.ObjectRecognition.nb _ _DiCarlo, J. J., Zoccolan, D., & Rust, N. C. (2012). How does the brain solve visual object recognition? Neuron, 73(3), 415\u2013434. _ Liu, Z., Knill, D. C., & Kersten, D. (1995). Object Classification for Human and Ideal Observers. Vision Research, 35(4), 549-568\\. ([pdf)](../../papers/LiuKnillKersten95.pdf) Tjan, B., Braje, W., Legge, G. E., & Kersten, D. (1995). Human efficiency for recognizing 3-D objects in luminance noise. Vision Research, 35(21), 3053-3069. Tanaka K (2003) Columns for complex visual object features in the inferotemporal cortex: clustering of cells with similar but slightly different stimulus selectivities. Cerebral cortex 13:90-99. Serre, T., Oliva, A., & Poggio, T. (2007). A feedforward architecture accounts for rapid categorization. Proc Natl Acad Sci U S A, 104(15), 6424-6429\\. Yamins, D. L. K., Hong, H., Cadieu, C. F., Solomon, E. A., Seibert, D., & DiCarlo, J. J. (2014). Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proceedings of the National Academy of Sciences of the United States of America, 111(23), 8619-8624. Nov 27 25\\. Object recognition II feeforward architectures _25_Bidirectional_I.key.pdf __ Ullman, S., Vidal-Naquet, M., & Sali, E. (2002). Visual features of intermediate complexity and their use in classification. Nat Neurosci, 5(7), 682-687. _ Grill-Spector, K. (2003). The neural basis of object perception. Curr Opin Neurobiol, 13(2), 159-166. Rao, R. P., & Ballard, D. H. (1999). Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat Neurosci, 2(1), 79-87. Bullier, J. (2001). Integrated model of visual processing. Brain Res Brain Res Rev, 36(2-3), 96-107. Tenenbaum JB: Bayesian modeling of human concept learning. In Advances in Neural Information Processing Systems. Edited by Kearns MSS, Solla A, Cohn DA: Cambridge, MA: MIT Press: 1999. Dec 2 26\\. Object recognition III feedback architectures _26_BidirectionalFeedback.key.pdf_ [(pdf](Lectures/26.%20ObjectRecognition_III/26_BidirectionalFeedback.pdf)) _ _ Torralba, A., Oliva, A., Castelhano, M. S., & Henderson, J. M. (2006). Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search. Psychol Rev, 113(4), 766-786. Chikkerur, S., Serre, T., Tan, C., & Poggio, T. (2010). What and where: A Bayesian inference theory of attention. Vision Research, 50(22), 2233\u20132247. Upload Assignment 6 to [Canvas](https://ay17.moodle.umn.edu/course/view.php?id=4100) Problem_Set_6 .nb Dec 4 27\\. Empirical evidence for bidirectional computations 27.EmpiricalEvidenceBidirectionalProcessing Longuet-Higgins, H. C., & Prazdny, K. (1980). The Interpretation of a Moving Retinal Image. Proceedings of the Royal Society of London B, 208, 385-397. Horn BKP (1986) Robot Vision. Cambridge MA: MIT Press., chapter 17 Schrater PR, Kersten D (2000) How optimal depth cue integration depends on the task. International Journal of Computer Vision 40:73-91. Upload a complete DRAFT of FINAL PROJECT to [Canvas](https://ay17.moodle.umn.edu/course/view.php?id=4100) by _** December 4**__**th.**_ Dec 9 28\\. Vision for action, spatial layout, heading. Homegeneous coordinates. _28.SpatialLayoutScenes.nb _ _Kalman filter notes (pdf)_ Upload your peer comments to Canvas by Monday Dec 11th Dec 11 (Last day of class) _In Class Project Presentations_ Drafts returned to you with Instructor comments Dec 21 Upload Final Revised Draft of Project to Canvas. Final Project Assignment . Goal: This course integrates the behavioral, neural and computational principles of perception. Students often find the interdisciplinary integration to be the most challenging aspect of the course. Through writing, you will learn to synthesize results from diverse and typically isolated disciplines. By writing about your project work, you will learn to think through the broader implications of your project, and to effectively communicate the rationale and results of your contribution in words. You will do a final page research report in which you will describe, in the form of a scientific paper, the results of an original computer program on a topic in computational vision. Your final project will involve: 1) a computer program and; 2) a 2000-3000 word final paper describing your project. For your computer project, you will do one of the following: 1) Write a program to simulate a model from the computer vision literature ; 2) Design and program a method for solving some problem in perception. 3) Design and program a psychophysical experiment to study an aspect of human visual perception. The results of your final project should be written up in the form of a short scientific paper or Mathematica Notebook, describing the motivation, methods, results, and interpretation. If you choose to write your program in Mathematica, your paper and program can be combined can be formated as a Mathematica notebook. See: Books and Tutorials on Notebooks. If you do your final project using Python, you can turn your paper in as a Jupyter notebook. Your paper will be critiqued and returned for you to revise and resubmit in final form. You should write for an audience consisting of your class peers. Completing the final paper involves 4 steps. Each step requires that you email a document to the teaching assistant. Outline (2% of grade)** .** You will submit a working title and paragraph outline by the deadline noted in the syllabus. These outlines will be critiqued in order to help you find an appropriate focus for your papers. (Consult with the instructor or TA for ideas well ahead of time). Complete draft (5% of grade). A double-spaced, complete draft of the paper must be turned in by the deadline noted in the syllabus. Papers should be between 2000 and 3000 words. In addition to the title, author and date lines, papers must include the following sections: Abstract, Introduction, Methods, Results, Discussion, and Bibliography. Use citations to motivate your problem and to justify your claims. Cite authors by name and date, e.g. (Marr & Poggio, 1979). Citations should be original sources, not wikipedia. Use a standard citation format, such as APA. (The UM library has information on style guides , and in particular APA style .) Papers must be typed, with a page number on each page. Figures should be numbered and have figure captions. This draft will be reviewed by your instructor and one of you class peers. The point break down for the total 5% is: 2 pts for completing Introduction, 2 pts for completing Methods, 1 pt for completing Discussion) Peer commentary (5% of grade) . You will submit a written commentary (200 to 500 words) on a complete draft of one of your class peers. The project drafts and commentaries will be anonymous. The commentary should provide feedback to improve the quality and clarity of the writing. Final draft (20% of grade) and \"Cover letter\" (8% of grade). The final draft must be turned in by the date noted on the syllabus. The \"Cover letter\" should describe how your revision addressed comments from your peer evaluator and from your instructor. It should itemize key criticisms together with a brief description of the changes you made to your draft manuscript. Some Resources: Student Writing Support: Center for Writing, 306b Lind Hall and satellite locations (612.625.1893) http://writing.umn.edu . NOTE: Plagiarism, a form of scholastic dishonesty and a disciplinary offense, is described by the Regents as follows: Scholastic dishonesty means plagiarizing; cheating on assignments or examinations; engaging in unauthorized collaboration on academic work; taking, acquiring, or using test materials without faculty permission; submitting false or incomplete records of academic achievement; acting alone or in cooperation with another to falsify records or to obtain dishonestly grades, honors, awards, or professional endorsement; altering, forging, or misusing a University academic record; or fabricating or falsifying data, research procedures, or data analysis. http://www1.umn.edu/regents/policies/academic/Code_of_Conduct.html. See too: http://writing.umn.edu/tww/plagiarism/ and http://writing.umn.edu/tww/plagiarism/definitions.html Privacy Statement","title":"PSY5036F2019"},{"location":"courses/PSY5036F2019/#computational-vision","text":"courses.kersten.org Psychology Department , University of Minnesota Psy 5036W, Fall 2019, 3 credits #34359 08:45 A.M. - 10:00 A.M. Mondays and Wednesdays Elliott Hall N227 Instructor : Daniel Kersten. Office : S212 Elliott Hall. Phone : 612 625-2589 email : kersten@umn.edu Office hours : Mondays 10:00-11:00 am or by appointment. The visual perception of what is in the world is accomplished continually, instantaneously, and usually without conscious thought. The very effortlessness of perception disguises the underlying richness of the problem. We can gain insight into the processes and functions of human vision by studying the relationship between neural mechanisms and visual behavior through computer analysis and simulation. Students will learn about the anatomy and neurophysiology of vision and how they relate to the phenomona of perception. An underlying theme will be to treat vision as a process of statistical inference. There will be in-class programming exercises using the language Mathematica. No prior programming experience is required; however, some familiarity with probability, vector calculus and linear algebra is helpful.","title":"Computational Vision"},{"location":"courses/PSY5036F2019/#readings","text":"","title":"Readings"},{"location":"courses/PSY5036F2019/#main","text":"Lecture notes, Main Readings & Supplementary Material are all available online.","title":"Main"},{"location":"courses/PSY5036F2019/#additional-readings","text":"","title":"Additional readings"},{"location":"courses/PSY5036F2019/#math-and-vision","text":"( EV ) Early Vision. Yuille and Kersten. In From Neuron to Cognition via Computational Neuroscience , M.A. Arbib, James J. Bonaiuto Editors, Cambridge MA: The MIT Press, in 2016 ( preprint pdf ) Understanding Vision: Theory, Models, and Data. Li Zhaoping. 2014.( publisher page ) ( author's web outline )","title":"Math and vision"},{"location":"courses/PSY5036F2019/#functional-human-vision","text":"( FV ) Foundations of Vision . Wandell ( web )","title":"Functional human vision"},{"location":"courses/PSY5036F2019/#neurophysiology","text":"( NVN ) The New Visual Neurosciences . John S. Werner and Leo M. Chalupa, edts. 2014.","title":"Neurophysiology"},{"location":"courses/PSY5036F2019/#software","text":"","title":"Software"},{"location":"courses/PSY5036F2019/#mathematica","text":"Mathematica is the primary programming environment for this course. Students who have registered for the course will have access through the Psychology Department's site license. Alternatives: Mathematica is available in several labs on campus, go to http://www.oit.umn.edu/computer-labs/software/index.htm You may wish to purchase Mathematica for Students see http://www.wolfram.com/products/student/mathforstudents/index.html . For help using Mathematica, see: http://mathematica.stackexchange.com","title":"Mathematica"},{"location":"courses/PSY5036F2019/#pythonipython","text":"http://ipython.org http://jupyter-notebook-beginner-guide.readthedocs.org/en/latest/index.html http://www.scipy.org For an online course in using Python and PsychoPy for research in human vision see: http://nbviewer.ipython.org/github/gestaltrevision/python_for_visres/blob/master/index.ipynb","title":"Python/IPython"},{"location":"courses/PSY5036F2019/#writing","text":"Gopen, G. D., & Swan, J. A., 1990. The Science of Scientific Writing. American Scientist , 78 , 550-558. Supplementary: The Sense of Style: The Thinking Person's Guide to Writing in the 21 st Century (2014), Pinker, Steven. ( amazon link ) Penrose, A. M., & Katz, S. B. (1998). Writing in the Sciences: Exploring Conventions of Scientific Discourse . New York: St. Martin's Press, Inc. American Psychological Association. (2009). Publication manual of the American Psychological Association (6 th ed.). Washington, DC: American Psychological Association Writing assistance. THE CENTER FOR WRITING offers free one-to-one writing assistance to undergraduate and graduate students, with appointments up to 45 minutes. Nonnative speaker specialists are available. For more information, see http://writing.umn.edu . Psychology department resources: http://writing.psych.umn.edu/student-resources **Grade Requirements ** There will be programming assignments and a final project . The grade weights are: Exercise/programming assignments: 55% Final project in-class presentations: 5 % Final project : 40% (five parts: 2% (title and outline) +5%(first draft) +5% (peer commentary) +8% (cover letter response) + 20% (final draft)) The programming assignments will use the Mathematica programming environment. No prior experience with Mathematica is necessary. Assignment due By the 6 am on the day after the nominal due date. _** Late Policy : Assignments turned in within 24 hours following the due date will have 15% deducted from the assignment score. Assignments turned in between 24 and 48 hours following the due date will have 30% deducted from the score. Assignments more than 48 hours late will receive a score of zero.**_","title":"Writing"},{"location":"courses/PSY5036F2019/#lectures","text":"Check this section before each class for recent additions and revisions. (5036W Course material from 2017) Lecture notes are in Mathematica Notebook and pdf format. You can download the Mathematica notebook files below to view with Mathematica or Wolfram CDF Player (which is free). [University Calendar](http://onestop.umn.edu/onestop/calendar.html) **Date** **Lecture** _**Main Readings**_ **Supplementary Material** **Assignments due** **I. Introduction** Sep 4 1\\. Introduction to Computational Vision _1.IntroToComputationalVision.nb _ Olshausen, B. A. (2013). Perception as an Inference Problem. In M. Gazzaniga (Ed.), The New Cognitive Neurosciences, 5th Edition (pp. 1\u00e2\u20ac\u201c22). MIT Press. (pp. 1\u00e2\u20ac\u201c18). MIT Press. Screencast: [http://www.wolfram.com/broadcast/screencasts/handsonstart/](http://www.wolfram.com/broadcast/screencasts/handsonstart/) (WITH AUDIO)[ ](Lectures/1_MultidisciplinaryStudy/FoxApertures2.mov)Check out demos under: **Life Sciences/Cognitive Science/Perception** and **Engineering & Technology/Image Processing** on the Mathematica Demonstrations site: [http://demonstrations.wolfram.com/](http://demonstrations.wolfram.com/) _Kersten, D., & Yuille, A. (2003). Bayesian models of object perception. Current Opinion in Neurobiology, 13(2), 1-9. _ EV: Section 1 Sep 9 2.Limits to Vision _2.LimitsToVision.nb__ Hecht, S., Shlaer, S., & Pirenne, M. H. (1942). Energy, quanta, and vision. Journal of General Physiology, 25, 819-840. _ Barlow, H. B. (1981). Critical Limiting Factors in the Design of the Eye and Visual Cortex. Proc. Roy. Soc. Lond. B, 212, 1-34. Baylor, D. A., Lamb, T. D., & Yau, K. W. (1979). Responses of retinal rods to single photons. Journal of Physiology, Lond., 288, 613-634. Tinsley, J. N., Molodtsov, M. I., Prevedel, R., Wartmann, D., Pons, J. E. E., Lauwers, M., & Vaziri, A. (2016). Direct detection of a single photon by humans. Nature Communications, 7, 1\u20139. Sep 11 3\\. The Ideal Observer _3.TheIdealObserver.nb _ ProbabilityOverview.nb Griffiths, T. L., & Yuille, A. (2008). A primer on probabilistic inference. In M. Oaksford and N. Chater (Eds.). The probabilistic mind: Prospects for rational models of cognition. Oxford: Oxford University Press [(pdf](../../coursepapers/GriffithsYuilleProbPrimerTICsmmc1.pdf)). Try your luck against an ideal discriminator of dot density YesNoDotDiscriminationDemo.nb Upload Assignment #1 to [Canvas ](/courses/132509/assignments/701580) Assignment_1_Mathematica.nb Sep 16 4\\. Ideal observer analysis: Humans vs. ideals. Neurons vs. ideals _4.IdealObserverAnalysis.nb_ Kersten and Mamassian (2008), Ideal observer theory. The New Encyclopedia of Neuroscience, Squire et al., editors (pdf). Geisler, W. S. (2011). Contributions of ideal observer theory to vision research. Vision Research, 51(7), 771\u2013781. Burgess, A. E., Wagner, R. F., Jennings, R. J., & Barlow, H. B. (1981)_. Efficiency of human visual signal discrimination. Science, 214(4516), 93-94\\._ Deneve, S., Latham, P. E., & Pouget, A. (1999). Reading population codes: a neural implementation of ideal observers. Nature Neuroscience, 2(8), 740\u2013745. Measure your absolute efficiency to discriminate dot density using a 2AFC task 2AFCDotDiscriminationDemo.nb **II. Image formation, pattern synthesis** Sep 18 5.Psychophysics: tools & techniques _5.Psychophysics.nb[](Lectures/5_PsychophysicsSKEobserver/5_Psychophysics.nb) _ SKEDetection2AFCInLineDisplay.nb Farell, B. & Pelli, D. G. (1999) Psychophysical methods, or how to measure a threshold and why. In R. H. S. Carpenter & J. G. Robson (Eds.), Vision Research: A Practical Guide to Laboratory Methods, New York: Oxford University (Press.http://psych.nyu.edu/pelli/ Morgenstern, Y., & Elder, J. H. (2012). Local Visual Energy Mechanisms Revealed by Detection of Global Patterns. Journal of Neuroscience, 32(11), 3679\u20133696\\. For a free Matlab psychophysics package, see: [http://psychotoolbox.org](http://psychtoolbox.org/) For a free Python psychophysics package, see: [http://www.psychopy.org](http://www.psychopy.org) Sep 23 6\\. Bayesian decision theory & perception _6.BayesDecisionTheory.nb _ _Geisler, W. S., & Kersten, D. (2002). Illusions, perception and Bayes. Nat Neurosci, 5(6), 508-510\\. ([pdf](http://gandalf.psych.umn.edu/%7Ekersten/kersten-lab/papers/GeislerKerstennn0602-508.pdf))_ [EV Section 3](../../coursepapers/YuilleKerstenFinalChapter2016.pdf#3) Sep 25 7\\. Limits to spatial resolution, image modeling, introduction to linear systems _7.ImageModelLinearSystems.nb _ _Campbell, F. W., & Green, D. (1965). Optical and retinal factors affecting visual resolution. Journal of Physiology (Lond.), 181, 576-593\\. ([pdf](../../coursepapers/CampbellGreen_JP1965.pdf))_ Williams, D. R. (1986). Seeing through the photoreceptor mosaic. 9(5), 193-197. LinearAlgebraReview.nb Convolutions_Tutorial.nb IPython convolutions notebook Upload Assignment #2 to [Canvas](https://ay17.moodle.umn.edu/course/view.php?id=4100) Problem_Set_2.nb **III. Early visual coding** Sep 30 8\\. Linear systems analysis _8.LinearSystemsOptics.nb _ EV: Section 2 _CSF.gif_ Tutorials: Fourier_neural_image.nb Oct 2 9\\. Features and filters. Spatial filter models of early human vision _9.NeuralSpatialFiltering.nb _ Campbell, F. W., & Robson, J. R. (1968). Application of Fourier Analysis to the Visibility of Gratings. Journal of Physiology 197, 551-566. De Valois, R. L., Albrecht, D. G., & Thorell, L. G. (1982). Spatial frequency selectivity of cells in macaque visual cortex. Vision Res, 22(5), 545-559. Watson, A. B. (1987). Efficiency of a model human image code. J Opt Soc Am A, 4(12), 2401-2417. IPython demo of gabor filtering Steerable pyramids: http://www.cns.nyu.edu/~eero/steerpyr/ Oct 7 10\\. Features and filters. Local processing & image analysis _10.ImageProcessing.nb _ Gollisch, T., & Meister, M. (2010). Eye Smarter than Scientists Believed: Neural Computations in Circuits of the Retina. Neuron, 65(2), 150\u2013164. Albrecht, D. G., De Valois, R. L., & Thorell, L. G. (1980). Visual cortical neurons: are bars or gratings the optimal stimuli? Science, 207(4426), 88-90. Adelson, E. H., & Bergen, J. R. (1991). The plenoptic function and the elements of early vision. In M. S. Landy & J. A. Movshon (Eds.), Computational Models of Visual Processing. Cambridge, MA: The MIT Press: A Bradford Book. ClassificationImage demo ([ReverseCorrelation.nb](Reverse%20correlation/ReverseCorrelation.nb)) Ahumada, A. J., Jr. (2002). Classification image weights and internal noise level estimation. J Vis, 2(1), 121-131\\. ([pdf)](Reverse%20correlation/Ahumada-2002-jov-2-1-8.pdf) Upload Assignment 3 to [Canvas](https://ay17.moodle.umn.edu/course/view.php?id=4100) Problem_Set_3.nb [](Grading,%20Exercises%20&%20Exams/Assignments_due/Assignmt_2_Convolve.nb) Oct 9 11\\. Coding efficiency: Retina _11.CodingEfficiency.nb _ Geisler, W. S. (2008). Visual perception and the statistical properties of natural scenes. Annu Rev Psychol, 59, 167-192\\. Laughlin, S. (1981). A simple coding procedure enhances a neuron's information capacity. Z Naturforsch [C], 36(9-10), 910-912. Atick, J. J., & Redlich, A. N. (1992). What does the retina know about natural scenes? Neural Computation, 4(2), 196\u2013210\\. Meister, M., & Berry, M. J., 2nd. (1999). The neural code of the retina. Neuron, 22(3), 435-450.[(pdf](../../coursepapers/meister+berry_99.pdf)) Srinivasan, M. V., Laughlin, S. B., & Dubs, A. (1982). Predictive coding: a fresh view of inhibition in the retina. Proc R Soc Lond B Biol Sci, 216(1205), 427-459. IPython demo of natural image statistics Oct 14 12\\. Coding efficiency: Cortex _12.SpatialCodingEfficiency.nb _ _Simoncelli, E. P., & Olshausen, B. A. (2001). Natural image statistics and neural representation. Annu Rev Neurosci, 24, 1193-1216._ ContrastNormalizationNotes.nb Laughlin, S. B., de Ruyter van Steveninck, R. R., & Anderson, J. C. (1998). The metabolic cost of neural information. Nat Neurosci, 1(1), 36-41. Lennie, P. (2003). The cost of cortical computation. Curr Biol, 13(6), 493-497.[](../../coursepapers/LennieCurBio2003.pdf) Multi-resolution, image pyramids, and efficient coding: JepsonFleet2005pyramids_notes.pdf AdelsonPyramidRCA84.pdf **IV. Intermediate-level vision, integration, grouping** Oct 16 13\\. Edge detection 13.EdgeDetection.nb Hubel, D. H., & Wiesel, T. N. (1977). Ferrier lecture. Functional architecture of macaque monkey visual cortex. Proc R Soc Lond B Biol Sci, 198(1130), 1-59. IPython demo of statistical edge detection Oct 21 14\\. Objects and scenes from images. The visual cortical pathways and hierarchy. _14.ScenesfromImages.nb __ von der Heydt R (2003) Image parsing mechanisms of the visual cortex. In: The Visual Neurosciences (Werner JS, Chalupa LM, eds.), pp 1139-1150\\. Cambridge, Mass.: MIT press._ Kersten, D. J., & Yuille, A. L. (2014). Inferential Models of the Visual Cortical Hierarchy. In M. S. Gazzaniga & G. R. Mangun (Eds.), The New Cognitive Neurosciences, 5th Edition (pp. 1\u00e2\u20ac\u201c22). MIT Press.[](http://vision.psych.umn.edu/users/kersten//kersten-lab/coursepapers/KerstenYuilleNewCogNeuro2014.pdf) Zhou H, Friedman HS, von der Heydt R (2000) Coding of border ownership in monkey visual cortex. J Neuroscience 20: 6594-6611. Oct 23 15\\. Scene-based generative models _15.SurfaceGeometryDepth.nb _ _Kersten, D., Mamassian, P., & Yuille, A. (2004). Object perception as Bayesian Inference. Annual Review of Psychology, 55, 271-304. _ Oct 28 16\\. Shape-from-X _16.ShapeFromX.nb _ Reflectance map: Shape from shading: Horn BKP (1986) Robot Vision. Cambridge MA: MIT Press. Ch 11 Barron, J. T., & Malik, J. (2015). Shape, Illumination, and Reflectance from Shading. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(8), 1670\u00e2\u20ac\u201c1687\\. http://doi.org/10.1109/TPAMI.2014.2377712 Belhumeur, P. N., Kriegman, D. J., & Yuille, A. (1997). The Bas-Relief Ambiguity. ([pdf](https://pdfs.semanticscholar.org/71ac/0dc7634e4a56fd41dfac270ec5883fcbb44f.pdf)) Johnson, M. K., & Adelson, E. H. (2011). Shape Estimation in Natural Illumination. Computer Vision and Pattern Recognition (CVPR), 2553\u20132560. Muryy, A. A., Welchman, A. E., Blake, A., & Fleming, R. W. (2013). Specular reflections and the estimation of shape from binocular disparity. Proceedings of the National Academy of Sciences of the United States of America, 110(6), 2413\u20132418. cube.mov random.mov Oct 30 17\\. Shape from shading Overview of python/ipython for computational vision[ ](https://wakari.io/sharing/bundle/kersten/Lect_19Intro_Python) _17\\. Shape from shading.nb_ Lect_17Intro_Python.ipynb (source) _17\\. IPython notebook_ Demos by Weichao Qiu and Dan Kersten, supplement to _**Early Vision**._ Yuille and Kersten. A chapter in _From Neuron to Cognition via Computational Neuroscience_, M.A. Arbib, James J. Bonaiuto Editors, Cambridge MA: The MIT Press, in 2016 [Anaconda](https://store.continuum.io/cshop/anaconda/) python installation recommended. We will use [Juypter/IPython](http://ipython.org), a browser-based notebook interface for python. See [here](http://nbviewer.ipython.org/github/ipython/ipython/blob/1.x/examples/notebooks/Part%205%20-%20Rich%20Display%20System.ipynb) for illustrations of IPython cell types, and [here](https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks) for a collection of sample notebooks. Look [here](http://iacs-courses.seas.harvard.edu/courses/am207/blog/installing-python.html) for some good tips on installation, as well as the parent directory for excellent ipython-based course material on scientific computing using Monte Carlo methods. For a quick start to scientific programming, see: [http://nbviewer.ipython.org/gist/rpmuller/5920182](http://nbviewer.ipython.org/gist/rpmuller/5920182) For a comphrensive coverage of scientific python see[:https://scipy-lectures.github.io](https://scipy-lectures.github.io) And for a ground-up set of tutorials on python see: [http://learnpythonthehardway.org/book/](http://learnpythonthehardway.org/book/) Switching from matlab to python? [http://wiki.scipy.org/NumPy_for_Matlab_User](http://mathesaurus.sourceforge.net/matlab-numpy.html) ProjectIdeasF2015.nb Nov 4 18\\. Motion: optic flow _18.MotionOpticFlow.nb _ _OpenCV python demo:_ [OpticFlowSparse.ipynb](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/Lectures/18.MotionOpticFlow/OpticFlowSparse.ipynb) needs: [648aa10.avi](Lectures/17_PythonForVision/648aa10.avi) Horn, B. K. P., & Schunck, B. G. (1981). Determining Optical Flow. Artificial Intelligence, 17, 185-203. Optic Flow (2013) Florian Raudies, Scholarpedia, 8(7):30724\\. doi:10.4249/scholarpedia.30724 (with available matlab code) Optic flow matlab code from Michael Black's lab. Borst, A. (2007). Correlation versus gradient type motion detectors: the pros and cons. Philos Trans R Soc Lond B Biol Sci, 362(1479), 369-374. [http://web.mit.edu/persci/people/adelson/illusions_demos.html](http://web.mit.edu/persci/people/adelson/illusions_demos.html) [IPython aperture demo](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/Lectures/17_PythonForVision/Aperture%20demo.ipynb) EV: Section 2.4 FV: Chapter 10 Nov 6 19\\. Motion: biological, human perception _19.MotionHumanPerception.nb _ _Weiss, Y., Simoncelli, E. P., & Adelson, E. H. (2002). Motion illusions as optimal percepts. Nat Neurosci, 5(6), 598-604. ([pdf](../../coursepapers/WeissSimonAdelNatNeu2002.pdf))_ Heeger, D. J., Simoncelli, E. P., & Movshon, J. A. (1996). Computational models of cortical visual processing. Proc Natl Acad Sci U S A, 93(2), 623-627\\. ([pdf](../../coursepapers/Heeger96-reprint%20PNAS.pdf)) [http://demonstrations.wolfram.com/DisappearingDotIllusion/](http://demonstrations.wolfram.com/DisappearingDotIllusion/) [http://www.biomotionlab.ca/Demos/BMLwalker.html](http://www.biomotionlab.ca/Demos/BMLwalker.html) EV: Section 4.4 FV: Chapter 10 Nov 11 20\\. Material perception _20.SurfaceMaterial.nb _ V1 and lightness Doerschner, K., Fleming, R. W., Yilmaz, O., Schrater, P. R., Hartung, B., & Kersten, D. (2011). Visual motion and the perception of surface material. Current Biology, 21(23), 2010\u20132016. Fleming, R. W., Dror, R. O., & Adelson, E. H. (2003). Real-world illumination and the perception of surface reflectance properties. J Vis, 3(5), 347-368\\. _Adelson, E. H. (1993). Perceptual organization and the judgment of brightness. Science, 262, 2042-2044 _ Boyaci, H., Fang, F., Murray, S. O., & Kersten, D. (2007). Responses to lightness variations in early human visual cortex. Curr Biol, 17(11), 989-993 ([pdf](../../coursepapers/BoyaciCurrBiol2007.pdf))_[http://www.bilkent.edu.tr/~hboyaci/Vision/](http://www.bilkent.edu.tr/%7Ehboyaci/Vision/)_ [http://web.mit.edu/persci/people/adelson/checkershadow_illusion.html](http://web.mit.edu/persci/people/adelson/checkershadow_illusion.html) [http://gandalf.psych.umn.edu/users/kersten/kersten-lab/demos/transparency.html](http://gandalf.psych.umn.edu/users/kersten/kersten-lab/demos/transparency.html) [http://gandalf.psych.umn.edu/~kersten/kersten-lab/demos/MatteOrShiny.html](http://gandalf.psych.umn.edu/%7Ekersten/kersten-lab/demos/MatteOrShiny.html) Upload Assignment 5 to [Canvas](https://ay17.moodle.umn.edu/course/view.php?id=4100) texture_classification_plot_gabor.ipynb Upload Final project title & paragraph outline to [C](https://ay17.moodle.umn.edu/course/view.php?id=4100)anvas Nov 13 21\\. Texture. _21.Texture.nb _ Freeman, J., & Simoncelli, E. P. (2011). Metamers of the ventral stream. Nature Publishing Group, 14(9), 1195-1201\\. http://doi.org/10.1038/nn.2889 Heeger DJ and Bergen JR, Pyramid Based Texture Analysis/Synthesis, Computer Graphics Proceedings, p. 229-238, 1995\\. ([pdf)](../../coursepapers/heeger-siggraph95.pdf). EfrosTextureSynthesis.ipynb From: [https://github.com/rbaravalle/efros](https://github.com/rbaravalle/efros) [img2.png](Lectures/21.%20Texture/img2.png) A sample: [out2.png](Lectures/21.%20Texture/out2.png) Nov 18 22.Science writing (Thanksgiving week) _22.ScienceWriting.nb_ Gopen & Swan, 1990 ([pdf](../../coursepapers/GopenSwan1990.pdf)) [UM Psychology](http://writing.psych.umn.edu/student-resources) Nov 20 23.Perceptual integration _23.PerceptualIntegration.nb _ McDermott, J., Weiss, Y., & Adelson, E. H. (2001). Beyond junctions: nonlocal form constraints on motion interpretation. Perception, 30(8), 905-923\\. ([pdf](../../coursepapers/McDermottbeyond_junctions.pdf)) [http://www.perceptionweb.com/perception/perc0801/square.html](http://www.perceptionweb.com/perception/perc0801/square.html) Hillis, J. M., Ernst, M. O., Banks, M. S., & Landy, M. S. (2002). Combining sensory information: mandatory fusion within, but not between, senses. Science, 298(5598), 1627-1630.([pdf](../../coursepapers/HillisErnstBanksLandyscience02.pdf)) Ernst, M. O., & Banks, M. S. (2002). Humans integrate visual and haptic information in a statistically optimal fashion. Nature, 415(6870), 429-433. Stocker, A. A., & Simoncelli, E. (2008). A Bayesian model of conditioned perception. Advances in Neural Information Processing Systems, 20, 1409-1416. [IPython demo of ideal integration](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5036W2015/ArbibFinalChapterJun17_2015/Demos/ipynb/5.Cue%20Combination.ipynb) EV: Section 5 **V. High-level vision** Nov 25 24\\. Object recognition I _24.ObjectRecognition.nb _ _DiCarlo, J. J., Zoccolan, D., & Rust, N. C. (2012). How does the brain solve visual object recognition? Neuron, 73(3), 415\u2013434. _ Liu, Z., Knill, D. C., & Kersten, D. (1995). Object Classification for Human and Ideal Observers. Vision Research, 35(4), 549-568\\. ([pdf)](../../papers/LiuKnillKersten95.pdf) Tjan, B., Braje, W., Legge, G. E., & Kersten, D. (1995). Human efficiency for recognizing 3-D objects in luminance noise. Vision Research, 35(21), 3053-3069. Tanaka K (2003) Columns for complex visual object features in the inferotemporal cortex: clustering of cells with similar but slightly different stimulus selectivities. Cerebral cortex 13:90-99. Serre, T., Oliva, A., & Poggio, T. (2007). A feedforward architecture accounts for rapid categorization. Proc Natl Acad Sci U S A, 104(15), 6424-6429\\. Yamins, D. L. K., Hong, H., Cadieu, C. F., Solomon, E. A., Seibert, D., & DiCarlo, J. J. (2014). Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proceedings of the National Academy of Sciences of the United States of America, 111(23), 8619-8624. Nov 27 25\\. Object recognition II feeforward architectures _25_Bidirectional_I.key.pdf __ Ullman, S., Vidal-Naquet, M., & Sali, E. (2002). Visual features of intermediate complexity and their use in classification. Nat Neurosci, 5(7), 682-687. _ Grill-Spector, K. (2003). The neural basis of object perception. Curr Opin Neurobiol, 13(2), 159-166. Rao, R. P., & Ballard, D. H. (1999). Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat Neurosci, 2(1), 79-87. Bullier, J. (2001). Integrated model of visual processing. Brain Res Brain Res Rev, 36(2-3), 96-107. Tenenbaum JB: Bayesian modeling of human concept learning. In Advances in Neural Information Processing Systems. Edited by Kearns MSS, Solla A, Cohn DA: Cambridge, MA: MIT Press: 1999. Dec 2 26\\. Object recognition III feedback architectures _26_BidirectionalFeedback.key.pdf_ [(pdf](Lectures/26.%20ObjectRecognition_III/26_BidirectionalFeedback.pdf)) _ _ Torralba, A., Oliva, A., Castelhano, M. S., & Henderson, J. M. (2006). Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search. Psychol Rev, 113(4), 766-786. Chikkerur, S., Serre, T., Tan, C., & Poggio, T. (2010). What and where: A Bayesian inference theory of attention. Vision Research, 50(22), 2233\u20132247. Upload Assignment 6 to [Canvas](https://ay17.moodle.umn.edu/course/view.php?id=4100) Problem_Set_6 .nb Dec 4 27\\. Empirical evidence for bidirectional computations 27.EmpiricalEvidenceBidirectionalProcessing Longuet-Higgins, H. C., & Prazdny, K. (1980). The Interpretation of a Moving Retinal Image. Proceedings of the Royal Society of London B, 208, 385-397. Horn BKP (1986) Robot Vision. Cambridge MA: MIT Press., chapter 17 Schrater PR, Kersten D (2000) How optimal depth cue integration depends on the task. International Journal of Computer Vision 40:73-91. Upload a complete DRAFT of FINAL PROJECT to [Canvas](https://ay17.moodle.umn.edu/course/view.php?id=4100) by _** December 4**__**th.**_ Dec 9 28\\. Vision for action, spatial layout, heading. Homegeneous coordinates. _28.SpatialLayoutScenes.nb _ _Kalman filter notes (pdf)_ Upload your peer comments to Canvas by Monday Dec 11th Dec 11 (Last day of class) _In Class Project Presentations_ Drafts returned to you with Instructor comments Dec 21 Upload Final Revised Draft of Project to Canvas. Final Project Assignment . Goal: This course integrates the behavioral, neural and computational principles of perception. Students often find the interdisciplinary integration to be the most challenging aspect of the course. Through writing, you will learn to synthesize results from diverse and typically isolated disciplines. By writing about your project work, you will learn to think through the broader implications of your project, and to effectively communicate the rationale and results of your contribution in words. You will do a final page research report in which you will describe, in the form of a scientific paper, the results of an original computer program on a topic in computational vision. Your final project will involve: 1) a computer program and; 2) a 2000-3000 word final paper describing your project. For your computer project, you will do one of the following: 1) Write a program to simulate a model from the computer vision literature ; 2) Design and program a method for solving some problem in perception. 3) Design and program a psychophysical experiment to study an aspect of human visual perception. The results of your final project should be written up in the form of a short scientific paper or Mathematica Notebook, describing the motivation, methods, results, and interpretation. If you choose to write your program in Mathematica, your paper and program can be combined can be formated as a Mathematica notebook. See: Books and Tutorials on Notebooks. If you do your final project using Python, you can turn your paper in as a Jupyter notebook. Your paper will be critiqued and returned for you to revise and resubmit in final form. You should write for an audience consisting of your class peers. Completing the final paper involves 4 steps. Each step requires that you email a document to the teaching assistant. Outline (2% of grade)** .** You will submit a working title and paragraph outline by the deadline noted in the syllabus. These outlines will be critiqued in order to help you find an appropriate focus for your papers. (Consult with the instructor or TA for ideas well ahead of time). Complete draft (5% of grade). A double-spaced, complete draft of the paper must be turned in by the deadline noted in the syllabus. Papers should be between 2000 and 3000 words. In addition to the title, author and date lines, papers must include the following sections: Abstract, Introduction, Methods, Results, Discussion, and Bibliography. Use citations to motivate your problem and to justify your claims. Cite authors by name and date, e.g. (Marr & Poggio, 1979). Citations should be original sources, not wikipedia. Use a standard citation format, such as APA. (The UM library has information on style guides , and in particular APA style .) Papers must be typed, with a page number on each page. Figures should be numbered and have figure captions. This draft will be reviewed by your instructor and one of you class peers. The point break down for the total 5% is: 2 pts for completing Introduction, 2 pts for completing Methods, 1 pt for completing Discussion) Peer commentary (5% of grade) . You will submit a written commentary (200 to 500 words) on a complete draft of one of your class peers. The project drafts and commentaries will be anonymous. The commentary should provide feedback to improve the quality and clarity of the writing. Final draft (20% of grade) and \"Cover letter\" (8% of grade). The final draft must be turned in by the date noted on the syllabus. The \"Cover letter\" should describe how your revision addressed comments from your peer evaluator and from your instructor. It should itemize key criticisms together with a brief description of the changes you made to your draft manuscript. Some Resources: Student Writing Support: Center for Writing, 306b Lind Hall and satellite locations (612.625.1893) http://writing.umn.edu . NOTE: Plagiarism, a form of scholastic dishonesty and a disciplinary offense, is described by the Regents as follows: Scholastic dishonesty means plagiarizing; cheating on assignments or examinations; engaging in unauthorized collaboration on academic work; taking, acquiring, or using test materials without faculty permission; submitting false or incomplete records of academic achievement; acting alone or in cooperation with another to falsify records or to obtain dishonestly grades, honors, awards, or professional endorsement; altering, forging, or misusing a University academic record; or fabricating or falsifying data, research procedures, or data analysis. http://www1.umn.edu/regents/policies/academic/Code_of_Conduct.html. See too: http://writing.umn.edu/tww/plagiarism/ and http://writing.umn.edu/tww/plagiarism/definitions.html Privacy Statement","title":"Lectures"},{"location":"courses/PSY5038F2018/","text":"# PSY 5038W - Introduction to Neural Networks Fall 2018 \u00b6 Class #: 34494 9:45AM-11:00AM MW Elliott Hall N391 (Course web pages: courses.kersten.org) Instructor: Daniel Kersten, kersten@umn.edu, Office: S212 Elliott Hall, Phone: 625-2589 Office hours: Mondays 11:00 to 12:00 and by appointment. Teaching assistant: Yijun Ge, gexxx119@umn.edu, N10 Elliott Hall Office hours: Wednesdays 11:00 to 12:00 and by appointment. (Note: N10 is in a secured area. Please send email to TA to open door.) Course description. Introduction to large scale parallel distributed processing models in neural and cognitive science. Topics include: linear models, statistical pattern theory, Hebbian rules, self-organization, non-linear models, information optimization, and representation of neural information. Applications to sensory processing, perception, learning, and memory. Prerequisites : Linear algebra, multivariate calculus. Readings \u00b6 Lecture notes (see below ) Software \u00b6 Mathematica \u00b6 Mathematica is the primary programming environment for this course. Students who have registered for the course will have Google Docs access through the Psychology Department's site license . Alternatives: Mathematica is available in several labs on campus, go to http://www.oit.umn.edu/computer-labs/software/index.htm You may wish to purchase Mathematica for Students see http://www.wolfram.com/products/student/mathforstudents/index.html . You can also access Mathematica on the CLA servers: mac (Note: you may have to change the forward slash to a back slash) windows If you never programmed before go here . If you have programming experience, go here . For user help on using Mathematica, see: http://mathematica.stackexchange.com Learning center: http://www.wolfram.com/learningcenter/ Python/Jupyter/IPython \u00b6 http://ipython.org http://jupyter-notebook-beginner-guide.readthedocs.org/en/latest/index.html http://www.scipy.org For an online course in using Python and PsychoPy for research in human vision see: http://nbviewer.ipython.org/github/gestaltrevision/python_for_visres/blob/master/index.ipynb Supplementary \u00b6 http://www.pybrain.org https://code.google.com/p/neurolab/ http://briansimulator.org Writing \u00b6 Gopen, G. D., & Swan, J. A., 1990. The Science of Scientific Writing. American Scientist , 78 , 550-558. ( pdf ) Supplementary: The Sense of Style: The Thinking Person's Guide to Writing in the 21 st Century (2014), Pinker, Steven. ( amazon link ) Penrose, A. M., & Katz, S. B. (1998). Writing in the Sciences: Exploring Conventions of Scientific Discourse . New York: St. Martin's Press, Inc. American Psychological Association. (2009). Publication manual of the American Psychological Association (6 th ed.). Washington, DC: American Psychological Association Writing assistance. THE CENTER FOR WRITING offers free one-to-one writing assistance to undergraduate and graduate students, with appointments up to 45 minutes. Nonnative speaker specialists are available. For more information, see http://writing.umn.edu . Psychology department resources: http://writing.psych.umn.edu/student-resources Supplementary readings \u00b6 * Anderson, James. (1995) Introduction to Neural Networks , MIT Press. _Bishop, C. M. (2006). Pattern recognition and machine learning. New York: Springer. Dayan, P., & Abbott, L. F. (2001). Theoretical neuroscience : computational and mathematical modeling of neural systems. Cambridge, Mass.: MIT Press. Freeman, J. A. (1994). Simulating Neural Networks with Mathematica . Reading, MA: Addison-Wesley Publishing Company. http://library.wolfram.com/infocenter/Books/3485/ * Gershenfeld , N. A. (1999). The nature of mathematical modeling. Cambridge ; New York: Cambridge University Press. _ Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning . MIT Press. ( online ) Hertz, J., Krogh, A., & ;Palmer , R. G. (1991). Introduction to the theory of neural computation (Santa Fe Institute Studies in the Sciences of Complexity ed.). Reading, MA: Addison-Wesley Publishing Company. Koch, C., & Segev , I. (Eds.). (1998). Methods in Neuronal Modeling : From Ions to Networks (2 nd ed.). Cambridge, MA: MIT Press. _* MacKay, D. J. C. (2003). Information theory, inference, and learning algorithms. Cambridge, UK ; New York: Cambridge University Press. http://www.inference.phy.cam.ac.uk/mackay/itila/book.html ***_Murphy, K. P. (2012). Machine Learning: a Probabilistic Perspective. MIT Press. *Neural/Cognitive Science **Physics/Applied Math ***Statistical/machine learning Grade Requirements \u00b6 There will be programming assignments, as well as a final project . The grade weights are: Exercise/programming assignments: 55% Final project presentations: 5 % Final project : 40% (four parts: 2%+5%+5%+28%) The programming assignments will use the Mathematica programming environment. No prior experience with Mathematica is necessary.[ ](http://www2.publabs.umn.edu/publab/text/locations.html)Your completed problem set assignment should be uploaded to Canvas by midnight on the date due. In general you should use the downloaded Mathematica notebook as your template, then add your answers, and then upload the finished assignment. You can copy and paste any code bits you need from the Lecture notebooks. But of course, you cannot copy and paste code or any other answer materials from someone else. * * * Outline & Lecture Notes \u00b6 (Under construction) \u00b6 http://onestop.umn.edu/calendars/ _ (NOTE: Links to revised lecture material below will be posted on the day of the lecture. Links to the pdfs Lecture notes are in Mathematica Notebook and pdf format. You can download the Mathematica notebook files below to view with Mathematica or Wolfram CDF Player (which is free). Lecture Date Lecture Additional Readings & supplementary material Assignments due 1 Sep 5 Introduction [ Mathematica notebook](/courses/71054/files/3310692/download?wrap=1 \"Lect_1_Introduction.nb\") ([ pdf ](/courses/71054/files/3310707/download?wrap=1 \"Lect_1_Introduction.nb.pdf\")) [ Mathematica screencast](http://www.wolfram.com/broadcast/screencasts/handsonstart/) [Top 100 Brain Structures](http://www.med.harvard.edu/AANLIB/cases/caseM/case.html) 2 Sep 10 The neuron [( pdf file](/courses/71054/files/3378180/download?wrap=1 \"Lect_2_TheNeuron.nb.pdf\"))| [ Mathematica notebook](/courses/71054/files/3378177/download?wrap=1 \"Lect_2_TheNeuron-1.nb\") [Hodgkin- Huxley.nb ](/courses/71054/files/3311407/download?wrap=1 \"Hodgkin-Huxley.nb\") [Myelinated neuron (Wolfram Demo)](http://demonstrations.wolfram.com/ActionPotentialPropagationAlongMyelinatedAxons/) Koch & Segev , 2000 [( pdf )](/courses/71054/files/3310978/download?wrap=1 \"Koch_Segev_NN2000.pdf\") Meunier & Segev , 2002 ([ pdf ](/courses/71054/files/3311455/download \"MeunierSegev.pdf\")) 3 Sep 12 Neural Models, McCulloch-Pitt ([ pdf file](/courses/71054/files/3415176/download?wrap=1 \"Lect_3_NeuralModeling.nb.pdf\"))| [ Mathematica notebook](/courses/71054/files/3415175/download?wrap=1 \"Lect_3_NeuralModeling.nb\") Integrate-and-fire models. Chap 14.2 of Koch, C. (2004) [( pdf )](/courses/71054/files/3404515/download?wrap=1 \"Koch2004-1.pdf\") 4 Sep 17 Generic neuron model ([ pdf file](/courses/71054/files/3477521/download?wrap=1 \"Lect_4_GenericModel.nb.pdf\"))| [ Mathematica notebook](/courses/71054/files/3477511/download?wrap=1 \"Lect_4_GenericModel.nb\") [ _ Problem Set 1 _ ](/courses/71054/assignments/285875 \"Problem Set 1\") 5 Sep 19 Lateral inhibition [(](Lectures/Lect_5_LatInhibition/Lect_5_LatInhibition.nb.pdf) [ pdf file](/courses/71054/files/3519528/download?wrap=1 \"Lect_5_LatInhibition.nb.pdf\") )| [ Mathematica notebook](/courses/71054/files/3519521/download?wrap=1 \"Lect_5_LatInhibition.nb\") Hartline (1972) ([ pdf ](/courses/71054/files/3311329/download?wrap=1 \"Hartline72.pdf\")) 6 Sep 24 Matrices ( [ pdf file](/courses/71054/files/3582868/download?wrap=1 \"Lect_6_Matrices.nb.pdf\") )| [ Mathematica notebook](/courses/71054/files/3582875/download?wrap=1 \"Lect_6_Matrices.nb\") 7 Sep 26 Linear systems, learning & memory ( [ pdf file](/courses/71054/files/3620907/download?wrap=1 \"Lect_7_LinearSystems.nb.pdf\") )| [ Mathematica notebook](/courses/71054/files/3620901/download?wrap=1 \"Lect_7_LinearSystems.nb\") 8 Oct 1 Linear recall, association and memory simulations ([ pdf file](/courses/71054/files/3693072/download?wrap=1 \"Lect_8_HeterAuto.nb.pdf\"))| [ Mathematica notebook](/courses/71054/files/3693069/download?wrap=1 \"Lect_8_HeterAuto.nb\") [ _ Problem Set 2 _ ](/courses/71054/files/3529157/download?wrap=1 \"Problem_Set_2.nb\") Due Tuesday Oct 2. 9 Oct 3 Overview of non-linear networks, discriminative models, Perceptron, SVMs ([ pdf file](/courses/71054/files/3740368/download?wrap=1 \"Lect_9_Perceptron.nb.pdf\"))| , [Mathematica notebook](/courses/71054/files/3740361/download?wrap=1 \"Lect_9_Perceptron.nb\") SVMs: [ J\u00e4kel et al., (2009)](/courses/71054/files/3311336/download?wrap=1 \"JakelTICsKernelMethods2009.pdf\") J[\u00e4kel](/courses/71054/files/3311334/download?wrap=1 \"Jakel_etal_2007Preprint_4784[0].pdf\") [et al., (2007)](/courses/71054/files/3311334/download?wrap=1 \"Jakel_etal_2007Preprint_4784[0].pdf\") Mathematica SVMs: Nilsson, Bj\u00f6rkegren & Tegn\u00e9r (2006) MathSVMv7.nb Fisher's linear discriminant notes ( pdf ) Mathematica notebook (updated) 10 Oct 8 Supervised learning as regression, Widrow -Hoff, backprop & deep learning, ([ pdf file](/courses/71054/files/3815215/download?wrap=1 \"Lect_10_RegressWid.nb.pdf\"))| [ Mathematica notebook](/courses/71054/files/3815213/download?wrap=1 \"Lect_10_RegressWid.nb\") [ Backpropagation.m ](/courses/71054/files/3723598/download?wrap=1 \"Backpropagation.m\") XOR backpropagation demo. [ Mathematica notebook](/courses/71054/files/3815263/download?wrap=1 \"MultiLayerBackprop.nb\") [LeNet-5](http://yann.lecun.com/exdb/lenet/) Poirazi , Brannon & Mel (2003) ([ pdf ](/courses/71054/files/3311351/download?wrap=1 \"Poirazi2003Pyramidal_neuron_as_two-layer_neural_network.pdf\")) Williams (1992) ([ pdf )](/courses/71054/files/3311362/download?wrap=1 \"williams86.pdf\") 11 Oct 10 Hopfield networks [( pdf file](/courses/71054/files/3857749/download?wrap=1 \"Lect_11_Hopfield.nb.pdf\"))| [ Mathematica notebook](/courses/71054/files/3857745/download?wrap=1 \"Lect_11_Hopfield.nb\") Hopfield (1982) ([ pdf ](/courses/71054/files/3311374/download?wrap=1 \"Hopfield1982.pdf\")) Marr & Poggio (1976) ([ pdf ](/courses/71054/files/3311378/download?wrap=1 \"MarrPoggio1976.pdf\")) Hopfield (1984) ([ pdf ](/courses/71054/files/3311375/download?wrap=1 \"Hopfield1984.pdf\")) Durstewitz et al. (2000) ([ pdf )](/courses/71054/files/3311383/download?wrap=1 \"dusterwitz00.pdf\") [IPython](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5038WF2014/Lectures/Lect_12_Hopfield/HopfieldTwoNeuronDemo.ipynb) (Jupyter) demo of Hopfield Stereo correspondence. [ Mathematica demo](/courses/71054/files/3857853/download?wrap=1 \"Correspondence_HopfieldDis.nb\"). [IPython demo.](http://nbviewer.jupyter.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5038WF2014/Lectures/Lect_11_Hopfield/HopfieldStereo.ipynb) 12 Oct 15 Boltzmann machine ([ pdf file](/courses/71054/files/3932721/download?wrap=1 \"Lect_12_Boltzmann.nb.pdf\"))| [ Mathematica notebook](/courses/71054/files/3932718/download?wrap=1 \"Lect_12_Boltzmann.nb\") Berkes , P., Orban , G., Lengyel , M., & Fiser , J. (2011). Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment. Science, 331(6013), 83\\. ([ pdf ](/courses/71054/files/3312953/download?wrap=1 \"Berkes2011Spontaneous_cortical_activity_reveals_hallmarks_of_an_optimal_internal_model_of_the_environment.pdf\")) [ _ _Problem Set_ 3 _ ](/courses/71054/files/3723564/download?wrap=1 \"Problem_Set_3.nb\") _ Due Tuesday Oct 16. _ 13 Oct 17 Probability and neural networks ([ pdf file](/courses/71054/files/3971494/download?wrap=1 \"Lect_13_Probability.nb.pdf\"))| [ Mathematica notebook](/courses/71054/files/3971493/download?wrap=1 \"Lect_13_Probability.nb\") Griffiths and Yuille (2006) ([ pdf ](/courses/71054/files/3312980/download?wrap=1 \"GriffithsYuilleProbPrimerTICsmmc1.pdf\")) Kersten, D., & Yuille , A. (2003). Bayesian models of object perception. Current Opinion in Neurobiology, 13(2), 1-9\\. ([ pdf ](/courses/71054/files/3312991/download?wrap=1 \"KerstenYuilleCurrOpinNeu2003.pdf\")) Kersten D. & Yuille, A.L (2013) .Vision: Bayesian Inference and Beyond. The New Visual Neurosciences. John S. Werner and Leo M. Chalupa (Editors) MIT Press. Cambridge MA..[(pdf)](/courses/71054/files/4073103/download?wrap=1 \"Kersten2013Vision_Bayesian_Inference_and_Beyond.pdf\") 14 Oct 22 Multivariate distributions, Regression, Interpolation, perceptual completion ([ pdf ](/courses/71054/files/4032724/download?wrap=1 \"Lect14_MultinormalsRegressionSculptingCost.nb.pdf\")) [ Mathematica notebook](/courses/71054/files/4032721/download?wrap=1 \"Lect14_MultinormalsRegressionSculptingCost.nb\") Notes on overfitting and the bias/variance dilemma ([Mathematica notebook](/courses/71054/files/4275562/download?wrap=1 \"NotesOnBiasVariance.nb\")) 15 Oct 24 Graphical models ([ pdf ](/courses/71054/files/4073219/download?wrap=1 \"Lect_15_ProbabilityGraphicalModels-1.nb.pdf\")) [ Mathematica notebook](/courses/71054/files/4073214/download?wrap=1 \"Lect_15_ProbabilityGraphicalModels-1.nb\") Pattern Recognition and Machine Learning, _ Chapter 8: Graphical Models _. Christopher M. Bishop [( pdf ](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/05/Bishop-PRML-sample.pdf)) Weiss Y. ([ pdf ](http://www.cs.huji.ac.il/%7Eyweiss/nips96.pdf)) Belief propagation tutorial by James Coughlan ( [pdf](http://www.ski.org/sites/default/files/publications/bptutorial.pdf) ). Ma, W. J. (2012). Organizing probabilistic models of perception. Trends in Cognitive Sciences, 16(10), 511\u2013518\\. ( pdf ) 16 Oct 29 Belief Propagation: regression and interpolation revisited [(pdf](/courses/71054/files/4136590/download?wrap=1 \"Lect_16_BeliefProp.nb.pdf\") ) [Mathematica notebook](/courses/71054/files/4136599/download?wrap=1 \"Lect_16_BeliefProp.nb\") [James Coughlan's BP tutorial](http://computerrobotvision.org/2009/tutorial_day/crv09_belief_propagation_v2.pdf) PROJECT GUIDELINES ([pdf](/courses/71054/files/4136615/download?wrap=1 \"FinalProjectskey.key.pdf\")) SAMPLE PROJECT IDEAS from previous years( [pdf](/courses/71054/files/4136646/download?wrap=1 \"SampleFinalProjects.nb.pdf\") ) Sample abstracts from past students For demonstration style projects, see the [Wolfram Demonstration site](http://demonstrations.wolfram.com/) How To Do Research. William T. Freeman (2013), ([link)](http://people.csail.mit.edu/billf/publications/How_To_Do_Research.pdf) [ _ Problem Set 4 _ ](/courses/71054/files/3973764/download?wrap=1 \"Problem_Set_4.nb\") _ _ Due Tuesday Oct 30. _ _ 17 Oct 31 Supervised learning: neural networks in the context of machine learning ( [ pdf ](/courses/71054/files/4180102/download?wrap=1 \"Lect17_SupervisedNNsAndML.nb.pdf\") ) [ Mathematica notebook ](/courses/71054/files/4180101/download?wrap=1 \"Lect17_SupervisedNNsAndML.nb\") Hegde , J., Bart, E., & Kersten, D. (2008). Fragment-Based Learning of Visual Object Categories. Curr Biol. 18, 597-601 ([pdf](http://download.cell.com/current-biology/pdf/PIIS096098220800448X.pdf?intermediate=true)) 18 Nov 5 Deep learning, DCNNs Feedforward architectures for recognition Keynote presentation ([pdf](/courses/71054/files/4248803/download?wrap=1 \"CNNsLect18.pdf\")) Serre , T., Oliva , A., & Poggio , T. (2007). A feedforward architecture accounts for rapid categorization. Proc Natl Acad Sci U S A, 104(15), 6424-6429. Hong, H., Yamins, D. L. K., Majaj, N. J., & DiCarlo, J. J. (2016). Explicit information for category-orthogonal object properties increases along the ventral stream. _Nature Neuroscience_, _19_(4), 613\u2013622\\. [https://doi.org/10.1038/nn.4247](https://doi.org/10.1038/nn.4247) Kirchner, H., & Thorpe, S. J. (2006). Ultra-rapid object detection with saccadic eye movements: Visual processing speed revisited. Vision Research, 46(11), 1762\u20131776\\. doi:10.1016/j.visres.2005.10.002 ([pdf](http://www.sciencedirect.com/science/article/pii/S0042698905005110)) Kersten D. & Yuille, A.L. (2014) Inferential Models of the Visual Cortical Hierarchy. The New Cognitive Neurosciences, 5th Edition.([draft pdf)](http://gandalf.psych.umn.edu/users/kersten/kersten-lab/coursepapers/KerstenYuilleNewCogNeuro2014.pdf) 19 Nov 7 DCNNs Keynote presentation ([pdf](/courses/71054/files/4288503/download?wrap=1 \"Lect19DCNNs-1.pdf\")) [ Mathematica notebook with demos](/courses/71054/files/4360760/download?wrap=1 \"Lect19DeepLearningDCNNS-1.nb\") (revised 11/12/18) Notes on Bayesian decision theory. Utility, loss, and empirical risk ([Mathematica notebook](/courses/71054/files/4275594/download?wrap=1 \"NotesOnDecisionTheory.nb\")) Geisler , W. S., & Kersten, D. (2002). Illusions, perception and Bayes. Nat Neurosci , 5(6), 508-510\\. ([ pdf ](/courses/71054/files/4073138/download?wrap=1 \"Nat_Neurosci_2002_Geisler-2.pdf\")) 20 Nov 12 Recurrent neural networks (RNNs), sequence modeling [Keynote presentation](/courses/71054/files/4364075/download?wrap=1 \"RNNs-1.key\") [(pdf](/courses/71054/files/4364079/download?wrap=1 \"RNNs.pdf\")[)](/courses/71054/files/4360747/download?wrap=1 \"RNNs.key\") [ Mathematica notebook with demos ](/courses/71054/files/4360750/download?wrap=1 \"RNNMathematicaIIntro.nb\") Kalman filter notes ([pdf](/courses/71054/files/4360788/download?wrap=1 \"kalman.pdf\")) Kalman filter [Mathematica demo](/courses/71054/files/4360856/download?wrap=1 \"KalmanTracking.nb\")Mar 21 Nov 14 Markov chain Monte Carlo (MCMC) sampling [Mathematica notebook](/courses/71054/files/4485616/download?wrap=1 \"Lect_21_MoreSamplingMCMC-1.nb\") ([pdf](/courses/71054/files/4485620/download?wrap=1 \"Lect_21_MoreSamplingMCMC-1.nb.pdf\")) Lake, B. M., Salakhutdinov, R., & Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350(6266), 1332\u20131338\\. [http://doi.org/10.1126/science.aab3050](http://doi.org/10.1126/science.aab3050) [Metropolis2D.ipynb](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5038WF2014/Lectures/Lect_20_MCMC/Metropolis2D.ipynb) [http://pymc-devs.github.io/pymc/](http://pymc-devs.github.io/pymc/) Recommended pymc tutorials: [http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/) _ [_Problem Set_ 5](/courses/71054/files/4273266/download?wrap=1 \"Problem_Set_5.nb\")[ ](Problem_Sets/Problem_Set_5.nb) _ _ _ Due Tuesday Nov. 20. _ _ 22 Nov 19 MCMC continued (see Lecture 21 notebook) For a quick start to scientific programming, see: [http://nbviewer.ipython.org/gist/rpmuller/5920182](http://nbviewer.ipython.org/gist/rpmuller/5920182) For a list of some notebooks in psychology, neuroscience, and machine learning see: [https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks#psychology-and-neuroscience](https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks#psychology-and-neuroscience) For a comphrensive coverage of scientific python see[:https://scipy-lectures.github.io](https://scipy-lectures.github.io) And for a ground-up set of tutorials on python see: [http://learnpythonthehardway.org/book/](http://learnpythonthehardway.org/book/) Switching from matlab to python? [https://stsievert.com/blog/2015/09/01/matlab-to-python/](https://stsievert.com/blog/2015/09/01/matlab-to-python/) [Final project title & paragraph outline due](/courses/71054/assignments/369425 \"Final Project title and paragraph outline\") (2%) 23 Nov 21 Overview of python and jupyter notebooks for scientific computation /neural networks, and Bayesian computations . Starting python in the middle: [Jupyter notebook on colab](https://drive.google.com/open?id=1xQ7LN-6q7SptF0TdZ_kM2DlN25tE89r0) [Source jupyter notebook](/courses/71054/files/4527474/download?wrap=1 \"Lect_21Intro_Python3.ipynb\"). MCMC sampling using Python3 and PyMC3 [Jupyter notebook on colab](https://colab.research.google.com/drive/1N0CgswSGEpG4XKBy5g2zKO_Ps_gfR9yR) [Source jupyter notebook. ](/courses/71054/files/4527479/download?wrap=1 \"Lect_PyMC3.ipynb\") Lect_21_PyMC (raw [IPython notebook](Lectures/Lect_21_PyMc/Lect_21_PyMC.ipynb)) or [Jupyter nbviewer](http://nbviewer.jupyter.org/url/gandalf.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5038WF2016/Lectures/Lect_21_PyMc/Lect_21_PyMC.ipynb) PyMC2 sprinkler ([raw](Lectures/Lect_21_PyMc/PearlSprinklerPYMC.ipynb)) [Jupyter viewer](https://nbviewer.jupyter.org/url/gandalf.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5038WF2016/Lectures/Lect_21_PyMc/PearlSprinklerPYMC.ipynb) PyMC3 Gaussian mixtures ([raw](Lectures/Lect_21_PyMc/Gaussian%20Mixture%20PYMC3%20example.ipynb)) [Jupyter viewer](https://nbviewer.jupyter.org/url/gandalf.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5038WF2016/Lectures/Lect_21_PyMc/Gaussian%20Mixture%20PYMC3%20example.ipynb) PyMC3 spike rate transitions ([raw](Lectures/Lect_21_PyMc/PYMC3%20Spikes%20Model%20Segmentation.ipynb)) [Jupyter viewer](https://nbviewer.jupyter.org/url/gandalf.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5038WF2016/Lectures/Lect_21_PyMc/PYMC3%20Spikes%20Model%20Segmentation.ipynb) Scikit-learn gaussian mixtures [(raw](Lectures/Lect_21_PyMc/Bayesian%20Gaussian%20mixture%20model%20sklearn%20demo.ipynb)) [Jupyter viewer](https://nbviewer.jupyter.org/url/gandalf.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5038WF2016/Lectures/Lect_21_PyMc/Bayesian%20Gaussian%20mixture%20model%20sklearn%20demo.ipynb) 24 Nov 26 Introduction to neural networks for self-organization Overview of visual system architecture Keynote ([pdf](/courses/71054/files/4602935/download?wrap=1 \"Lect_24_VisualArchitectureLateral-2.pdf\")) AdaptMaps [ Mathematica notebook](/courses/71054/files/4602939/download?wrap=1 \"SelfOrganizationAdaptMaps-1.nb\") ([ pdf ](/courses/71054/files/4602949/download?wrap=1 \"SelfOrganizationAdaptMaps-1.nb.pdf\")) Supplement: [ ContingentAdaptation.nb ](/courses/71054/files/4562382/download?wrap=1 \"ContingentAdaptation.nb\") [](http://www.biomotionlab.ca/Demos/BMLwalker.html) 25 Nov 28 Introduction to neural networks for self-organization continued (see pdfs from previous lecture) Oja's rule and PCA: Sanger (2003) ([ pdf ](http://vision.psych.umn.edu/users/kersten//kersten-lab/coursepapers/SangerPopCodes.pdf)) Ernst, M. O., & Banks, M. S. (2002). Humans integrate visual and haptic information in a statistically optimal fashion. Nature, 415(6870), 429-433\\. ([pdf)](http://vision.psych.umn.edu/users/kersten//kersten-lab/coursepapers/ErnstBanks2002.pdf) Ma, W. J. (2012). Organizing probabilistic models of perception. Trends in Cognitive Sciences, 16(10), 511\u2013518\\. ([pdf](http://vision.psych.umn.edu/users/kersten//kersten-lab/coursepapers/Ma2012Organizing_probabilistic_models_of_perception-1.pdf)) [ 26 ](/courses/71054/files/4685569/download?wrap=1 \"Lect_SelfOrgPCA_SVD_Oja.nb\") [ Dec 3 ](/courses/71054/files/4685569/download?wrap=1 \"Lect_SelfOrgPCA_SVD_Oja.nb\") Efficient coding. PCA, SVD, sparse coding [ Mathematica notebook ](/courses/71054/files/4685576/download?wrap=1 \"Lect_SelfOrgPCA_SVD_Oja-1.nb\") ([ pdf ](/courses/71054/files/4685619/download?wrap=1 \"Lect_SelfOrgPCA_SVD_Oja.nb.pdf\")) Scientific writing and presentations [ Mathematica notebook ](/courses/71054/files/4685626/download?wrap=1 \"ScienceWriting.nb\") [( pdf ](/courses/71054/files/4685628/download?wrap=1 \"ScienceWriting.nb.pdf\")) Gopen & Swan, 1990 ([ pdf )](/courses/71054/files/3313033/download?wrap=1 \"GopenSwan1990.pdf\") [Denis Pelli's advice for scientific writing](http://psych.nyu.edu/pelli/style.html) Ullman, S., Vidal- Naquet , M., & Sali , E. (2002). Visual features of intermediate complexity and their use in classification. Nat Neurosci , 5(7), 682-687. _ [_Problem Set_ 6](/courses/71054/assignments/381057 \"Problem Set 6\") Due December 13 _ 27 Dec 5 Clustering , EM, segmentation [Mathematica notebook](/courses/71054/files/4750417/download?wrap=1 \"Lect_27_ClusteringEM-1.nb\") ([pdf](/courses/71054/files/4750425/download?wrap=1 \"Lect_27_ClusteringEM-1.nb.pdf\")) (updated to work with Mathematica 11.3) Expectation Maximization: Weiss Y. [(](Lectures/Lect_18_EM/EM%20Weiss%20Tutorial.pdf)[ pdf ](http://www.cs.huji.ac.il/%7Eyweiss/emTutorial.pdf)) Neural population codes ([Mathematica notebook](http://vision.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5038WF2016/Lectures/Lect_24_SelfOrgPCA_SVD/Lect_24b_VisualRepCode.nb)) Quiroga , R. Q., Reddy, L., Kreiman , G., Koch, C., & Fried, I. (2005) .([pdf)](http://vision.psych.umn.edu/users/kersten//kersten-lab/coursepapers/GrandmotherCellKoch2005.pdf) Probabilistic neural representations, Poisson-like codes, and the neural integration of information. Keynote presentation ([pdf](Lectures/Lect_24_SelfOrgPCA_SVD/Lect_24_LateralOrgNeuralPopulationCodes.key.pdf)) [ Complete Draft of Final Project (5%)_ **Due Friday December 7**_ ](/courses/71054/assignments/390909 \"Final Project DRAFT\") Dec 10 Class presentations Peer comments on Final Project (5%)_ Due Wednesday December 12_ Dec 12 Last day of classes Class presentations Drafts returned with Instructor and peer comments December 12 Dec 20 End of Semester Submit Final Revised Draft of Project (28%) * * * ### Final Project Assignment This course teaches you how to understand cognitive and perceptual aspects of brain processing in terms of computation. Writing a computer program encourages you to think clearly about the assumptions underlying a given theory. Getting a program to work, however, tests just one level of clear thinking. By writing about your work, you will learn to think through the broader implications of your final project, and to effectively communicate the rationale and results in words. Your final project will involve: 1) a computer simulation and; 2) a 2000-3000 word final paper describing your simulation. For your computer project, you will do one of the following: 1) Devise a novel application for a neural network model studied in the course; 2) Write a program to simulate a model from the neural network literature ; 3) Design and program a method for solving some problem in perception, cognition or motor control. The results of your final project should be written up in the form of a short scientific paper, describing the motivation, methods, results, and interpretation. Your paper will be critiqued and returned for you to revise and resubmit in final form. You should write for an audience consisting of your class peers. You may elect to have your final paper published in the course's web-based electronic journal. Completing the final paper involves 3 steps: Outline . You will submit a working title and paragraph outline by the deadline noted in the syllabus. These outlines will be critiqued in order to help you find an appropriate focus for your papers. ( 2% of grade). (Consult with the instructor or TA for ideas well ahead of time). Complete draft . You will then submit a complete draft of your paper ( 2000-3000 words ). Papers must include the following sections: Abstract, Introduction, Methods, Results, Discussion, and Bibliography. Use citations to motivate your problem and to justify your claims. Figures should be numbered and have figure captions. Cite authors by name and date, e.g. (Marr & Poggio, 1979). Use a standard citation format, such as APA. Papers must be typed, with a page number on each page.Each paper will be reviewed with specific recommendations for improvement. ( 5% of grade) Peer commentary . Each student will submit a paragraph on an anonymous paired project draft ( 5% of grade) Final draft . You will submit a final revision for grading. ( 28% of grade). The final draft must be turned in by the date noted on the syllabus. If you choose to write your program in Mathematica, your paper and program can be combined can be formated as a Mathematica notebook. See: Books and Tutorials on Notebooks. Your paper will be critiqued and returned for you to revise and resubmit in final form. You should write for an audience consisting of your class peers. Some Resources: Student Writing Support: Center for Writing, 306b Lind Hall and satellite locations (612.625.1893) http://writing.umn.edu . Online Writing Center: http://writing.umn.edu/sws/visit/online/index.html NOTE: Plagiarism, a form of scholastic dishonesty and a disciplinaryoffense, is described by the Regents as follows: Scholasticdishonesty means plagiarizing; cheating on assignments or examinations;engaging in unauthorized collaboration on academic work; taking,acquiring, or using test materials without faculty permission; submittingfalse or incomplete records of academic achievement; acting alone or incooperation with another to falsify records or to obtain dishonestlygrades, honors, awards, or professional endorsement; or altering,forging, or misusing a University academic record; or fabricating orfalsifying of data, research procedures, or data analysis. http://regents.umn.edu/sites/regents.umn.edu/files/policies/Student_Conduct_Code.pdf NOTE: Sexual Assault and higher education: Training modules and information The Department of Psychology supports the efforts of the University of Minnesota towards prevention of sexual assault. We encourage all students to participate in the free online training that has been established for undergraduate students and graduate students. The training highlights pertinent issues regarding sexual assault, including, but not limited to: defining healthy relationships, consent, bystander intervention, and gender roles. Haven (for undergraduate students under the age of 25) and Haven Plus (for undergraduates over 25, graduate students, and professional students) is the training available at no cost to University of Minnesota students. Additionally, to learn more about how you can help reduce sexual assault at the University of Minnesota, please visit the Aurora Center . \u00a9 2018 Daniel Kersten, University of Minnesota Privacy Statement","title":"PSY5038F2018"},{"location":"courses/PSY5038F2018/#fall-2018","text":"Class #: 34494 9:45AM-11:00AM MW Elliott Hall N391 (Course web pages: courses.kersten.org) Instructor: Daniel Kersten, kersten@umn.edu, Office: S212 Elliott Hall, Phone: 625-2589 Office hours: Mondays 11:00 to 12:00 and by appointment. Teaching assistant: Yijun Ge, gexxx119@umn.edu, N10 Elliott Hall Office hours: Wednesdays 11:00 to 12:00 and by appointment. (Note: N10 is in a secured area. Please send email to TA to open door.) Course description. Introduction to large scale parallel distributed processing models in neural and cognitive science. Topics include: linear models, statistical pattern theory, Hebbian rules, self-organization, non-linear models, information optimization, and representation of neural information. Applications to sensory processing, perception, learning, and memory. Prerequisites : Linear algebra, multivariate calculus.","title":"Fall 2018"},{"location":"courses/PSY5038F2018/#readings","text":"Lecture notes (see below )","title":"Readings"},{"location":"courses/PSY5038F2018/#software","text":"","title":"Software"},{"location":"courses/PSY5038F2018/#mathematica","text":"Mathematica is the primary programming environment for this course. Students who have registered for the course will have Google Docs access through the Psychology Department's site license . Alternatives: Mathematica is available in several labs on campus, go to http://www.oit.umn.edu/computer-labs/software/index.htm You may wish to purchase Mathematica for Students see http://www.wolfram.com/products/student/mathforstudents/index.html . You can also access Mathematica on the CLA servers: mac (Note: you may have to change the forward slash to a back slash) windows If you never programmed before go here . If you have programming experience, go here . For user help on using Mathematica, see: http://mathematica.stackexchange.com Learning center: http://www.wolfram.com/learningcenter/","title":"Mathematica"},{"location":"courses/PSY5038F2018/#pythonjupyteripython","text":"http://ipython.org http://jupyter-notebook-beginner-guide.readthedocs.org/en/latest/index.html http://www.scipy.org For an online course in using Python and PsychoPy for research in human vision see: http://nbviewer.ipython.org/github/gestaltrevision/python_for_visres/blob/master/index.ipynb","title":"Python/Jupyter/IPython"},{"location":"courses/PSY5038F2018/#supplementary","text":"http://www.pybrain.org https://code.google.com/p/neurolab/ http://briansimulator.org","title":"Supplementary"},{"location":"courses/PSY5038F2018/#writing","text":"Gopen, G. D., & Swan, J. A., 1990. The Science of Scientific Writing. American Scientist , 78 , 550-558. ( pdf ) Supplementary: The Sense of Style: The Thinking Person's Guide to Writing in the 21 st Century (2014), Pinker, Steven. ( amazon link ) Penrose, A. M., & Katz, S. B. (1998). Writing in the Sciences: Exploring Conventions of Scientific Discourse . New York: St. Martin's Press, Inc. American Psychological Association. (2009). Publication manual of the American Psychological Association (6 th ed.). Washington, DC: American Psychological Association Writing assistance. THE CENTER FOR WRITING offers free one-to-one writing assistance to undergraduate and graduate students, with appointments up to 45 minutes. Nonnative speaker specialists are available. For more information, see http://writing.umn.edu . Psychology department resources: http://writing.psych.umn.edu/student-resources","title":"Writing"},{"location":"courses/PSY5038F2018/#supplementary-readings","text":"* Anderson, James. (1995) Introduction to Neural Networks , MIT Press. _Bishop, C. M. (2006). Pattern recognition and machine learning. New York: Springer. Dayan, P., & Abbott, L. F. (2001). Theoretical neuroscience : computational and mathematical modeling of neural systems. Cambridge, Mass.: MIT Press. Freeman, J. A. (1994). Simulating Neural Networks with Mathematica . Reading, MA: Addison-Wesley Publishing Company. http://library.wolfram.com/infocenter/Books/3485/ * Gershenfeld , N. A. (1999). The nature of mathematical modeling. Cambridge ; New York: Cambridge University Press. _ Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning . MIT Press. ( online ) Hertz, J., Krogh, A., & ;Palmer , R. G. (1991). Introduction to the theory of neural computation (Santa Fe Institute Studies in the Sciences of Complexity ed.). Reading, MA: Addison-Wesley Publishing Company. Koch, C., & Segev , I. (Eds.). (1998). Methods in Neuronal Modeling : From Ions to Networks (2 nd ed.). Cambridge, MA: MIT Press. _* MacKay, D. J. C. (2003). Information theory, inference, and learning algorithms. Cambridge, UK ; New York: Cambridge University Press. http://www.inference.phy.cam.ac.uk/mackay/itila/book.html ***_Murphy, K. P. (2012). Machine Learning: a Probabilistic Perspective. MIT Press. *Neural/Cognitive Science **Physics/Applied Math ***Statistical/machine learning","title":"Supplementary readings"},{"location":"courses/PSY5038F2018/#grade-requirements","text":"There will be programming assignments, as well as a final project . The grade weights are: Exercise/programming assignments: 55% Final project presentations: 5 % Final project : 40% (four parts: 2%+5%+5%+28%) The programming assignments will use the Mathematica programming environment. No prior experience with Mathematica is necessary.[ ](http://www2.publabs.umn.edu/publab/text/locations.html)Your completed problem set assignment should be uploaded to Canvas by midnight on the date due. In general you should use the downloaded Mathematica notebook as your template, then add your answers, and then upload the finished assignment. You can copy and paste any code bits you need from the Lecture notebooks. But of course, you cannot copy and paste code or any other answer materials from someone else. * * *","title":"Grade Requirements"},{"location":"courses/PSY5038F2018/#outline-lecture-notes","text":"","title":"Outline &amp; Lecture Notes"},{"location":"courses/PSY5038F2018/#under-construction","text":"http://onestop.umn.edu/calendars/ _ (NOTE: Links to revised lecture material below will be posted on the day of the lecture. Links to the pdfs Lecture notes are in Mathematica Notebook and pdf format. You can download the Mathematica notebook files below to view with Mathematica or Wolfram CDF Player (which is free). Lecture Date Lecture Additional Readings & supplementary material Assignments due 1 Sep 5 Introduction [ Mathematica notebook](/courses/71054/files/3310692/download?wrap=1 \"Lect_1_Introduction.nb\") ([ pdf ](/courses/71054/files/3310707/download?wrap=1 \"Lect_1_Introduction.nb.pdf\")) [ Mathematica screencast](http://www.wolfram.com/broadcast/screencasts/handsonstart/) [Top 100 Brain Structures](http://www.med.harvard.edu/AANLIB/cases/caseM/case.html) 2 Sep 10 The neuron [( pdf file](/courses/71054/files/3378180/download?wrap=1 \"Lect_2_TheNeuron.nb.pdf\"))| [ Mathematica notebook](/courses/71054/files/3378177/download?wrap=1 \"Lect_2_TheNeuron-1.nb\") [Hodgkin- Huxley.nb ](/courses/71054/files/3311407/download?wrap=1 \"Hodgkin-Huxley.nb\") [Myelinated neuron (Wolfram Demo)](http://demonstrations.wolfram.com/ActionPotentialPropagationAlongMyelinatedAxons/) Koch & Segev , 2000 [( pdf )](/courses/71054/files/3310978/download?wrap=1 \"Koch_Segev_NN2000.pdf\") Meunier & Segev , 2002 ([ pdf ](/courses/71054/files/3311455/download \"MeunierSegev.pdf\")) 3 Sep 12 Neural Models, McCulloch-Pitt ([ pdf file](/courses/71054/files/3415176/download?wrap=1 \"Lect_3_NeuralModeling.nb.pdf\"))| [ Mathematica notebook](/courses/71054/files/3415175/download?wrap=1 \"Lect_3_NeuralModeling.nb\") Integrate-and-fire models. Chap 14.2 of Koch, C. (2004) [( pdf )](/courses/71054/files/3404515/download?wrap=1 \"Koch2004-1.pdf\") 4 Sep 17 Generic neuron model ([ pdf file](/courses/71054/files/3477521/download?wrap=1 \"Lect_4_GenericModel.nb.pdf\"))| [ Mathematica notebook](/courses/71054/files/3477511/download?wrap=1 \"Lect_4_GenericModel.nb\") [ _ Problem Set 1 _ ](/courses/71054/assignments/285875 \"Problem Set 1\") 5 Sep 19 Lateral inhibition [(](Lectures/Lect_5_LatInhibition/Lect_5_LatInhibition.nb.pdf) [ pdf file](/courses/71054/files/3519528/download?wrap=1 \"Lect_5_LatInhibition.nb.pdf\") )| [ Mathematica notebook](/courses/71054/files/3519521/download?wrap=1 \"Lect_5_LatInhibition.nb\") Hartline (1972) ([ pdf ](/courses/71054/files/3311329/download?wrap=1 \"Hartline72.pdf\")) 6 Sep 24 Matrices ( [ pdf file](/courses/71054/files/3582868/download?wrap=1 \"Lect_6_Matrices.nb.pdf\") )| [ Mathematica notebook](/courses/71054/files/3582875/download?wrap=1 \"Lect_6_Matrices.nb\") 7 Sep 26 Linear systems, learning & memory ( [ pdf file](/courses/71054/files/3620907/download?wrap=1 \"Lect_7_LinearSystems.nb.pdf\") )| [ Mathematica notebook](/courses/71054/files/3620901/download?wrap=1 \"Lect_7_LinearSystems.nb\") 8 Oct 1 Linear recall, association and memory simulations ([ pdf file](/courses/71054/files/3693072/download?wrap=1 \"Lect_8_HeterAuto.nb.pdf\"))| [ Mathematica notebook](/courses/71054/files/3693069/download?wrap=1 \"Lect_8_HeterAuto.nb\") [ _ Problem Set 2 _ ](/courses/71054/files/3529157/download?wrap=1 \"Problem_Set_2.nb\") Due Tuesday Oct 2. 9 Oct 3 Overview of non-linear networks, discriminative models, Perceptron, SVMs ([ pdf file](/courses/71054/files/3740368/download?wrap=1 \"Lect_9_Perceptron.nb.pdf\"))| , [Mathematica notebook](/courses/71054/files/3740361/download?wrap=1 \"Lect_9_Perceptron.nb\") SVMs: [ J\u00e4kel et al., (2009)](/courses/71054/files/3311336/download?wrap=1 \"JakelTICsKernelMethods2009.pdf\") J[\u00e4kel](/courses/71054/files/3311334/download?wrap=1 \"Jakel_etal_2007Preprint_4784[0].pdf\") [et al., (2007)](/courses/71054/files/3311334/download?wrap=1 \"Jakel_etal_2007Preprint_4784[0].pdf\") Mathematica SVMs: Nilsson, Bj\u00f6rkegren & Tegn\u00e9r (2006) MathSVMv7.nb Fisher's linear discriminant notes ( pdf ) Mathematica notebook (updated) 10 Oct 8 Supervised learning as regression, Widrow -Hoff, backprop & deep learning, ([ pdf file](/courses/71054/files/3815215/download?wrap=1 \"Lect_10_RegressWid.nb.pdf\"))| [ Mathematica notebook](/courses/71054/files/3815213/download?wrap=1 \"Lect_10_RegressWid.nb\") [ Backpropagation.m ](/courses/71054/files/3723598/download?wrap=1 \"Backpropagation.m\") XOR backpropagation demo. [ Mathematica notebook](/courses/71054/files/3815263/download?wrap=1 \"MultiLayerBackprop.nb\") [LeNet-5](http://yann.lecun.com/exdb/lenet/) Poirazi , Brannon & Mel (2003) ([ pdf ](/courses/71054/files/3311351/download?wrap=1 \"Poirazi2003Pyramidal_neuron_as_two-layer_neural_network.pdf\")) Williams (1992) ([ pdf )](/courses/71054/files/3311362/download?wrap=1 \"williams86.pdf\") 11 Oct 10 Hopfield networks [( pdf file](/courses/71054/files/3857749/download?wrap=1 \"Lect_11_Hopfield.nb.pdf\"))| [ Mathematica notebook](/courses/71054/files/3857745/download?wrap=1 \"Lect_11_Hopfield.nb\") Hopfield (1982) ([ pdf ](/courses/71054/files/3311374/download?wrap=1 \"Hopfield1982.pdf\")) Marr & Poggio (1976) ([ pdf ](/courses/71054/files/3311378/download?wrap=1 \"MarrPoggio1976.pdf\")) Hopfield (1984) ([ pdf ](/courses/71054/files/3311375/download?wrap=1 \"Hopfield1984.pdf\")) Durstewitz et al. (2000) ([ pdf )](/courses/71054/files/3311383/download?wrap=1 \"dusterwitz00.pdf\") [IPython](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5038WF2014/Lectures/Lect_12_Hopfield/HopfieldTwoNeuronDemo.ipynb) (Jupyter) demo of Hopfield Stereo correspondence. [ Mathematica demo](/courses/71054/files/3857853/download?wrap=1 \"Correspondence_HopfieldDis.nb\"). [IPython demo.](http://nbviewer.jupyter.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5038WF2014/Lectures/Lect_11_Hopfield/HopfieldStereo.ipynb) 12 Oct 15 Boltzmann machine ([ pdf file](/courses/71054/files/3932721/download?wrap=1 \"Lect_12_Boltzmann.nb.pdf\"))| [ Mathematica notebook](/courses/71054/files/3932718/download?wrap=1 \"Lect_12_Boltzmann.nb\") Berkes , P., Orban , G., Lengyel , M., & Fiser , J. (2011). Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment. Science, 331(6013), 83\\. ([ pdf ](/courses/71054/files/3312953/download?wrap=1 \"Berkes2011Spontaneous_cortical_activity_reveals_hallmarks_of_an_optimal_internal_model_of_the_environment.pdf\")) [ _ _Problem Set_ 3 _ ](/courses/71054/files/3723564/download?wrap=1 \"Problem_Set_3.nb\") _ Due Tuesday Oct 16. _ 13 Oct 17 Probability and neural networks ([ pdf file](/courses/71054/files/3971494/download?wrap=1 \"Lect_13_Probability.nb.pdf\"))| [ Mathematica notebook](/courses/71054/files/3971493/download?wrap=1 \"Lect_13_Probability.nb\") Griffiths and Yuille (2006) ([ pdf ](/courses/71054/files/3312980/download?wrap=1 \"GriffithsYuilleProbPrimerTICsmmc1.pdf\")) Kersten, D., & Yuille , A. (2003). Bayesian models of object perception. Current Opinion in Neurobiology, 13(2), 1-9\\. ([ pdf ](/courses/71054/files/3312991/download?wrap=1 \"KerstenYuilleCurrOpinNeu2003.pdf\")) Kersten D. & Yuille, A.L (2013) .Vision: Bayesian Inference and Beyond. The New Visual Neurosciences. John S. Werner and Leo M. Chalupa (Editors) MIT Press. Cambridge MA..[(pdf)](/courses/71054/files/4073103/download?wrap=1 \"Kersten2013Vision_Bayesian_Inference_and_Beyond.pdf\") 14 Oct 22 Multivariate distributions, Regression, Interpolation, perceptual completion ([ pdf ](/courses/71054/files/4032724/download?wrap=1 \"Lect14_MultinormalsRegressionSculptingCost.nb.pdf\")) [ Mathematica notebook](/courses/71054/files/4032721/download?wrap=1 \"Lect14_MultinormalsRegressionSculptingCost.nb\") Notes on overfitting and the bias/variance dilemma ([Mathematica notebook](/courses/71054/files/4275562/download?wrap=1 \"NotesOnBiasVariance.nb\")) 15 Oct 24 Graphical models ([ pdf ](/courses/71054/files/4073219/download?wrap=1 \"Lect_15_ProbabilityGraphicalModels-1.nb.pdf\")) [ Mathematica notebook](/courses/71054/files/4073214/download?wrap=1 \"Lect_15_ProbabilityGraphicalModels-1.nb\") Pattern Recognition and Machine Learning, _ Chapter 8: Graphical Models _. Christopher M. Bishop [( pdf ](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/05/Bishop-PRML-sample.pdf)) Weiss Y. ([ pdf ](http://www.cs.huji.ac.il/%7Eyweiss/nips96.pdf)) Belief propagation tutorial by James Coughlan ( [pdf](http://www.ski.org/sites/default/files/publications/bptutorial.pdf) ). Ma, W. J. (2012). Organizing probabilistic models of perception. Trends in Cognitive Sciences, 16(10), 511\u2013518\\. ( pdf ) 16 Oct 29 Belief Propagation: regression and interpolation revisited [(pdf](/courses/71054/files/4136590/download?wrap=1 \"Lect_16_BeliefProp.nb.pdf\") ) [Mathematica notebook](/courses/71054/files/4136599/download?wrap=1 \"Lect_16_BeliefProp.nb\") [James Coughlan's BP tutorial](http://computerrobotvision.org/2009/tutorial_day/crv09_belief_propagation_v2.pdf) PROJECT GUIDELINES ([pdf](/courses/71054/files/4136615/download?wrap=1 \"FinalProjectskey.key.pdf\")) SAMPLE PROJECT IDEAS from previous years( [pdf](/courses/71054/files/4136646/download?wrap=1 \"SampleFinalProjects.nb.pdf\") ) Sample abstracts from past students For demonstration style projects, see the [Wolfram Demonstration site](http://demonstrations.wolfram.com/) How To Do Research. William T. Freeman (2013), ([link)](http://people.csail.mit.edu/billf/publications/How_To_Do_Research.pdf) [ _ Problem Set 4 _ ](/courses/71054/files/3973764/download?wrap=1 \"Problem_Set_4.nb\") _ _ Due Tuesday Oct 30. _ _ 17 Oct 31 Supervised learning: neural networks in the context of machine learning ( [ pdf ](/courses/71054/files/4180102/download?wrap=1 \"Lect17_SupervisedNNsAndML.nb.pdf\") ) [ Mathematica notebook ](/courses/71054/files/4180101/download?wrap=1 \"Lect17_SupervisedNNsAndML.nb\") Hegde , J., Bart, E., & Kersten, D. (2008). Fragment-Based Learning of Visual Object Categories. Curr Biol. 18, 597-601 ([pdf](http://download.cell.com/current-biology/pdf/PIIS096098220800448X.pdf?intermediate=true)) 18 Nov 5 Deep learning, DCNNs Feedforward architectures for recognition Keynote presentation ([pdf](/courses/71054/files/4248803/download?wrap=1 \"CNNsLect18.pdf\")) Serre , T., Oliva , A., & Poggio , T. (2007). A feedforward architecture accounts for rapid categorization. Proc Natl Acad Sci U S A, 104(15), 6424-6429. Hong, H., Yamins, D. L. K., Majaj, N. J., & DiCarlo, J. J. (2016). Explicit information for category-orthogonal object properties increases along the ventral stream. _Nature Neuroscience_, _19_(4), 613\u2013622\\. [https://doi.org/10.1038/nn.4247](https://doi.org/10.1038/nn.4247) Kirchner, H., & Thorpe, S. J. (2006). Ultra-rapid object detection with saccadic eye movements: Visual processing speed revisited. Vision Research, 46(11), 1762\u20131776\\. doi:10.1016/j.visres.2005.10.002 ([pdf](http://www.sciencedirect.com/science/article/pii/S0042698905005110)) Kersten D. & Yuille, A.L. (2014) Inferential Models of the Visual Cortical Hierarchy. The New Cognitive Neurosciences, 5th Edition.([draft pdf)](http://gandalf.psych.umn.edu/users/kersten/kersten-lab/coursepapers/KerstenYuilleNewCogNeuro2014.pdf) 19 Nov 7 DCNNs Keynote presentation ([pdf](/courses/71054/files/4288503/download?wrap=1 \"Lect19DCNNs-1.pdf\")) [ Mathematica notebook with demos](/courses/71054/files/4360760/download?wrap=1 \"Lect19DeepLearningDCNNS-1.nb\") (revised 11/12/18) Notes on Bayesian decision theory. Utility, loss, and empirical risk ([Mathematica notebook](/courses/71054/files/4275594/download?wrap=1 \"NotesOnDecisionTheory.nb\")) Geisler , W. S., & Kersten, D. (2002). Illusions, perception and Bayes. Nat Neurosci , 5(6), 508-510\\. ([ pdf ](/courses/71054/files/4073138/download?wrap=1 \"Nat_Neurosci_2002_Geisler-2.pdf\")) 20 Nov 12 Recurrent neural networks (RNNs), sequence modeling [Keynote presentation](/courses/71054/files/4364075/download?wrap=1 \"RNNs-1.key\") [(pdf](/courses/71054/files/4364079/download?wrap=1 \"RNNs.pdf\")[)](/courses/71054/files/4360747/download?wrap=1 \"RNNs.key\") [ Mathematica notebook with demos ](/courses/71054/files/4360750/download?wrap=1 \"RNNMathematicaIIntro.nb\") Kalman filter notes ([pdf](/courses/71054/files/4360788/download?wrap=1 \"kalman.pdf\")) Kalman filter [Mathematica demo](/courses/71054/files/4360856/download?wrap=1 \"KalmanTracking.nb\")Mar 21 Nov 14 Markov chain Monte Carlo (MCMC) sampling [Mathematica notebook](/courses/71054/files/4485616/download?wrap=1 \"Lect_21_MoreSamplingMCMC-1.nb\") ([pdf](/courses/71054/files/4485620/download?wrap=1 \"Lect_21_MoreSamplingMCMC-1.nb.pdf\")) Lake, B. M., Salakhutdinov, R., & Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350(6266), 1332\u20131338\\. [http://doi.org/10.1126/science.aab3050](http://doi.org/10.1126/science.aab3050) [Metropolis2D.ipynb](http://nbviewer.ipython.org/url/gandalf.psych.umn.edu/users/kersten/kersten-lab/courses/Psy5038WF2014/Lectures/Lect_20_MCMC/Metropolis2D.ipynb) [http://pymc-devs.github.io/pymc/](http://pymc-devs.github.io/pymc/) Recommended pymc tutorials: [http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/) _ [_Problem Set_ 5](/courses/71054/files/4273266/download?wrap=1 \"Problem_Set_5.nb\")[ ](Problem_Sets/Problem_Set_5.nb) _ _ _ Due Tuesday Nov. 20. _ _ 22 Nov 19 MCMC continued (see Lecture 21 notebook) For a quick start to scientific programming, see: [http://nbviewer.ipython.org/gist/rpmuller/5920182](http://nbviewer.ipython.org/gist/rpmuller/5920182) For a list of some notebooks in psychology, neuroscience, and machine learning see: [https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks#psychology-and-neuroscience](https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks#psychology-and-neuroscience) For a comphrensive coverage of scientific python see[:https://scipy-lectures.github.io](https://scipy-lectures.github.io) And for a ground-up set of tutorials on python see: [http://learnpythonthehardway.org/book/](http://learnpythonthehardway.org/book/) Switching from matlab to python? [https://stsievert.com/blog/2015/09/01/matlab-to-python/](https://stsievert.com/blog/2015/09/01/matlab-to-python/) [Final project title & paragraph outline due](/courses/71054/assignments/369425 \"Final Project title and paragraph outline\") (2%) 23 Nov 21 Overview of python and jupyter notebooks for scientific computation /neural networks, and Bayesian computations . Starting python in the middle: [Jupyter notebook on colab](https://drive.google.com/open?id=1xQ7LN-6q7SptF0TdZ_kM2DlN25tE89r0) [Source jupyter notebook](/courses/71054/files/4527474/download?wrap=1 \"Lect_21Intro_Python3.ipynb\"). MCMC sampling using Python3 and PyMC3 [Jupyter notebook on colab](https://colab.research.google.com/drive/1N0CgswSGEpG4XKBy5g2zKO_Ps_gfR9yR) [Source jupyter notebook. ](/courses/71054/files/4527479/download?wrap=1 \"Lect_PyMC3.ipynb\") Lect_21_PyMC (raw [IPython notebook](Lectures/Lect_21_PyMc/Lect_21_PyMC.ipynb)) or [Jupyter nbviewer](http://nbviewer.jupyter.org/url/gandalf.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5038WF2016/Lectures/Lect_21_PyMc/Lect_21_PyMC.ipynb) PyMC2 sprinkler ([raw](Lectures/Lect_21_PyMc/PearlSprinklerPYMC.ipynb)) [Jupyter viewer](https://nbviewer.jupyter.org/url/gandalf.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5038WF2016/Lectures/Lect_21_PyMc/PearlSprinklerPYMC.ipynb) PyMC3 Gaussian mixtures ([raw](Lectures/Lect_21_PyMc/Gaussian%20Mixture%20PYMC3%20example.ipynb)) [Jupyter viewer](https://nbviewer.jupyter.org/url/gandalf.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5038WF2016/Lectures/Lect_21_PyMc/Gaussian%20Mixture%20PYMC3%20example.ipynb) PyMC3 spike rate transitions ([raw](Lectures/Lect_21_PyMc/PYMC3%20Spikes%20Model%20Segmentation.ipynb)) [Jupyter viewer](https://nbviewer.jupyter.org/url/gandalf.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5038WF2016/Lectures/Lect_21_PyMc/PYMC3%20Spikes%20Model%20Segmentation.ipynb) Scikit-learn gaussian mixtures [(raw](Lectures/Lect_21_PyMc/Bayesian%20Gaussian%20mixture%20model%20sklearn%20demo.ipynb)) [Jupyter viewer](https://nbviewer.jupyter.org/url/gandalf.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5038WF2016/Lectures/Lect_21_PyMc/Bayesian%20Gaussian%20mixture%20model%20sklearn%20demo.ipynb) 24 Nov 26 Introduction to neural networks for self-organization Overview of visual system architecture Keynote ([pdf](/courses/71054/files/4602935/download?wrap=1 \"Lect_24_VisualArchitectureLateral-2.pdf\")) AdaptMaps [ Mathematica notebook](/courses/71054/files/4602939/download?wrap=1 \"SelfOrganizationAdaptMaps-1.nb\") ([ pdf ](/courses/71054/files/4602949/download?wrap=1 \"SelfOrganizationAdaptMaps-1.nb.pdf\")) Supplement: [ ContingentAdaptation.nb ](/courses/71054/files/4562382/download?wrap=1 \"ContingentAdaptation.nb\") [](http://www.biomotionlab.ca/Demos/BMLwalker.html) 25 Nov 28 Introduction to neural networks for self-organization continued (see pdfs from previous lecture) Oja's rule and PCA: Sanger (2003) ([ pdf ](http://vision.psych.umn.edu/users/kersten//kersten-lab/coursepapers/SangerPopCodes.pdf)) Ernst, M. O., & Banks, M. S. (2002). Humans integrate visual and haptic information in a statistically optimal fashion. Nature, 415(6870), 429-433\\. ([pdf)](http://vision.psych.umn.edu/users/kersten//kersten-lab/coursepapers/ErnstBanks2002.pdf) Ma, W. J. (2012). Organizing probabilistic models of perception. Trends in Cognitive Sciences, 16(10), 511\u2013518\\. ([pdf](http://vision.psych.umn.edu/users/kersten//kersten-lab/coursepapers/Ma2012Organizing_probabilistic_models_of_perception-1.pdf)) [ 26 ](/courses/71054/files/4685569/download?wrap=1 \"Lect_SelfOrgPCA_SVD_Oja.nb\") [ Dec 3 ](/courses/71054/files/4685569/download?wrap=1 \"Lect_SelfOrgPCA_SVD_Oja.nb\") Efficient coding. PCA, SVD, sparse coding [ Mathematica notebook ](/courses/71054/files/4685576/download?wrap=1 \"Lect_SelfOrgPCA_SVD_Oja-1.nb\") ([ pdf ](/courses/71054/files/4685619/download?wrap=1 \"Lect_SelfOrgPCA_SVD_Oja.nb.pdf\")) Scientific writing and presentations [ Mathematica notebook ](/courses/71054/files/4685626/download?wrap=1 \"ScienceWriting.nb\") [( pdf ](/courses/71054/files/4685628/download?wrap=1 \"ScienceWriting.nb.pdf\")) Gopen & Swan, 1990 ([ pdf )](/courses/71054/files/3313033/download?wrap=1 \"GopenSwan1990.pdf\") [Denis Pelli's advice for scientific writing](http://psych.nyu.edu/pelli/style.html) Ullman, S., Vidal- Naquet , M., & Sali , E. (2002). Visual features of intermediate complexity and their use in classification. Nat Neurosci , 5(7), 682-687. _ [_Problem Set_ 6](/courses/71054/assignments/381057 \"Problem Set 6\") Due December 13 _ 27 Dec 5 Clustering , EM, segmentation [Mathematica notebook](/courses/71054/files/4750417/download?wrap=1 \"Lect_27_ClusteringEM-1.nb\") ([pdf](/courses/71054/files/4750425/download?wrap=1 \"Lect_27_ClusteringEM-1.nb.pdf\")) (updated to work with Mathematica 11.3) Expectation Maximization: Weiss Y. [(](Lectures/Lect_18_EM/EM%20Weiss%20Tutorial.pdf)[ pdf ](http://www.cs.huji.ac.il/%7Eyweiss/emTutorial.pdf)) Neural population codes ([Mathematica notebook](http://vision.psych.umn.edu/users/kersten//kersten-lab/courses/Psy5038WF2016/Lectures/Lect_24_SelfOrgPCA_SVD/Lect_24b_VisualRepCode.nb)) Quiroga , R. Q., Reddy, L., Kreiman , G., Koch, C., & Fried, I. (2005) .([pdf)](http://vision.psych.umn.edu/users/kersten//kersten-lab/coursepapers/GrandmotherCellKoch2005.pdf) Probabilistic neural representations, Poisson-like codes, and the neural integration of information. Keynote presentation ([pdf](Lectures/Lect_24_SelfOrgPCA_SVD/Lect_24_LateralOrgNeuralPopulationCodes.key.pdf)) [ Complete Draft of Final Project (5%)_ **Due Friday December 7**_ ](/courses/71054/assignments/390909 \"Final Project DRAFT\") Dec 10 Class presentations Peer comments on Final Project (5%)_ Due Wednesday December 12_ Dec 12 Last day of classes Class presentations Drafts returned with Instructor and peer comments December 12 Dec 20 End of Semester Submit Final Revised Draft of Project (28%) * * * ### Final Project Assignment This course teaches you how to understand cognitive and perceptual aspects of brain processing in terms of computation. Writing a computer program encourages you to think clearly about the assumptions underlying a given theory. Getting a program to work, however, tests just one level of clear thinking. By writing about your work, you will learn to think through the broader implications of your final project, and to effectively communicate the rationale and results in words. Your final project will involve: 1) a computer simulation and; 2) a 2000-3000 word final paper describing your simulation. For your computer project, you will do one of the following: 1) Devise a novel application for a neural network model studied in the course; 2) Write a program to simulate a model from the neural network literature ; 3) Design and program a method for solving some problem in perception, cognition or motor control. The results of your final project should be written up in the form of a short scientific paper, describing the motivation, methods, results, and interpretation. Your paper will be critiqued and returned for you to revise and resubmit in final form. You should write for an audience consisting of your class peers. You may elect to have your final paper published in the course's web-based electronic journal. Completing the final paper involves 3 steps: Outline . You will submit a working title and paragraph outline by the deadline noted in the syllabus. These outlines will be critiqued in order to help you find an appropriate focus for your papers. ( 2% of grade). (Consult with the instructor or TA for ideas well ahead of time). Complete draft . You will then submit a complete draft of your paper ( 2000-3000 words ). Papers must include the following sections: Abstract, Introduction, Methods, Results, Discussion, and Bibliography. Use citations to motivate your problem and to justify your claims. Figures should be numbered and have figure captions. Cite authors by name and date, e.g. (Marr & Poggio, 1979). Use a standard citation format, such as APA. Papers must be typed, with a page number on each page.Each paper will be reviewed with specific recommendations for improvement. ( 5% of grade) Peer commentary . Each student will submit a paragraph on an anonymous paired project draft ( 5% of grade) Final draft . You will submit a final revision for grading. ( 28% of grade). The final draft must be turned in by the date noted on the syllabus. If you choose to write your program in Mathematica, your paper and program can be combined can be formated as a Mathematica notebook. See: Books and Tutorials on Notebooks. Your paper will be critiqued and returned for you to revise and resubmit in final form. You should write for an audience consisting of your class peers. Some Resources: Student Writing Support: Center for Writing, 306b Lind Hall and satellite locations (612.625.1893) http://writing.umn.edu . Online Writing Center: http://writing.umn.edu/sws/visit/online/index.html NOTE: Plagiarism, a form of scholastic dishonesty and a disciplinaryoffense, is described by the Regents as follows: Scholasticdishonesty means plagiarizing; cheating on assignments or examinations;engaging in unauthorized collaboration on academic work; taking,acquiring, or using test materials without faculty permission; submittingfalse or incomplete records of academic achievement; acting alone or incooperation with another to falsify records or to obtain dishonestlygrades, honors, awards, or professional endorsement; or altering,forging, or misusing a University academic record; or fabricating orfalsifying of data, research procedures, or data analysis. http://regents.umn.edu/sites/regents.umn.edu/files/policies/Student_Conduct_Code.pdf NOTE: Sexual Assault and higher education: Training modules and information The Department of Psychology supports the efforts of the University of Minnesota towards prevention of sexual assault. We encourage all students to participate in the free online training that has been established for undergraduate students and graduate students. The training highlights pertinent issues regarding sexual assault, including, but not limited to: defining healthy relationships, consent, bystander intervention, and gender roles. Haven (for undergraduate students under the age of 25) and Haven Plus (for undergraduates over 25, graduate students, and professional students) is the training available at no cost to University of Minnesota students. Additionally, to learn more about how you can help reduce sexual assault at the University of Minnesota, please visit the Aurora Center . \u00a9 2018 Daniel Kersten, University of Minnesota Privacy Statement","title":"(Under construction)"},{"location":"courses/PSY8036SP2018/","text":"Data-driven generative models for perception, dreaming, and imagining \u00b6 University of Minnesota, Spring Semester, 2018 **Topics in Computational Vision \u00b6 **Psy 8036 (Kersten) Psy 5993 Section 034 (Schrater) http://courses.kersten.org https://ay17.moodle.umn.edu/course/view.php?id=8619#section-11 \u00b6 Instructors: Dan Kersten (kersten@umn.edu) Paul Schrater (schrater@umn.edu) Summary It has been proposed that perception is fundamentally a process of \u201canalysis-by-synthesis\u201d in which the sensory input is analyzed bottom-up, with perceptual interpretations tested and refined by top-down predictions of the input, through synthesis. However, while the computational and neural study of the analysis component is well-developed, less is known about the principles and mechanisms that underly synthesis. This seminar will explore recent advances using \u201cdeep\u201d learning algorithms to discover hierarchical statistical regularities in large datasets of natural patterns, and the relevance of the learning results to models of human perception and recognition. These algorithms also provide the basis for the stochastic synthesis of novel, yet familiar patterns, which raises the question of whether the human experiences of dreams and hallucinations, and the ability to imagine, reflect the same statistical regularities that are discoverable using machine learning. The class format will include short introductory lectures by the instructors, and weekly student presentations of current literature. The short lectures will provide historical context as well as tutorials on machine learning (e.g. TensorFlow for neural network simulations). Meeting time : First meeting Tuesday, Jan 16 th , 3:00 pm. Place: Elliott N227 Students can sign up for either Topics in Computational Vision Psy 8036 (Kersten) or Psy 5993 Section 034 (Schrater) . Background There is a long history of theories of perception in which the brain \u201cexplains\u201d sensory input in terms of external, behaviorally relevant causes. A current hypothesis is that this process is implemented in part by cortical feedback mechanisms that synthesize predictions of early data representations in order to test how well the brain's current interpretation of the world corresponds with the sensory data. In this view, perception involves a cycle in which the incoming data triggers a set of explanations, i.e. hypotheses, which are used to measure how far the expected sensory input differs from the actual input. From a computational perspective, such generative models of perceptual inference have a number of advantages over strictly bottom-up inference. A generative model can incorporate measures of \"goodness-of-fit\" to decide whether to accept or reject an interpretation--some explanations are better than others. Discrepancies between sensory data and predictions may also be used to direct attentional resources and signal whether more complex combinations of hypotheses are needed. Further, with sufficient structure, a generative model could provide the basis for the perceptual interpretation of sensory input outside the range of past experience. While computational theories for bottom-up neural mechanisms for perception have received considerable scientific attention, much less is known about top-down mechanisms. This seminar will explore the idea that the brain has hierarchically structured mechanisms that can synthesize patterns of input representations with the following constraints: 1) the mechanisms build on inductive structural biases that are innate; 2) the mechanisms reflect the statistical regularities induced by the physical causes of sensory experience, i.e. they are \"data-driven\"; 3) the need for cognitive processes to access semantic, perceptual content over levels of abstraction. Assumptions 1) and 2) constrain the class of generative models to be \"data-driven\", i.e. models that can be learned from sensory data. Recent computational methods for data-driven pattern synthesis (e.g. VAE, InfoGAN, Adversarial Bayes, StackGAN) will be covered in this seminar. We will also explore the proposal that the same circuitry that may underly feedback in perception is used during imagery, dreams, and hallucinations. Tentative Syllabus \u00b6 **Week** **Topics** **Background material** **Discussion topics and papers** 1: Jan 16 Background Models of perception Yuille, A., & Kersten, D. (2006). Vision as Bayesian inference: analysis by synthesis? Trends in Cognitive Sciences, 10(7), 301\u2013308\\. 2: Jan 23 Overview of machine learning Ackley, D. H., Hinton, G. E., & Sejnowski, T. J. (1985). A learning algorithm for Boltzmann machines. Cognitive Science, 9(1), 147\u2013169. 3: Jan 30 Shallow image models, textures Zhu, S. C., Wu, Y., & Mumford, D. (1998). Filters, random fields and maximum entropy (FRAME): Towards a unified theory for texture modeling. International Journal of Computer Vision, 27(2), 107\u2013126\\. McDermott, J. H., Schemitsch, M., & Simoncelli, E. P. (2013). Summary statistics in auditory perception. Nature Publishing Group, 16(4), 493\u2013498\\. 4: Feb 6 Hierarchical image models, deep learning Zhu, S.-C., & Mumford, D. (2006). Quest for a stochastic grammar of images. Foundations and Trends\u00ae in Computer Graphics and Vision, 2(4), 259\u2013362\\. Topic preview: Visual imagery 5: Feb 13 Hierarchical image models, deep learning Topic preview: Auditory imagery 6: Feb 20 Hierarchical image models, deep learning Topic preview: Hypnagogic imagery 7: Feb 27 Dynamic textures, patterns Xie, J., & Zhu, S. C. (n.d.). Synthesizing Dynamic Patterns by Spatial-Temporal Generative ConvNet. arXiv.org. Vondrick, C., Pirsiavash, H., & Torralba, A. (2016). Generating Videos with Scene Dynamics. Advances in Neural Information Processing Systems NIPS, 613\u2013621. Topic preview: Dreams 8: Mar 6 Visual imagery Christophel, T. B., Klink, P. C., Spitzer, B., Roelfsema, P. R., & Haynes, J.-D. (2017). The Distributed Nature of Working Memory. Trends in Cognitive Sciences, 1\u201315\\. Dijkstra, N., Zeidman, P., Ondobaka, S., Gerven, M. A. J., & Friston, K. (2017). Distinct Top-down and Bottom-up Brain Connectivity During Visual Perception and Imagery. Scientific Reports, 1\u20139\\. Topic preview: Lucid dreaming Mar 13 Spring Break 9: Mar 20 Auditory, musical imagery Zatorre, R. J., & Halpern, A. R. (2005). Mental Concerts: Musical Imagery and Auditory Cortex. Neuron, 47(1), 9\u201312. Riecke, L., A. J. van Opstal, R. Goebel, and E. Formisano. \u201cHearing Illusory Sounds in Noise: Sensory-Perceptual Transformations in Primary Auditory Cortex.\u201d Journal of Neuroscience 27, no. 46 (November 14, 2007): 12684\u201389\\. McDermott, Josh H., and Andrew J. Oxenham. \u201cSpectral Completion of Partially Masked Sounds.\u201d Proceedings of the National Academy of Sciences 105, no. 15 (2008): 5939\u20135944. Topic overview: Hallucinations & psychedelics 10: Mar 27 Hypnagogic imagery Schacter, D. L. (1976). The hypnagogic state: a critical review of the literature. Psychological Bulletin. Topic preview: Hallucinations & schizophrenia 11: Apr 3 Dreams Stickgold, R., Hobson, J. A., Fosse, R., & Fosse, M. (2001). Sleep, Learning, and Dreams: Off-line Memory Reprocessing. Science, 294(5544), 1052\u20131057\\. Crick, F., G. Mitchison., 1983\\. The function of dream sleep. Nature. Springer Topic preview: Imagination 12: Apr 10 Lucid dreaming Voss, U., Holzmann, R., Tuin, I., , J. A. Hobson., 2009\\. Lucid dreaming: a state of consciousness with features of both waking and non-lucid dreaming. Sleep. 13: Apr 17 Hallucinations Seri\u00e8s, P., Reichert, D. P., & Storkey, A. J. (2010). Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model, 2020\u20132028. Ermentrout, G. B., & Cowan, J. D. (1979). A mathematical theory of visual hallucination patterns. Biological Cybernetics, 34(3), 137\u2013150 Howard, R. J., Brammer, M. J., David, A., Woodruff, P., & Williams, S. (1998). The anatomy of conscious vision: an fMRI study of visual hallucinations. Nature neuroscience, 1(8), 738-742. 14: Apr 24 Hallucinations Kumar, S., Sedley, W., Barnes, G. R., Teki, S., Friston, K. J., & Griffiths, T. D. (2014). A brain basis for musical hallucinations. Cortex, 52(C), 86\u201397 15: May 1 Imagination, art and design Friston, K. J., Lin, M., Frith, C. D., Pezzulo, G., Hobson, J. A., & Ondobaka, S. (2017). Active Inference, Curiosity and Insight. Neural Computation, 29(10), 2633\u20132683. 16: May 8 Finals week FINAL PROJECT PRESENTATIONS Sample Readings (under construction) \u00b6 Background \u00b6 Ackley, D. H., Hinton, G. E., & Sejnowski, T. J. (1985). A learning algorithm for Boltzmann machines. Cognitive Science, 9(1), 147\u2013169. Bastos, A. M., Usrey, W. M., Adams, R. A., Mangun, G. R., Fries, P., & Friston, K. J. (2012). Canonical Microcircuits for Predictive Coding. Neuron, 76(4), 695\u2013711. Berkes, P., Orban, G., Lengyel, M., & Fiser, J. (2011). Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment. Science, 331(6013), 83\u201387. Dayan, P., Hinton, G. E., Neal, R. M., & Zemel, R. S. (1995). The Helmholtz Machine. Neural Computation, 7(5), 889\u2013904. Ouden, den, H. E. M. (2012). How prediction errors shape perception, attention, and motivation, 1\u201312. Orban, G., Pietro Berkes, Fiser, J., & Lengyel, M. (2016). Neural Variability and Sampling-Based Probabilistic Representations in the Visual Cortex. Neuron, 92(2), 530\u2013543. MacKay, D. M. (1956). Towards an information-flow model of human behaviour. British Journal of Psychology (London, England : 1953), 47(1), 30\u201343. Lake, B. M., Salakhutdinov, R., & Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350(6266), 1332\u20131338. http://doi.org/10.1126/science.aab3050 LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436\u2013444. http://doi.org/10.1038/nature14539 McDermott, Josh H., and Andrew J. Oxenham. \u201cSpectral Completion of Partially Masked Sounds.\u201d Proceedings of the National Academy of Sciences 105, no. 15 (2008): 5939\u20135944.Mumford, D. (1992). On the computational architecture of the neocortex. Biological Cybernetics, 66(3), 241\u2013251. Mumford, D. (1994). Pattern theory: a unifying perspective, 187\u2013224. Rao, R. P. N., & Ballard, D. H. (1999). Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nature Neuroscience, 2, 79\u201387. Tu, Z., Chen, X., Yuille, A. L., & Zhu, S.-C. (2005). Image parsing: Unifying segmentation, detection, and recognition. International Journal of Computer Vision, 63(2), 113\u2013140. Yuille, A., & Kersten, D. (2006). Vision as Bayesian inference: analysis by synthesis? Trends in Cognitive Sciences, 10(7), 301\u2013308. Richards, W. (1971). The Fortification Illusions of Migraines, Scientific American, 1\u201310. Zhu, S.-C., & Mumford, D. (2006). Quest for a stochastic grammar of images. Foundations and Trends\u00ae in Computer Graphics and Vision, 2(4), 259\u2013362. http://doi.org/10.1561/0600000018 Shallow generative models : Texture synthesis \u00b6 Freeman, J., & Simoncelli, E. P. (2011). Metamers of the ventral stream. Nature Publishing Group, 14(9), 1195\u20131201. http://doi.org/10.1038/nn.2889 McDermott, J. H., Schemitsch, M., & Simoncelli, E. P. (2013). Summary statistics in auditory perception. Nature Publishing Group, 16(4), 493\u2013498. McDermott, J. H., & Simoncelli, E. P. (2011). Sound Texture Perception via Statistics of the Auditory Periphery: Evidence from Sound Synthesis. Neuron, 71(5), 926\u2013940. Zhu, S. C., Wu, Y., & Mumford, D. (1998). Filters, random fields and maximum entropy (FRAME): Towards a unified theory for texture modeling. International Journal of Computer Vision, 27(2), 107\u2013126. Hierarchical (deep) data-driven generative models \u00b6 Chen, X., Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., & Abbeel, P. (2016). InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets, 2172\u20132180. Goodfellow, I. (2016, December 31). NIPS 2016 Tutorial: Generative Adversarial Networks. Kulkarni, T. D., Whitney, W. F., Kohli, P., & Tenenbaum, J. (2015). Deep Convolutional Inverse Graphics Network, 2539\u20132547. Rock, J., Issaranon, T., Deshpande, A., & Forsyth, D. (2016, December 5). Authoring image decompositions with generative models. Varol, G., Romero, J., Martin, X., Mahmood, N., Black, M. J., Laptev, I., & Schmid, C. (2017, January 5). Learning from Synthetic Humans. Xie, J., Zhu, S.-C., & Wu, Y. N. (2016, June 3). Synthesizing Dynamic Patterns by Spatial-Temporal Generative ConvNet. Yosinski, J., Clune, J., Nguyen, A., Fuchs, T., & Lipson, H. (2015, June 22). Understanding Neural Networks Through Deep Visualization. Zhang, H., Xu, T., Li, H., Zhang, S., Wang, X., Huang, X., & Metaxas, D. (2016, December 10). StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks. Hypnagogic imagery \u00b6 Gurstelle, E. B., & de Oliveira, J. L. (2004). Daytime parahypnagogia: a state of consciousness that occurs when we almost fall asleep. Medical Hypotheses, 62(2), 166\u2013168. http://doi.org/10.1016/S0306-9877(03)00306-2 Holmes, E. A., James, E. L., Coode-Bate, T., & Deeprose, C. (2009). Can Playing the Computer Game \u201cTetris\u201d Reduce the Build-Up of Flashbacks for Trauma? A Proposal from Cognitive Science. PLoS ONE, 4(1), e4153. http://doi.org/10.1371/journal.pone.0004153.t004 Nielsen, T. A. (1995). Describing and modeling hypnagogic imagery using a systematic self-observation procedure. Dreaming, 5(2), 75\u201394. http://doi.org/10.1037/h0094426 Nielsen, T. A. (2016). A Self-Observational Study of Spontaneous Hypnagogic Imagery Using the Upright Napping Procedure. Imagination, Cognition and Personality, 11(4), 353\u2013366. http://doi.org/10.2190/3LVV-L5GY-UR5V-N0TG *Schacter, D. L. (1976). The hypnagogic state: a critical review of the literature. Psychological Bulletin. Stickgold, R. (2000). Replaying the Game: Hypnagogic Images in Normals and Amnesics. Science, 290(5490), 350\u2013353. http://doi.org/10.1126/science.290.5490.350 Dreams \u00b6 Band, J. C. Z. F. A., 2016. (n.d.). Animal \u201cHypnosis\u201d and Waking Nightmares. Anomalistik.De Crick, F., G. Mitchison., 1983. The function of dream sleep. Nature. Springer *Hobson, J. A., & Mccarley, R. W. (197.). The brain as a dream state generator: an activation-synthesis hypothesis of the dream process. The American Journal of Psychiatry. Dresler, M., Koch, S. P., Wehrle, R., Spoormaker, V. I., Holsboer, F., Steiger, A., et al. (2011). Dreamed Movement Elicits Activation in the Sensorimotor Cortex. Current Biology : CB. Stickgold, R., Hobson, J. A., Fosse, R., & Fosse, M. (2001). Sleep, Learning, and Dreams: Off-line Memory Reprocessing. Science, 294(5544), 1052\u20131057. http://doi.org/10.1126/science.1063530 Stickgold, R. (2005). Sleep-dependent memory consolidation. Nature, 437(7063), 1272\u20131278. http://doi.org/10.1038/nature04286 Studies, J. H. J. O. C., 2014. (n.d.). Consciousness, dreams, and inference: the cartesian theatre revisited. Ingentaconnect.com Hallucinations \u00b6 Bressloff, P. C., Cowan, J. D., Golubitsky, M., Thomas, P. J., & Wiener, M. C. (2002). What geometric visual hallucinations tell us about the visual cortex. Neural Computation, 14(3), 473\u2013491. http://doi.org/10.1162/089976602317250861 Cummings, J. L., & Miller, B. L. (1987). Visual hallucinations. Clinical occurrence and use in differential diagnosis. The Western Journal of Medicine, 146(1), 46\u201351. *Ermentrout, G. B., & Cowan, J. D. (1979). A mathematical theory of visual hallucination patterns. Biological Cybernetics, 34(3), 137\u2013150. http://doi.org/10.1007/BF00336965 Merabet, L. B., Maguire, D., Warde, A., Alterescu, K., Stickgold, R., & Pascual-Leone, A. (2004). Visual hallucinations during prolonged blindfolding in sighted subjects. Journal of Neuro-Ophthalmology, 24(2), 109\u2013113. Howard, R. J., Brammer, M. J., David, A., Woodruff, P., & Williams, S. (1998). The anatomy of conscious vision: an fMRI study of visual hallucinations. Nature neuroscience, 1(8), 738-742.Seri\u00e8s, P., Reichert, D. P., & Storkey, A. J. (2010). Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model, 2020\u20132028. Silverstein, S. M. (2016). Visual Perception Disturbances in Schizophrenia: A Unified Model. In The Neuropsychopathology of Schizophrenia: Molecules, Brain Systems, Motivation, and Cognition (3 rd ed., Vol. 63, pp. 77\u2013132). Cham: Springer International Publishing. http://doi.org/10.1007/978-3-319-30596-7_4 Kumar, S., Sedley, W., Barnes, G. R., Teki, S., Friston, K. J., & Griffiths, T. D. (2014). A brain basis for musical hallucinations. Cortex, 52(C), 86\u201397. http://doi.org/10.1016/j.cortex.2013.12.002 Imagery and imagination \u00b6 Chetverikov, A., & Kristj\u00e1nsson, \u00c1. (2016). On the joys of perceiving: Affect as feedback for perceptual predictions. Actpsy, 169(C), 1\u201310. http://doi.org/10.1016/j.actpsy.2016.05.005 Dijkstra, N., Zeidman, P., Ondobaka, S., Gerven, M. A. J., & Friston, K. (2017). Distinct Top-down and Bottom-up Brain Connectivity During Visual Perception and Imagery. Scientific Reports, 1\u20139. http://doi.org/10.1038/s41598-017-05888-8 Friston, K. J., Lin, M., Frith, C. D., Pezzulo, G., Hobson, J. A., & Ondobaka, S. (2017). Active Inference, Curiosity and Insight. Neural Computation, 29(10), 2633\u20132683. http://doi.org/10.1162/neco_a_00999 Kosslyn, S. M., & Thompson, W. L. (2003). When is early visual cortex activated during visual mental imagery? Psychological Bulletin, 129(5), 723\u2013746. http://doi.org/10.1037/0033-2909.129.5.723 Kosslyn, S. M., Alpert, N. M., Thompson, W. L., Maljkovic, V., Weise, S. B., Chabris, C. F., et al. (1993). Visual Mental Imagery Activates Topographically Organized Visual Cortex: PET Investigations. Journal of Cognitive Neuroscience, 5(3), 263\u2013287. http://doi.org/10.1162/jocn.1993.5.3.263 Kosslyn, S., & Ganis, G. (2000). Neural foundations of imagery. Nature Reviews \u2026. Pearson, J., Naselaris, T., Holmes, E. A., & Kosslyn, S. M. (2015). Mental Imagery: Functional Mechanisms and Clinical Applications. Trends in Cognitive Sciences, 19(10), 590\u2013602. http://doi.org/10.1016/j.tics.2015.08.003 Riecke, L., A. J. van Opstal, R. Goebel, and E. Formisano. \u201cHearing Illusory Sounds in Noise: Sensory-Perceptual Transformations in Primary Auditory Cortex.\u201d Journal of Neuroscience 27, no. 46 (November 14, 2007): 12684\u201389. https://doi.org/10.1523/JNEUROSCI.2713-07.2007. Schacter, D. L., Addis, D. R., Hassabis, D., Martin, V. C., Spreng, R. N., & Szpunar, K. K. (2012). The Future of Memory: Remembering, Imagining, and the Brain. Neuron, 76(4), 677\u2013694. http://doi.org/10.1016/j.neuron.2012.11.001 Zatorre, R. J., & Halpern, A. R. (2005). Mental Concerts: Musical Imagery and Auditory Cortex. Neuron, 47(1), 9\u201312. http://doi.org/10.1016/j.neuron.2005.06.013 Imagery and memory \u00b6 Albers, A. M., Kok, P., Toni, I., Dijkerman, H. C., & de Lange, F. P. (2013). Shared Representations for Working Memory and Mental Imagery in Early Visual Cortex. Curbio, 23(15), 1427\u20131431. http://doi.org/10.1016/j.cub.2013.05.065 Christophel, T. B., Klink, P. C., Spitzer, B., Roelfsema, P. R., & Haynes, J.-D. (2017). The Distributed Nature of Working Memory. Trends in Cognitive Sciences, 1\u201315. http://doi.org/10.1016/j.tics.2016.12.007 Naselaris, T., Olman, C. A., Stansbury, D. E., Ugurbil, K., & Gallant, J. L. (2015). A voxel-wise encoding model for early visual areas decodes mental images of remembered scenes. NeuroImage, 105(C), 215\u2013228. http://doi.org/10.1016/j.neuroimage.2014.10.018 Self, M. W., van Kerkoerle, T., & Roelfsema, P. R. (2016). Layer-specificity in the effects of attention and working memory on activity in primary visual cortex. Nature Communications, 8, 1\u201312. http://doi.org/10.1038/ncomms13804 Stickgold, R. (2005). Sleep-dependent memory consolidation. Nature, 437(7063), 1272\u20131278. http://doi.org/10.1038/nature04286 Privacy Statement","title":"PSY8036SP2018"},{"location":"courses/PSY8036SP2018/#data-driven-generative-models-for-perception-dreaming-and-imagining","text":"University of Minnesota, Spring Semester, 2018","title":"Data-driven generative models for perception, dreaming, and imagining"},{"location":"courses/PSY8036SP2018/#topics-in-computational-vision","text":"**Psy 8036 (Kersten) Psy 5993 Section 034 (Schrater) http://courses.kersten.org","title":"**Topics in Computational Vision"},{"location":"courses/PSY8036SP2018/#httpsay17moodleumneducourseviewphpid8619section-11","text":"Instructors: Dan Kersten (kersten@umn.edu) Paul Schrater (schrater@umn.edu) Summary It has been proposed that perception is fundamentally a process of \u201canalysis-by-synthesis\u201d in which the sensory input is analyzed bottom-up, with perceptual interpretations tested and refined by top-down predictions of the input, through synthesis. However, while the computational and neural study of the analysis component is well-developed, less is known about the principles and mechanisms that underly synthesis. This seminar will explore recent advances using \u201cdeep\u201d learning algorithms to discover hierarchical statistical regularities in large datasets of natural patterns, and the relevance of the learning results to models of human perception and recognition. These algorithms also provide the basis for the stochastic synthesis of novel, yet familiar patterns, which raises the question of whether the human experiences of dreams and hallucinations, and the ability to imagine, reflect the same statistical regularities that are discoverable using machine learning. The class format will include short introductory lectures by the instructors, and weekly student presentations of current literature. The short lectures will provide historical context as well as tutorials on machine learning (e.g. TensorFlow for neural network simulations). Meeting time : First meeting Tuesday, Jan 16 th , 3:00 pm. Place: Elliott N227 Students can sign up for either Topics in Computational Vision Psy 8036 (Kersten) or Psy 5993 Section 034 (Schrater) . Background There is a long history of theories of perception in which the brain \u201cexplains\u201d sensory input in terms of external, behaviorally relevant causes. A current hypothesis is that this process is implemented in part by cortical feedback mechanisms that synthesize predictions of early data representations in order to test how well the brain's current interpretation of the world corresponds with the sensory data. In this view, perception involves a cycle in which the incoming data triggers a set of explanations, i.e. hypotheses, which are used to measure how far the expected sensory input differs from the actual input. From a computational perspective, such generative models of perceptual inference have a number of advantages over strictly bottom-up inference. A generative model can incorporate measures of \"goodness-of-fit\" to decide whether to accept or reject an interpretation--some explanations are better than others. Discrepancies between sensory data and predictions may also be used to direct attentional resources and signal whether more complex combinations of hypotheses are needed. Further, with sufficient structure, a generative model could provide the basis for the perceptual interpretation of sensory input outside the range of past experience. While computational theories for bottom-up neural mechanisms for perception have received considerable scientific attention, much less is known about top-down mechanisms. This seminar will explore the idea that the brain has hierarchically structured mechanisms that can synthesize patterns of input representations with the following constraints: 1) the mechanisms build on inductive structural biases that are innate; 2) the mechanisms reflect the statistical regularities induced by the physical causes of sensory experience, i.e. they are \"data-driven\"; 3) the need for cognitive processes to access semantic, perceptual content over levels of abstraction. Assumptions 1) and 2) constrain the class of generative models to be \"data-driven\", i.e. models that can be learned from sensory data. Recent computational methods for data-driven pattern synthesis (e.g. VAE, InfoGAN, Adversarial Bayes, StackGAN) will be covered in this seminar. We will also explore the proposal that the same circuitry that may underly feedback in perception is used during imagery, dreams, and hallucinations.","title":"https://ay17.moodle.umn.edu/course/view.php?id=8619#section-11"},{"location":"courses/PSY8036SP2018/#tentative-syllabus","text":"**Week** **Topics** **Background material** **Discussion topics and papers** 1: Jan 16 Background Models of perception Yuille, A., & Kersten, D. (2006). Vision as Bayesian inference: analysis by synthesis? Trends in Cognitive Sciences, 10(7), 301\u2013308\\. 2: Jan 23 Overview of machine learning Ackley, D. H., Hinton, G. E., & Sejnowski, T. J. (1985). A learning algorithm for Boltzmann machines. Cognitive Science, 9(1), 147\u2013169. 3: Jan 30 Shallow image models, textures Zhu, S. C., Wu, Y., & Mumford, D. (1998). Filters, random fields and maximum entropy (FRAME): Towards a unified theory for texture modeling. International Journal of Computer Vision, 27(2), 107\u2013126\\. McDermott, J. H., Schemitsch, M., & Simoncelli, E. P. (2013). Summary statistics in auditory perception. Nature Publishing Group, 16(4), 493\u2013498\\. 4: Feb 6 Hierarchical image models, deep learning Zhu, S.-C., & Mumford, D. (2006). Quest for a stochastic grammar of images. Foundations and Trends\u00ae in Computer Graphics and Vision, 2(4), 259\u2013362\\. Topic preview: Visual imagery 5: Feb 13 Hierarchical image models, deep learning Topic preview: Auditory imagery 6: Feb 20 Hierarchical image models, deep learning Topic preview: Hypnagogic imagery 7: Feb 27 Dynamic textures, patterns Xie, J., & Zhu, S. C. (n.d.). Synthesizing Dynamic Patterns by Spatial-Temporal Generative ConvNet. arXiv.org. Vondrick, C., Pirsiavash, H., & Torralba, A. (2016). Generating Videos with Scene Dynamics. Advances in Neural Information Processing Systems NIPS, 613\u2013621. Topic preview: Dreams 8: Mar 6 Visual imagery Christophel, T. B., Klink, P. C., Spitzer, B., Roelfsema, P. R., & Haynes, J.-D. (2017). The Distributed Nature of Working Memory. Trends in Cognitive Sciences, 1\u201315\\. Dijkstra, N., Zeidman, P., Ondobaka, S., Gerven, M. A. J., & Friston, K. (2017). Distinct Top-down and Bottom-up Brain Connectivity During Visual Perception and Imagery. Scientific Reports, 1\u20139\\. Topic preview: Lucid dreaming Mar 13 Spring Break 9: Mar 20 Auditory, musical imagery Zatorre, R. J., & Halpern, A. R. (2005). Mental Concerts: Musical Imagery and Auditory Cortex. Neuron, 47(1), 9\u201312. Riecke, L., A. J. van Opstal, R. Goebel, and E. Formisano. \u201cHearing Illusory Sounds in Noise: Sensory-Perceptual Transformations in Primary Auditory Cortex.\u201d Journal of Neuroscience 27, no. 46 (November 14, 2007): 12684\u201389\\. McDermott, Josh H., and Andrew J. Oxenham. \u201cSpectral Completion of Partially Masked Sounds.\u201d Proceedings of the National Academy of Sciences 105, no. 15 (2008): 5939\u20135944. Topic overview: Hallucinations & psychedelics 10: Mar 27 Hypnagogic imagery Schacter, D. L. (1976). The hypnagogic state: a critical review of the literature. Psychological Bulletin. Topic preview: Hallucinations & schizophrenia 11: Apr 3 Dreams Stickgold, R., Hobson, J. A., Fosse, R., & Fosse, M. (2001). Sleep, Learning, and Dreams: Off-line Memory Reprocessing. Science, 294(5544), 1052\u20131057\\. Crick, F., G. Mitchison., 1983\\. The function of dream sleep. Nature. Springer Topic preview: Imagination 12: Apr 10 Lucid dreaming Voss, U., Holzmann, R., Tuin, I., , J. A. Hobson., 2009\\. Lucid dreaming: a state of consciousness with features of both waking and non-lucid dreaming. Sleep. 13: Apr 17 Hallucinations Seri\u00e8s, P., Reichert, D. P., & Storkey, A. J. (2010). Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model, 2020\u20132028. Ermentrout, G. B., & Cowan, J. D. (1979). A mathematical theory of visual hallucination patterns. Biological Cybernetics, 34(3), 137\u2013150 Howard, R. J., Brammer, M. J., David, A., Woodruff, P., & Williams, S. (1998). The anatomy of conscious vision: an fMRI study of visual hallucinations. Nature neuroscience, 1(8), 738-742. 14: Apr 24 Hallucinations Kumar, S., Sedley, W., Barnes, G. R., Teki, S., Friston, K. J., & Griffiths, T. D. (2014). A brain basis for musical hallucinations. Cortex, 52(C), 86\u201397 15: May 1 Imagination, art and design Friston, K. J., Lin, M., Frith, C. D., Pezzulo, G., Hobson, J. A., & Ondobaka, S. (2017). Active Inference, Curiosity and Insight. Neural Computation, 29(10), 2633\u20132683. 16: May 8 Finals week FINAL PROJECT PRESENTATIONS","title":"Tentative Syllabus"},{"location":"courses/PSY8036SP2018/#sample-readings-under-construction","text":"","title":"Sample Readings (under construction)"},{"location":"courses/PSY8036SP2018/#background","text":"Ackley, D. H., Hinton, G. E., & Sejnowski, T. J. (1985). A learning algorithm for Boltzmann machines. Cognitive Science, 9(1), 147\u2013169. Bastos, A. M., Usrey, W. M., Adams, R. A., Mangun, G. R., Fries, P., & Friston, K. J. (2012). Canonical Microcircuits for Predictive Coding. Neuron, 76(4), 695\u2013711. Berkes, P., Orban, G., Lengyel, M., & Fiser, J. (2011). Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment. Science, 331(6013), 83\u201387. Dayan, P., Hinton, G. E., Neal, R. M., & Zemel, R. S. (1995). The Helmholtz Machine. Neural Computation, 7(5), 889\u2013904. Ouden, den, H. E. M. (2012). How prediction errors shape perception, attention, and motivation, 1\u201312. Orban, G., Pietro Berkes, Fiser, J., & Lengyel, M. (2016). Neural Variability and Sampling-Based Probabilistic Representations in the Visual Cortex. Neuron, 92(2), 530\u2013543. MacKay, D. M. (1956). Towards an information-flow model of human behaviour. British Journal of Psychology (London, England : 1953), 47(1), 30\u201343. Lake, B. M., Salakhutdinov, R., & Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350(6266), 1332\u20131338. http://doi.org/10.1126/science.aab3050 LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436\u2013444. http://doi.org/10.1038/nature14539 McDermott, Josh H., and Andrew J. Oxenham. \u201cSpectral Completion of Partially Masked Sounds.\u201d Proceedings of the National Academy of Sciences 105, no. 15 (2008): 5939\u20135944.Mumford, D. (1992). On the computational architecture of the neocortex. Biological Cybernetics, 66(3), 241\u2013251. Mumford, D. (1994). Pattern theory: a unifying perspective, 187\u2013224. Rao, R. P. N., & Ballard, D. H. (1999). Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nature Neuroscience, 2, 79\u201387. Tu, Z., Chen, X., Yuille, A. L., & Zhu, S.-C. (2005). Image parsing: Unifying segmentation, detection, and recognition. International Journal of Computer Vision, 63(2), 113\u2013140. Yuille, A., & Kersten, D. (2006). Vision as Bayesian inference: analysis by synthesis? Trends in Cognitive Sciences, 10(7), 301\u2013308. Richards, W. (1971). The Fortification Illusions of Migraines, Scientific American, 1\u201310. Zhu, S.-C., & Mumford, D. (2006). Quest for a stochastic grammar of images. Foundations and Trends\u00ae in Computer Graphics and Vision, 2(4), 259\u2013362. http://doi.org/10.1561/0600000018","title":"Background"},{"location":"courses/PSY8036SP2018/#shallow-generative-models-texture-synthesis","text":"Freeman, J., & Simoncelli, E. P. (2011). Metamers of the ventral stream. Nature Publishing Group, 14(9), 1195\u20131201. http://doi.org/10.1038/nn.2889 McDermott, J. H., Schemitsch, M., & Simoncelli, E. P. (2013). Summary statistics in auditory perception. Nature Publishing Group, 16(4), 493\u2013498. McDermott, J. H., & Simoncelli, E. P. (2011). Sound Texture Perception via Statistics of the Auditory Periphery: Evidence from Sound Synthesis. Neuron, 71(5), 926\u2013940. Zhu, S. C., Wu, Y., & Mumford, D. (1998). Filters, random fields and maximum entropy (FRAME): Towards a unified theory for texture modeling. International Journal of Computer Vision, 27(2), 107\u2013126.","title":"Shallow generative models: Texture synthesis"},{"location":"courses/PSY8036SP2018/#hierarchical-deep-data-driven-generative-models","text":"Chen, X., Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., & Abbeel, P. (2016). InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets, 2172\u20132180. Goodfellow, I. (2016, December 31). NIPS 2016 Tutorial: Generative Adversarial Networks. Kulkarni, T. D., Whitney, W. F., Kohli, P., & Tenenbaum, J. (2015). Deep Convolutional Inverse Graphics Network, 2539\u20132547. Rock, J., Issaranon, T., Deshpande, A., & Forsyth, D. (2016, December 5). Authoring image decompositions with generative models. Varol, G., Romero, J., Martin, X., Mahmood, N., Black, M. J., Laptev, I., & Schmid, C. (2017, January 5). Learning from Synthetic Humans. Xie, J., Zhu, S.-C., & Wu, Y. N. (2016, June 3). Synthesizing Dynamic Patterns by Spatial-Temporal Generative ConvNet. Yosinski, J., Clune, J., Nguyen, A., Fuchs, T., & Lipson, H. (2015, June 22). Understanding Neural Networks Through Deep Visualization. Zhang, H., Xu, T., Li, H., Zhang, S., Wang, X., Huang, X., & Metaxas, D. (2016, December 10). StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks.","title":"Hierarchical (deep) data-driven generative models"},{"location":"courses/PSY8036SP2018/#hypnagogic-imagery","text":"Gurstelle, E. B., & de Oliveira, J. L. (2004). Daytime parahypnagogia: a state of consciousness that occurs when we almost fall asleep. Medical Hypotheses, 62(2), 166\u2013168. http://doi.org/10.1016/S0306-9877(03)00306-2 Holmes, E. A., James, E. L., Coode-Bate, T., & Deeprose, C. (2009). Can Playing the Computer Game \u201cTetris\u201d Reduce the Build-Up of Flashbacks for Trauma? A Proposal from Cognitive Science. PLoS ONE, 4(1), e4153. http://doi.org/10.1371/journal.pone.0004153.t004 Nielsen, T. A. (1995). Describing and modeling hypnagogic imagery using a systematic self-observation procedure. Dreaming, 5(2), 75\u201394. http://doi.org/10.1037/h0094426 Nielsen, T. A. (2016). A Self-Observational Study of Spontaneous Hypnagogic Imagery Using the Upright Napping Procedure. Imagination, Cognition and Personality, 11(4), 353\u2013366. http://doi.org/10.2190/3LVV-L5GY-UR5V-N0TG *Schacter, D. L. (1976). The hypnagogic state: a critical review of the literature. Psychological Bulletin. Stickgold, R. (2000). Replaying the Game: Hypnagogic Images in Normals and Amnesics. Science, 290(5490), 350\u2013353. http://doi.org/10.1126/science.290.5490.350","title":"Hypnagogic imagery"},{"location":"courses/PSY8036SP2018/#dreams","text":"Band, J. C. Z. F. A., 2016. (n.d.). Animal \u201cHypnosis\u201d and Waking Nightmares. Anomalistik.De Crick, F., G. Mitchison., 1983. The function of dream sleep. Nature. Springer *Hobson, J. A., & Mccarley, R. W. (197.). The brain as a dream state generator: an activation-synthesis hypothesis of the dream process. The American Journal of Psychiatry. Dresler, M., Koch, S. P., Wehrle, R., Spoormaker, V. I., Holsboer, F., Steiger, A., et al. (2011). Dreamed Movement Elicits Activation in the Sensorimotor Cortex. Current Biology : CB. Stickgold, R., Hobson, J. A., Fosse, R., & Fosse, M. (2001). Sleep, Learning, and Dreams: Off-line Memory Reprocessing. Science, 294(5544), 1052\u20131057. http://doi.org/10.1126/science.1063530 Stickgold, R. (2005). Sleep-dependent memory consolidation. Nature, 437(7063), 1272\u20131278. http://doi.org/10.1038/nature04286 Studies, J. H. J. O. C., 2014. (n.d.). Consciousness, dreams, and inference: the cartesian theatre revisited. Ingentaconnect.com","title":"Dreams"},{"location":"courses/PSY8036SP2018/#hallucinations","text":"Bressloff, P. C., Cowan, J. D., Golubitsky, M., Thomas, P. J., & Wiener, M. C. (2002). What geometric visual hallucinations tell us about the visual cortex. Neural Computation, 14(3), 473\u2013491. http://doi.org/10.1162/089976602317250861 Cummings, J. L., & Miller, B. L. (1987). Visual hallucinations. Clinical occurrence and use in differential diagnosis. The Western Journal of Medicine, 146(1), 46\u201351. *Ermentrout, G. B., & Cowan, J. D. (1979). A mathematical theory of visual hallucination patterns. Biological Cybernetics, 34(3), 137\u2013150. http://doi.org/10.1007/BF00336965 Merabet, L. B., Maguire, D., Warde, A., Alterescu, K., Stickgold, R., & Pascual-Leone, A. (2004). Visual hallucinations during prolonged blindfolding in sighted subjects. Journal of Neuro-Ophthalmology, 24(2), 109\u2013113. Howard, R. J., Brammer, M. J., David, A., Woodruff, P., & Williams, S. (1998). The anatomy of conscious vision: an fMRI study of visual hallucinations. Nature neuroscience, 1(8), 738-742.Seri\u00e8s, P., Reichert, D. P., & Storkey, A. J. (2010). Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model, 2020\u20132028. Silverstein, S. M. (2016). Visual Perception Disturbances in Schizophrenia: A Unified Model. In The Neuropsychopathology of Schizophrenia: Molecules, Brain Systems, Motivation, and Cognition (3 rd ed., Vol. 63, pp. 77\u2013132). Cham: Springer International Publishing. http://doi.org/10.1007/978-3-319-30596-7_4 Kumar, S., Sedley, W., Barnes, G. R., Teki, S., Friston, K. J., & Griffiths, T. D. (2014). A brain basis for musical hallucinations. Cortex, 52(C), 86\u201397. http://doi.org/10.1016/j.cortex.2013.12.002","title":"Hallucinations"},{"location":"courses/PSY8036SP2018/#imagery-and-imagination","text":"Chetverikov, A., & Kristj\u00e1nsson, \u00c1. (2016). On the joys of perceiving: Affect as feedback for perceptual predictions. Actpsy, 169(C), 1\u201310. http://doi.org/10.1016/j.actpsy.2016.05.005 Dijkstra, N., Zeidman, P., Ondobaka, S., Gerven, M. A. J., & Friston, K. (2017). Distinct Top-down and Bottom-up Brain Connectivity During Visual Perception and Imagery. Scientific Reports, 1\u20139. http://doi.org/10.1038/s41598-017-05888-8 Friston, K. J., Lin, M., Frith, C. D., Pezzulo, G., Hobson, J. A., & Ondobaka, S. (2017). Active Inference, Curiosity and Insight. Neural Computation, 29(10), 2633\u20132683. http://doi.org/10.1162/neco_a_00999 Kosslyn, S. M., & Thompson, W. L. (2003). When is early visual cortex activated during visual mental imagery? Psychological Bulletin, 129(5), 723\u2013746. http://doi.org/10.1037/0033-2909.129.5.723 Kosslyn, S. M., Alpert, N. M., Thompson, W. L., Maljkovic, V., Weise, S. B., Chabris, C. F., et al. (1993). Visual Mental Imagery Activates Topographically Organized Visual Cortex: PET Investigations. Journal of Cognitive Neuroscience, 5(3), 263\u2013287. http://doi.org/10.1162/jocn.1993.5.3.263 Kosslyn, S., & Ganis, G. (2000). Neural foundations of imagery. Nature Reviews \u2026. Pearson, J., Naselaris, T., Holmes, E. A., & Kosslyn, S. M. (2015). Mental Imagery: Functional Mechanisms and Clinical Applications. Trends in Cognitive Sciences, 19(10), 590\u2013602. http://doi.org/10.1016/j.tics.2015.08.003 Riecke, L., A. J. van Opstal, R. Goebel, and E. Formisano. \u201cHearing Illusory Sounds in Noise: Sensory-Perceptual Transformations in Primary Auditory Cortex.\u201d Journal of Neuroscience 27, no. 46 (November 14, 2007): 12684\u201389. https://doi.org/10.1523/JNEUROSCI.2713-07.2007. Schacter, D. L., Addis, D. R., Hassabis, D., Martin, V. C., Spreng, R. N., & Szpunar, K. K. (2012). The Future of Memory: Remembering, Imagining, and the Brain. Neuron, 76(4), 677\u2013694. http://doi.org/10.1016/j.neuron.2012.11.001 Zatorre, R. J., & Halpern, A. R. (2005). Mental Concerts: Musical Imagery and Auditory Cortex. Neuron, 47(1), 9\u201312. http://doi.org/10.1016/j.neuron.2005.06.013","title":"Imagery and imagination"},{"location":"courses/PSY8036SP2018/#imagery-and-memory","text":"Albers, A. M., Kok, P., Toni, I., Dijkerman, H. C., & de Lange, F. P. (2013). Shared Representations for Working Memory and Mental Imagery in Early Visual Cortex. Curbio, 23(15), 1427\u20131431. http://doi.org/10.1016/j.cub.2013.05.065 Christophel, T. B., Klink, P. C., Spitzer, B., Roelfsema, P. R., & Haynes, J.-D. (2017). The Distributed Nature of Working Memory. Trends in Cognitive Sciences, 1\u201315. http://doi.org/10.1016/j.tics.2016.12.007 Naselaris, T., Olman, C. A., Stansbury, D. E., Ugurbil, K., & Gallant, J. L. (2015). A voxel-wise encoding model for early visual areas decodes mental images of remembered scenes. NeuroImage, 105(C), 215\u2013228. http://doi.org/10.1016/j.neuroimage.2014.10.018 Self, M. W., van Kerkoerle, T., & Roelfsema, P. R. (2016). Layer-specificity in the effects of attention and working memory on activity in primary visual cortex. Nature Communications, 8, 1\u201312. http://doi.org/10.1038/ncomms13804 Stickgold, R. (2005). Sleep-dependent memory consolidation. Nature, 437(7063), 1272\u20131278. http://doi.org/10.1038/nature04286 Privacy Statement","title":"Imagery and memory"},{"location":"courses/PSY8036SP2019/","text":"Deep networks: Behavior, Brain and Theory \u00b6 Dan Kersten & Paul Schrater February 5, 2019 University of Minnesota, Spring Semester, 2019 Topics in Computational Vision Psy 8036* Psy 5993 Section 034* Instructors: Dan Kersten: kersten@umn.edu Paul Schrater: schrater@umn.edu Meeting time: First meeting Tuesday, Jan 22th, 3:00 pm. Place: Elliott N227 *Students can sign up for either Topics in Computational Vision Psy 8036 (Kersten) or Psy 5993 Section 034 (Schrater). See Canvas page for updated weekly content. Abstract \u00b6 Recent rapid advances in deep learning networks have provided the means to produce \u201cimage computable models\u201d of human vision\u2013models that take natural images as input and produce accurate predictions of perceptual decisions. However, the current and future value of deep network research for understanding the brain\u2019s visual system faces both methodological and conceptual challenges. What are the best methods to compare deep networks to perceptual behavior and to the brain? And how can we achieve a conceptual understanding of the networks, to determine which elements are important and which are not? We will read and discuss empirical papers that compare network models of object recognition to behavior and the brain. The seminar will also review work that is helping to understand what functions networks can compute, and the limitations on learning to generalize. Finally, we will discuss advances that will be needed to understand the human ability to interpret virtually any image\u2013an ability that spans a wide range of visual tasks. The class format will include short introductory lectures by the instructors to provide historical context and weekly student presentations of current literature. Students will have the opportunity to collaborate on final programming projects. The course will also introduce and use Julia, a rapidly developing language for scientific programming, which is fast, flexible, and relatively easy to learn and use. Background \u00b6 There are good online resources for learning about artificial neural networks, and in particular deep convolutional neural networks. For video content, there is the Neural Networks for Machine Learning from Geoff Hinton\u2019s 2016 coursera lectures and Fei-Fei Li\u2019s Stanford 231n course, Convolutional Neural Networks for Visual Recognition . For books, see Ian Goodfellow\u2019s Deep Learning free online or for purchase , and Visual Cortex and Deep Networks: Learning Invariant Representations for purchase by Tomaso Poggio and Fabio Anselmi. For an excellent basic background and review, watch the first 9 lectures of the Stanford 231n course. Danger !!!DRAFT!!! Introduction \u00b6 Week 1 Deep architectures \u00b6 The first class will cover background and overview of the problems of human image understanding and visual recognition and how these problems have been approached. We\u2019ll go over the goals of the seminar in the context of three questions: 1) Is computational vision close to producing biologically consistent, predictive, models of human visual recognition performance? 2) assuming that candidate models exist; how well do we understand them for example, to decide when two networks are equivalent? 3) What is missing from current theories, in terms of conceptual understanding, behavioral functionality and their neural bases? To address the first question above, we\u2019ll review empirical papers, from psychophysics and neuroscience aimed at understanding the basic-level or \u201ccore\u201d function of rapid object identification with the goal of determining best ways of comparing network models to behavior and the brain. To address the second question, we will review theoretical work that seeks to understand what functions networks can compute, and how efficiently they can learn the parameters (e.g. \u201cweights\u201d) of those functions. Finally, we will assess where research may need to go to understand human ability to interpret virtually any image\u2013a challenge that will require advances in dynamic neural architectures that allow task flexibility. Background: For a short video Introduction to deep networks, see Lecture 1 from the MIT short course (6.S191): Introduction to Deep Learning. To run Julia programs and Jupyter notebooks locally on your computer, first install Julia , and then use the anaconda distribution to install Jupyter. For video instructions see: installing Julia and Jupyter . But the quickest and easiest way to start learning and using the Julia language is to sign in to JuliaBox where you\u2019ll immediately be able to create notebooks and access tutorials. Week 2 Class cancelled due to weather. \u00b6 Week 3 Deep networks and the brain & Intro to Julia programming \u00b6 Background: Video introduction to Julia programming. Introduction to Julia for Data Science and Scientific Computing Readings: Kietzmann, T. C., McClure, P., & Kriegeskorte, N. (2018, June 5). Deep Neural Networks In Computational Neuroscience. bioRxiv. doi: 10.1101/133504 Week 4 Deep networks and the brain reviews & Simulations with the Julia language \u00b6 Readings: Turner, M. H., Sanchez Giraldo, L. G., Schwartz, O., & Rieke, F. (2019, January). Stimulus- and goal-oriented frameworks for understanding natural vision. Nature Neuroscience, 22(1), 15\u201324. doi: 10.1038/s41593-018-0284-0 Jacobs, R. A. & Bates, C. J. (2018, November 27). Comparing the Visual Representations and Performance of Humans and Deep Neural Networks. Current Directions in Psychological Science, 0963721418801342. doi: 10.1177/0963721418801342 Kay, K. N. (2018, October 15). Principles for models of neural information processing. NeuroImage. New Advances in Encoding and Decoding of Brain Signals, 180, 101\u2013109. doi: 10.1016/j.neuroimage.2017.08.016 Empirical tests \u00b6 The most basic perceptual test is \u201clook and see\u201d which is what is often what is done by modelers. One can treat \u201cadversarial examples\u201d as behavioral tests to guide model development. However, one can be systematic and ask what parametric manipulations can be made of test images that we expect humans to generalize \u201cfor free\u201d. How best to design \u201cadversarial tasks\" for a model network? For example, based on typical experience, we expect little cost to testing on certain families of novel image variations. These manipulations can be based on 3D variables (e.g. object transformations such as 3D rotation, cast shadows, occlusion), or image variables (e.g. lower contrast, blur, noise). Manipulations can be based on highly artificial variations that we already know humans have generalization abilities, if limited, such as reverse contrast, non-linear histograms, morphs, and atypical occlusions. Given these manipulations, what are good quantitative measures that can be applied to both human and model observers? When does more model training solve the problem, and can we understand when to rule out a class of network architectures? Most current perceptual tests have been with feedforward DCNNs, and that is where we start. Week 5 Empirical tests of DCNNs: human object recognition \u00b6 Methodological challenges and the design of adversarial tasks. Readings: Ullman, S., Assif, L., Fetaya, E., & Harari, D. (2016, March 8). Atoms of recognition in human and computer vision. Proceedings of the National Academy of Sciences, 113(10), 2744\u20132749. doi: 10.1073/pnas.1513198113 . pmid: 26884200 Zhang, R., Isola, P., Efros, A. A., Shechtman, E., & Wang, O. (2018). The Unreasonable Effectiveness of Deep Features as a Perceptual Metric, 10. Retrieved from http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/0299.pdf Elsayed, G. F., Shankar, S., Cheung, B., Papernot, N., Kurakin, A., Goodfellow, I., & Sohl-Dickstein, J. (2018, February 22). Adversarial Examples that Fool both Computer Vision and Time-Limited Humans. arXiv: 1802.08195 [cs, q-bio, stat] . Retrieved November 13, 2018, from http://arxiv.org/abs/1802.08195 Geirhos, R., Temme, C. R. M., Rauber, J., Sch\ufffdtt, H. H., Bethge, M., & Wichmann, F. A. (2018). Generalisation in humans and deep neural networks. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, & R. Garnett (Eds.), Advances in Neural Information Processing Systems 31 (pp. 7549\u20137561). Curran Associates, Inc. Retrieved January 28, 2019, from http://papers.nips.cc/paper/7982-generalisation-in-humans-and-deep-neural-networks.pdf Week 6 Empirical tests of DCNNs and methods of study \u00b6 Including discussion of generative models, manifold discovery, posterior estimation \u2013 useful tools? Readings: Hill, M. Q., Parde, C. J., Castillo, C. D., Colon, Y. I., Ranjan, R., Chen, J.-C., \u2026, & O\u2019Toole, A. J. (2018, December 28). Deep Convolutional Neural Networks in the Face of Caricature: Identity and Image Revealed. arXiv: 1812.10902 [cs] . Retrieved January 23, 2019, from http://arxiv.org/abs/1812.10902 Zhang, M., Feng, J., Ma, K. T., Lim, J. H., Zhao, Q., & Kreiman, G. (2018, December). Finding any Waldo with zero-shot invariant and efficient visual search. Nature Communications, 9(1). doi: 10.1038/s41467-018-06217-x Ricci, M., Kim, J., & Serre, T. (2018, February 9). Same-different problems strain convolutional neural networks. arXiv: 1802.03390 [cs, q-bio] . Retrieved December 11, 2018, from http://arxiv.org/abs/1802.03390 Luo, W., Li, Y., Urtasun, R., & Zemel, R. (n.d.). Understanding the Effective Receptive Field in Deep Convolutional Neural Networks, 9 Week 7 DCNNs and the brain \u00b6 Zhou, B., Bau, D., Oliva, A., & Torralba, A. (2018). Interpreting Deep Visual Representations via Network Dissection. IEEE Transactions on Pattern Analysis and Machine Intelligence, 1\u20131. doi: 10.1109/TPAMI.2018.2858759 Readings: Rajalingham, R., Issa, E. B., Bashivan, P., Kar, K., Schmidt, K., & DiCarlo, J. J. (2018, February 12). Large-scale, high-resolution comparison of the core visual object recognition behavior of humans, monkeys, and state-of-the-art deep artificial neural networks. doi: 10.1101/240614 Schrimpf, M., Kubilius, J., Hong, H., Majaj, N. J., Rajalingham, R., Issa, E. B., \u2026, & DiCarlo, J. J. (2018, September 5). Brain-Score: Which Artificial Neural Network for Object Recognition is most Brain-Like? doi: 10.1101/407007 Breedlove, J. L., St-Yves, G., Olman, C. A., & Naselaris, T. (2018, November 9). Human brain activity during mental imagery exhibits signatures of inference in a hierarchical generative model. doi: 10.1101/462226 Understanding deep networks \u00b6 Week 8 Theory: shallow vs. deep \u00b6 Universal approximators. Hierarchy as a solution to over-fitting. Poggio, T., Mhaskar, H., Rosasco, L., Miranda, B., & Liao, Q. (2017, October 1). Why and when can deep-but not shallow-networks avoid the curse of dimensionality: A review. International Journal of Automation and Computing, 14(5), 503\u2013519. doi: 10.1007/s11633-017-1054-2 Garriga-Alonso, A., Aitchison, L., & Rasmussen, C. E. (2019). DEEP CONVOLUTIONAL NETWORKS AS SHALLOW GAUSSIAN PROCESSES, 16 Lin, H. & Jegelka, S. (2018, June 28). ResNet with one-neuron hidden layers is a Universal Approximator. arXiv: 1806.10909 [cs, stat] . Retrieved January 18, 2019, from http://arxiv.org/abs/1806.10909 Week 9 Theory: DCNNs and implicit generative models \u00b6 Feedforward DCNNs, implicit generative models, texture, and maximum entropy. Readings: Xie, J., Zhu, S.-C., & Wu, Y. N. (2017). Synthesizing dynamic patterns by spatial-temporal generative convnet. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 7093\u20137101). Retrieved from http://openaccess.thecvf.com/content_cvpr_2017/papers/Xie_Synthesizing_Dynamic_Patterns_CVPR_2017_paper.pdf Zhang, Q., Wu, Y. N., & Zhu, S.-C. (2017, October 2). Interpretable Convolutional Neural Networks. arXiv: 1710.00935 [cs] . Retrieved February 22, 2018, from http://arxiv.org/abs/1710.00935 WU, Y. N., XIE, J., LU, Y., & ZHU, S.-C. (2018). Sparse and Deep Generalizations of the FRAME Model. Retrieved from https://www.intlpress.com/site/pub/files/_fulltext/journals/amsa/2018/0003/0001/AMSA-2018-0003-0001-a007.pdf Week 10 Theory: invariance \u00b6 Readings: Tacchetti, A., Isik, L., & Poggio, T. A. (2018, September 15). Invariant Recognition Shapes Neural Representations of Visual Input. Annual Review of Vision Science, 4(1), 403\u2013422. doi: 10.1146/annurev-vision-091517-034103 Leibo, J. Z., Liao, Q., Anselmi, F., & Poggio, T. (2015, October 23). The Invariance Hypothesis Implies Domain-Specific Regions in Visual Cortex. PLOS Computational Biology, 11(10), e1004390. doi: 10.1371/journal.pcbi.1004390 Azulay, A. & Weiss, Y. (2018, May 30). Why do deep convolutional networks generalize so poorly to small image transformations? arXiv: 1805.12177 [cs] . Retrieved October 4, 2018, from http://arxiv.org/abs/1805.12177 Week 11 Theory: normalization \u00b6 The value and types of normalization: batch, spatial, temporal, and channel normalization. Liao, Q., Kawaguchi, K., & Poggio, T. (2016, October 19). Streaming Normalization: Towards Simpler and More Biologically-plausible Normalizations for Online and Recurrent Learning. arXiv: 1610.06160 [cs] . Retrieved December 7, 2018, from http://arxiv.org/abs/1610.06160 What\u2019s missing? \u00b6 Week 12 Compositionality and semantic accessibility \u00b6 The problems of occlusion and articulation (e.g. body pose). Computing spatial relationships,... Readings: Burgess, C. P., Matthey, L., Watters, N., Kabra, R., Higgins, I., Botvinick, M., & Lerchner, A. (2019, January 22). MONet: Unsupervised Scene Decomposition and Representation. arXiv: 1901.11390 [cs, stat] . Retrieved February 5, 2019, from http://arxiv.org/abs/1901.11390 Tang, H., Schrimpf, M., Lotter, W., Moerman, C., Paredes, A., Ortega Caro, J., \u2026, & Kreiman, G. (2018, August 28). Recurrent computations for visual pattern completion. Proceedings of the National Academy of Sciences, 115(35), 8835\u20138840. doi: 10.1073/pnas.1719397115 Zhang, Z., Xie, C., Wang, J.","title":"PSY8036SP2019"},{"location":"courses/PSY8036SP2019/#deep-networks-behavior-brain-and-theory","text":"Dan Kersten & Paul Schrater February 5, 2019 University of Minnesota, Spring Semester, 2019 Topics in Computational Vision Psy 8036* Psy 5993 Section 034* Instructors: Dan Kersten: kersten@umn.edu Paul Schrater: schrater@umn.edu Meeting time: First meeting Tuesday, Jan 22th, 3:00 pm. Place: Elliott N227 *Students can sign up for either Topics in Computational Vision Psy 8036 (Kersten) or Psy 5993 Section 034 (Schrater). See Canvas page for updated weekly content.","title":"Deep networks: Behavior, Brain and Theory"},{"location":"courses/PSY8036SP2019/#abstract","text":"Recent rapid advances in deep learning networks have provided the means to produce \u201cimage computable models\u201d of human vision\u2013models that take natural images as input and produce accurate predictions of perceptual decisions. However, the current and future value of deep network research for understanding the brain\u2019s visual system faces both methodological and conceptual challenges. What are the best methods to compare deep networks to perceptual behavior and to the brain? And how can we achieve a conceptual understanding of the networks, to determine which elements are important and which are not? We will read and discuss empirical papers that compare network models of object recognition to behavior and the brain. The seminar will also review work that is helping to understand what functions networks can compute, and the limitations on learning to generalize. Finally, we will discuss advances that will be needed to understand the human ability to interpret virtually any image\u2013an ability that spans a wide range of visual tasks. The class format will include short introductory lectures by the instructors to provide historical context and weekly student presentations of current literature. Students will have the opportunity to collaborate on final programming projects. The course will also introduce and use Julia, a rapidly developing language for scientific programming, which is fast, flexible, and relatively easy to learn and use.","title":"Abstract"},{"location":"courses/PSY8036SP2019/#background","text":"There are good online resources for learning about artificial neural networks, and in particular deep convolutional neural networks. For video content, there is the Neural Networks for Machine Learning from Geoff Hinton\u2019s 2016 coursera lectures and Fei-Fei Li\u2019s Stanford 231n course, Convolutional Neural Networks for Visual Recognition . For books, see Ian Goodfellow\u2019s Deep Learning free online or for purchase , and Visual Cortex and Deep Networks: Learning Invariant Representations for purchase by Tomaso Poggio and Fabio Anselmi. For an excellent basic background and review, watch the first 9 lectures of the Stanford 231n course. Danger !!!DRAFT!!!","title":"Background"},{"location":"courses/PSY8036SP2019/#introduction","text":"","title":"Introduction"},{"location":"courses/PSY8036SP2019/#week-1-deep-architectures","text":"The first class will cover background and overview of the problems of human image understanding and visual recognition and how these problems have been approached. We\u2019ll go over the goals of the seminar in the context of three questions: 1) Is computational vision close to producing biologically consistent, predictive, models of human visual recognition performance? 2) assuming that candidate models exist; how well do we understand them for example, to decide when two networks are equivalent? 3) What is missing from current theories, in terms of conceptual understanding, behavioral functionality and their neural bases? To address the first question above, we\u2019ll review empirical papers, from psychophysics and neuroscience aimed at understanding the basic-level or \u201ccore\u201d function of rapid object identification with the goal of determining best ways of comparing network models to behavior and the brain. To address the second question, we will review theoretical work that seeks to understand what functions networks can compute, and how efficiently they can learn the parameters (e.g. \u201cweights\u201d) of those functions. Finally, we will assess where research may need to go to understand human ability to interpret virtually any image\u2013a challenge that will require advances in dynamic neural architectures that allow task flexibility. Background: For a short video Introduction to deep networks, see Lecture 1 from the MIT short course (6.S191): Introduction to Deep Learning. To run Julia programs and Jupyter notebooks locally on your computer, first install Julia , and then use the anaconda distribution to install Jupyter. For video instructions see: installing Julia and Jupyter . But the quickest and easiest way to start learning and using the Julia language is to sign in to JuliaBox where you\u2019ll immediately be able to create notebooks and access tutorials.","title":"Week 1 Deep architectures"},{"location":"courses/PSY8036SP2019/#week-2-class-cancelled-due-to-weather","text":"","title":"Week 2 Class cancelled due to weather."},{"location":"courses/PSY8036SP2019/#week-3-deep-networks-and-the-brain-intro-to-julia-programming","text":"Background: Video introduction to Julia programming. Introduction to Julia for Data Science and Scientific Computing Readings: Kietzmann, T. C., McClure, P., & Kriegeskorte, N. (2018, June 5). Deep Neural Networks In Computational Neuroscience. bioRxiv. doi: 10.1101/133504","title":"Week 3 Deep networks and the brain &amp; Intro to Julia programming"},{"location":"courses/PSY8036SP2019/#week-4-deep-networks-and-the-brain-reviews-simulations-with-the-julia-language","text":"Readings: Turner, M. H., Sanchez Giraldo, L. G., Schwartz, O., & Rieke, F. (2019, January). Stimulus- and goal-oriented frameworks for understanding natural vision. Nature Neuroscience, 22(1), 15\u201324. doi: 10.1038/s41593-018-0284-0 Jacobs, R. A. & Bates, C. J. (2018, November 27). Comparing the Visual Representations and Performance of Humans and Deep Neural Networks. Current Directions in Psychological Science, 0963721418801342. doi: 10.1177/0963721418801342 Kay, K. N. (2018, October 15). Principles for models of neural information processing. NeuroImage. New Advances in Encoding and Decoding of Brain Signals, 180, 101\u2013109. doi: 10.1016/j.neuroimage.2017.08.016","title":"Week 4 Deep networks and the brain reviews &amp; Simulations with the Julia language"},{"location":"courses/PSY8036SP2019/#empirical-tests","text":"The most basic perceptual test is \u201clook and see\u201d which is what is often what is done by modelers. One can treat \u201cadversarial examples\u201d as behavioral tests to guide model development. However, one can be systematic and ask what parametric manipulations can be made of test images that we expect humans to generalize \u201cfor free\u201d. How best to design \u201cadversarial tasks\" for a model network? For example, based on typical experience, we expect little cost to testing on certain families of novel image variations. These manipulations can be based on 3D variables (e.g. object transformations such as 3D rotation, cast shadows, occlusion), or image variables (e.g. lower contrast, blur, noise). Manipulations can be based on highly artificial variations that we already know humans have generalization abilities, if limited, such as reverse contrast, non-linear histograms, morphs, and atypical occlusions. Given these manipulations, what are good quantitative measures that can be applied to both human and model observers? When does more model training solve the problem, and can we understand when to rule out a class of network architectures? Most current perceptual tests have been with feedforward DCNNs, and that is where we start.","title":"Empirical tests"},{"location":"courses/PSY8036SP2019/#week-5-empirical-tests-of-dcnns-human-object-recognition","text":"Methodological challenges and the design of adversarial tasks. Readings: Ullman, S., Assif, L., Fetaya, E., & Harari, D. (2016, March 8). Atoms of recognition in human and computer vision. Proceedings of the National Academy of Sciences, 113(10), 2744\u20132749. doi: 10.1073/pnas.1513198113 . pmid: 26884200 Zhang, R., Isola, P., Efros, A. A., Shechtman, E., & Wang, O. (2018). The Unreasonable Effectiveness of Deep Features as a Perceptual Metric, 10. Retrieved from http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/0299.pdf Elsayed, G. F., Shankar, S., Cheung, B., Papernot, N., Kurakin, A., Goodfellow, I., & Sohl-Dickstein, J. (2018, February 22). Adversarial Examples that Fool both Computer Vision and Time-Limited Humans. arXiv: 1802.08195 [cs, q-bio, stat] . Retrieved November 13, 2018, from http://arxiv.org/abs/1802.08195 Geirhos, R., Temme, C. R. M., Rauber, J., Sch\ufffdtt, H. H., Bethge, M., & Wichmann, F. A. (2018). Generalisation in humans and deep neural networks. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, & R. Garnett (Eds.), Advances in Neural Information Processing Systems 31 (pp. 7549\u20137561). Curran Associates, Inc. Retrieved January 28, 2019, from http://papers.nips.cc/paper/7982-generalisation-in-humans-and-deep-neural-networks.pdf","title":"Week 5 Empirical tests of DCNNs: human object recognition"},{"location":"courses/PSY8036SP2019/#week-6-empirical-tests-of-dcnns-and-methods-of-study","text":"Including discussion of generative models, manifold discovery, posterior estimation \u2013 useful tools? Readings: Hill, M. Q., Parde, C. J., Castillo, C. D., Colon, Y. I., Ranjan, R., Chen, J.-C., \u2026, & O\u2019Toole, A. J. (2018, December 28). Deep Convolutional Neural Networks in the Face of Caricature: Identity and Image Revealed. arXiv: 1812.10902 [cs] . Retrieved January 23, 2019, from http://arxiv.org/abs/1812.10902 Zhang, M., Feng, J., Ma, K. T., Lim, J. H., Zhao, Q., & Kreiman, G. (2018, December). Finding any Waldo with zero-shot invariant and efficient visual search. Nature Communications, 9(1). doi: 10.1038/s41467-018-06217-x Ricci, M., Kim, J., & Serre, T. (2018, February 9). Same-different problems strain convolutional neural networks. arXiv: 1802.03390 [cs, q-bio] . Retrieved December 11, 2018, from http://arxiv.org/abs/1802.03390 Luo, W., Li, Y., Urtasun, R., & Zemel, R. (n.d.). Understanding the Effective Receptive Field in Deep Convolutional Neural Networks, 9","title":"Week 6 Empirical tests of DCNNs and methods of study"},{"location":"courses/PSY8036SP2019/#week-7-dcnns-and-the-brain","text":"Zhou, B., Bau, D., Oliva, A., & Torralba, A. (2018). Interpreting Deep Visual Representations via Network Dissection. IEEE Transactions on Pattern Analysis and Machine Intelligence, 1\u20131. doi: 10.1109/TPAMI.2018.2858759 Readings: Rajalingham, R., Issa, E. B., Bashivan, P., Kar, K., Schmidt, K., & DiCarlo, J. J. (2018, February 12). Large-scale, high-resolution comparison of the core visual object recognition behavior of humans, monkeys, and state-of-the-art deep artificial neural networks. doi: 10.1101/240614 Schrimpf, M., Kubilius, J., Hong, H., Majaj, N. J., Rajalingham, R., Issa, E. B., \u2026, & DiCarlo, J. J. (2018, September 5). Brain-Score: Which Artificial Neural Network for Object Recognition is most Brain-Like? doi: 10.1101/407007 Breedlove, J. L., St-Yves, G., Olman, C. A., & Naselaris, T. (2018, November 9). Human brain activity during mental imagery exhibits signatures of inference in a hierarchical generative model. doi: 10.1101/462226","title":"Week 7 DCNNs and the brain"},{"location":"courses/PSY8036SP2019/#understanding-deep-networks","text":"","title":"Understanding deep networks"},{"location":"courses/PSY8036SP2019/#week-8-theory-shallow-vs-deep","text":"Universal approximators. Hierarchy as a solution to over-fitting. Poggio, T., Mhaskar, H., Rosasco, L., Miranda, B., & Liao, Q. (2017, October 1). Why and when can deep-but not shallow-networks avoid the curse of dimensionality: A review. International Journal of Automation and Computing, 14(5), 503\u2013519. doi: 10.1007/s11633-017-1054-2 Garriga-Alonso, A., Aitchison, L., & Rasmussen, C. E. (2019). DEEP CONVOLUTIONAL NETWORKS AS SHALLOW GAUSSIAN PROCESSES, 16 Lin, H. & Jegelka, S. (2018, June 28). ResNet with one-neuron hidden layers is a Universal Approximator. arXiv: 1806.10909 [cs, stat] . Retrieved January 18, 2019, from http://arxiv.org/abs/1806.10909","title":"Week 8 Theory: shallow vs. deep"},{"location":"courses/PSY8036SP2019/#week-9-theory-dcnns-and-implicit-generative-models","text":"Feedforward DCNNs, implicit generative models, texture, and maximum entropy. Readings: Xie, J., Zhu, S.-C., & Wu, Y. N. (2017). Synthesizing dynamic patterns by spatial-temporal generative convnet. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 7093\u20137101). Retrieved from http://openaccess.thecvf.com/content_cvpr_2017/papers/Xie_Synthesizing_Dynamic_Patterns_CVPR_2017_paper.pdf Zhang, Q., Wu, Y. N., & Zhu, S.-C. (2017, October 2). Interpretable Convolutional Neural Networks. arXiv: 1710.00935 [cs] . Retrieved February 22, 2018, from http://arxiv.org/abs/1710.00935 WU, Y. N., XIE, J., LU, Y., & ZHU, S.-C. (2018). Sparse and Deep Generalizations of the FRAME Model. Retrieved from https://www.intlpress.com/site/pub/files/_fulltext/journals/amsa/2018/0003/0001/AMSA-2018-0003-0001-a007.pdf","title":"Week 9 Theory: DCNNs and implicit generative models"},{"location":"courses/PSY8036SP2019/#week-10-theory-invariance","text":"Readings: Tacchetti, A., Isik, L., & Poggio, T. A. (2018, September 15). Invariant Recognition Shapes Neural Representations of Visual Input. Annual Review of Vision Science, 4(1), 403\u2013422. doi: 10.1146/annurev-vision-091517-034103 Leibo, J. Z., Liao, Q., Anselmi, F., & Poggio, T. (2015, October 23). The Invariance Hypothesis Implies Domain-Specific Regions in Visual Cortex. PLOS Computational Biology, 11(10), e1004390. doi: 10.1371/journal.pcbi.1004390 Azulay, A. & Weiss, Y. (2018, May 30). Why do deep convolutional networks generalize so poorly to small image transformations? arXiv: 1805.12177 [cs] . Retrieved October 4, 2018, from http://arxiv.org/abs/1805.12177","title":"Week 10 Theory: invariance"},{"location":"courses/PSY8036SP2019/#week-11-theory-normalization","text":"The value and types of normalization: batch, spatial, temporal, and channel normalization. Liao, Q., Kawaguchi, K., & Poggio, T. (2016, October 19). Streaming Normalization: Towards Simpler and More Biologically-plausible Normalizations for Online and Recurrent Learning. arXiv: 1610.06160 [cs] . Retrieved December 7, 2018, from http://arxiv.org/abs/1610.06160","title":"Week 11 Theory: normalization"},{"location":"courses/PSY8036SP2019/#whats-missing","text":"","title":"What\u2019s missing?"},{"location":"courses/PSY8036SP2019/#week-12-compositionality-and-semantic-accessibility","text":"The problems of occlusion and articulation (e.g. body pose). Computing spatial relationships,... Readings: Burgess, C. P., Matthey, L., Watters, N., Kabra, R., Higgins, I., Botvinick, M., & Lerchner, A. (2019, January 22). MONet: Unsupervised Scene Decomposition and Representation. arXiv: 1901.11390 [cs, stat] . Retrieved February 5, 2019, from http://arxiv.org/abs/1901.11390 Tang, H., Schrimpf, M., Lotter, W., Moerman, C., Paredes, A., Ortega Caro, J., \u2026, & Kreiman, G. (2018, August 28). Recurrent computations for visual pattern completion. Proceedings of the National Academy of Sciences, 115(35), 8835\u20138840. doi: 10.1073/pnas.1719397115 Zhang, Z., Xie, C., Wang, J.","title":"Week 12 Compositionality and semantic accessibility"},{"location":"datasets/camouflage/camouflage/","text":"Download \u00b6 The digital embryo camouflage challenge dataset: download This dataset provides 20 images of 9 objects. Each image has a novel camouflage albedo texture map, and a novel background of other digital embryos, also with a novel arrangements and camouflage patterns. The target object is always in front, i.e. unoccluded and \"in plain view\". The test set consists of 20 additional camouflaged images of the 9 objects. It is difficult to perceive the target object in any given image without experience. As an illustration of the effectiveness of the camouflage, note that on initial viewing a target object in the video below only becomes visible once it moves. Try pausing, then restarting the video. After a while, you may learn to recognize and segment the target object even in a static view. Making Digital Embryos \u00b6 Digital embryos are are created using a stochastic process which is analogous to embryological development. The novelty of the objects arises from the random initialization of growth \"hormones\" to the vertices of the polygon \"egge\". Because of the embryological nature of the algorithm, digital embryos bear some resemble to living forms, although they do not usually look like any particular plant or animal species. Digital embryos may have applications in art, entertainment, research, or anywhere novel 3D shapes are useful. Our interest is in vision research to understand how we learn novel objects. the embryos are used to study camouflage, visual learning, and object recognition. Brady, M. J., & Kersten, D. (2003). Bootstrapped learning of novel objects. J Vis, 3(6), 413-422.( pdf ) For more information on the algorithm, see: Brady, M. J. (1999). Psychophysical investigations of incomplete forms and forms with background (Order No. 9921424). Available from Dissertations & Theses @ CIC Institutions; ProQuest Dissertations & Theses A&I. (304522737) For more on the development and applications of digital embryos, see: Jay Hegd\u00e9's web page","title":"Camouflage"},{"location":"datasets/camouflage/camouflage/#download","text":"The digital embryo camouflage challenge dataset: download This dataset provides 20 images of 9 objects. Each image has a novel camouflage albedo texture map, and a novel background of other digital embryos, also with a novel arrangements and camouflage patterns. The target object is always in front, i.e. unoccluded and \"in plain view\". The test set consists of 20 additional camouflaged images of the 9 objects. It is difficult to perceive the target object in any given image without experience. As an illustration of the effectiveness of the camouflage, note that on initial viewing a target object in the video below only becomes visible once it moves. Try pausing, then restarting the video. After a while, you may learn to recognize and segment the target object even in a static view.","title":"Download"},{"location":"datasets/camouflage/camouflage/#making-digital-embryos","text":"Digital embryos are are created using a stochastic process which is analogous to embryological development. The novelty of the objects arises from the random initialization of growth \"hormones\" to the vertices of the polygon \"egge\". Because of the embryological nature of the algorithm, digital embryos bear some resemble to living forms, although they do not usually look like any particular plant or animal species. Digital embryos may have applications in art, entertainment, research, or anywhere novel 3D shapes are useful. Our interest is in vision research to understand how we learn novel objects. the embryos are used to study camouflage, visual learning, and object recognition. Brady, M. J., & Kersten, D. (2003). Bootstrapped learning of novel objects. J Vis, 3(6), 413-422.( pdf ) For more information on the algorithm, see: Brady, M. J. (1999). Psychophysical investigations of incomplete forms and forms with background (Order No. 9921424). Available from Dissertations & Theses @ CIC Institutions; ProQuest Dissertations & Theses A&I. (304522737) For more on the development and applications of digital embryos, see: Jay Hegd\u00e9's web page","title":"Making Digital Embryos"},{"location":"demos/lightness-shape/","text":"Lightness and shape \u00b6 The gradually shaded left and right halves of the flat object on the left are physically identical. The central regions of the left and right cylinders on the right also have identical intensity profiles. Further, all four of gradients are identical to across the central regions. The horizontal light intensity profiles are illustrated by the red lines. Your browser does not support HTML5 video. Knill, D. C., & Kersten, D. (1991). Apparent surface curvature affects lightness perception. Nature, 351, 228-230.","title":"Lightness and Shape"},{"location":"demos/lightness-shape/#lightness-and-shape","text":"The gradually shaded left and right halves of the flat object on the left are physically identical. The central regions of the left and right cylinders on the right also have identical intensity profiles. Further, all four of gradients are identical to across the central regions. The horizontal light intensity profiles are illustrated by the red lines. Your browser does not support HTML5 video. Knill, D. C., & Kersten, D. (1991). Apparent surface curvature affects lightness perception. Nature, 351, 228-230.","title":"Lightness and shape"},{"location":"demos/matte-shiny/","text":"Material from Motion \u00b6 Shiny or Matte? \u00b6 See: Hartung, B., & Kersten, D. (2002). Distinguishing shiny from matte [Abstract]. Journal of Vision, 2(7), 551a abstract . DOI 10.1167/2.7.551. This video shows how motion can affect material appearance. The first half of the movie simulates a chrome teapot rotating in mid-air. The appearance is what one might expect, that of a shiny chrome teapot. Half way through the movie, the reflection gets painted on to the teapot making a \"sticky reflection\". The painted-on pattern mimics what one would see in the reflection of a perfectly reflecting chrome teapot. Now the body of the teapot appears more or less like a painted matte object during the second half of the movie. Try stopping the movie. The teapot reverts to a more shiny appearance. Now with a croissant-shaped object: Your browser does not support the video tag. Many observers report that this polygonal object seems to look transparent rather than shiny-opaque. Your browser does not support the video tag. And the last one shows the \"wrong\" optic flow, in which the environment is moving about a different axis than the teapot. Your browser does not support the video tag. The highlights at points of high curvature in this last one conflict to some extent with the matte interpretation, and thus one can see these points as from a shiny object. Also, note the lack of contact information (inter-reflections are not modeled in this rendering) for the handle and spout. Your browser does not support the video tag. Movies were created by Bruce Hartung in collaboration with Dan Kersten and advice from Ted Adelson. The measured illumination map was obtained from http://www.debevec.org/Probes/ . This study was reported at the 2002 meeting of the Vision ScienceS Society in Sarasota, Florida: Hartung, B., & Kersten, D. (2002). Distinguishing Shiny from Matte. Presented at Vision SciencieS, Sarasota, Florida. For more on human perception of shiny objects, see: Doerschner, K., Fleming, R. W., Yilmaz, O., Schrater, P. R., Hartung, B., & Kersten, D. (2011). Visual Motion and the Perception of Surface Material. Current Biology, 21(23), 2010\u20132016. https://doi.org/10.1016/j.cub.2011.10.036 R.W. Fleming, R.O. Dror, and E.H. Adelson. How do Humans Determine Reflectance Properties under Unknown Illumination? Proceedings of the Workshop on Identifying Objects Across Variations in Lighting at CVPR, Hawaii, December, 2001.","title":"Shiny or Matte?"},{"location":"demos/matte-shiny/#material-from-motion","text":"","title":"Material from Motion"},{"location":"demos/matte-shiny/#shiny-or-matte","text":"See: Hartung, B., & Kersten, D. (2002). Distinguishing shiny from matte [Abstract]. Journal of Vision, 2(7), 551a abstract . DOI 10.1167/2.7.551. This video shows how motion can affect material appearance. The first half of the movie simulates a chrome teapot rotating in mid-air. The appearance is what one might expect, that of a shiny chrome teapot. Half way through the movie, the reflection gets painted on to the teapot making a \"sticky reflection\". The painted-on pattern mimics what one would see in the reflection of a perfectly reflecting chrome teapot. Now the body of the teapot appears more or less like a painted matte object during the second half of the movie. Try stopping the movie. The teapot reverts to a more shiny appearance. Now with a croissant-shaped object: Your browser does not support the video tag. Many observers report that this polygonal object seems to look transparent rather than shiny-opaque. Your browser does not support the video tag. And the last one shows the \"wrong\" optic flow, in which the environment is moving about a different axis than the teapot. Your browser does not support the video tag. The highlights at points of high curvature in this last one conflict to some extent with the matte interpretation, and thus one can see these points as from a shiny object. Also, note the lack of contact information (inter-reflections are not modeled in this rendering) for the handle and spout. Your browser does not support the video tag. Movies were created by Bruce Hartung in collaboration with Dan Kersten and advice from Ted Adelson. The measured illumination map was obtained from http://www.debevec.org/Probes/ . This study was reported at the 2002 meeting of the Vision ScienceS Society in Sarasota, Florida: Hartung, B., & Kersten, D. (2002). Distinguishing Shiny from Matte. Presented at Vision SciencieS, Sarasota, Florida. For more on human perception of shiny objects, see: Doerschner, K., Fleming, R. W., Yilmaz, O., Schrater, P. R., Hartung, B., & Kersten, D. (2011). Visual Motion and the Perception of Surface Material. Current Biology, 21(23), 2010\u20132016. https://doi.org/10.1016/j.cub.2011.10.036 R.W. Fleming, R.O. Dror, and E.H. Adelson. How do Humans Determine Reflectance Properties under Unknown Illumination? Proceedings of the Workshop on Identifying Objects Across Variations in Lighting at CVPR, Hawaii, December, 2001.","title":"Shiny or Matte?"},{"location":"demos/retinotopy/","text":"Illustration of log-polar mapping \u00b6 Retinal stimulation Corresponding V1 activity Mathematica code to do a cartesian to log-polar mapping download","title":"Retinotopy"},{"location":"demos/retinotopy/#illustration-of-log-polar-mapping","text":"Retinal stimulation Corresponding V1 activity Mathematica code to do a cartesian to log-polar mapping download","title":"Illustration of log-polar mapping"},{"location":"demos/shadows/","text":"Cast shadows and depth \u00b6 The strength of a cast shadow as a cue for depth can be illustrated by moving a shadow without moving the object casting the shadow. In the demo below, the green square doesn't move in the image, but it appears to move in depth, and in the image: See: Kersten, D., Knill, D., Mamassian, P. et al. Illusory motion from shadows. Nature 379, 31 (1996). local link . Nature site: (https://doi.org/10.1038/379031a0.). In the next demonstration, the image size of the ball is unchanged, but the position of the ball changes. The ball follows a diagonal trajectory inside a box. The ball's shadow first moves diagonally in a trajectory parallel to the ball, then it moves horizontally. The ball's trajectory is the same for both segments of the animation. The apparent motion in depth of the ball is strikingly different in the two cases. When the shadow is diagonal, the ball appears to slide along the floor to the back of the box. When the shadow trajectory is horizontal, the ball appears to rise above the floor of the box. See: Kersten, D., Mamassian, P., & Knill, D. C. (1997). Moving cast shadows induce apparent motion in depth. Perception, 26(2), 171-192. link Shadows and the bouncing ball \u00b6 The next demo provides a simple demonstration of vision's preference to interpret motion of a ball and its shadow as consistent with a stationary light source. 12 minutes worth of assorted shadow demonstrations \u00b6 Developed at the Max Planck Institute for Biological Cybernetics with Pascal Mamassian, Isabelle B\u00fclthoff, David Knill and Heinrich B\u00fclthoff in 1993. The video includes demonstrations of: how cast shadows can affect perceived size through depth; how motion of the light source are interpreted as changes in depth; apparent non-linear motion from cast shadows; how additional cues for light source motion don't help in interpreting ball motion as due to light source rather than depth changes; how cast shadows can reduce shape ambiguity; influence perceived rigidity; how the shape of an object doesn't need to match the shape or color of the \"shadow\" patch; and how the reversing the contrast of the \"shadow\"-i.e. a light rather than dark shadow--reduces the effect; and how illumination from below also can reduce the strength of the depth illusion. Shadows and sterescopic depth \u00b6 In this video, as in the above green square demo, the size of the green square doesn't change. But a stereoscopic cue is introduced that is in conflict with the shadow cue. The demonstration should be viewed with crossed-fusion--i.e. the left image to the right eye, and the right image to the left eye. The shadows are still effective at conveying a change in depth, despite the stereo disparity cue consistent with a depth change in the opposite direction\u2014at least initially. After a while, the disparity seems to win out and the green square move appears to move towards the checkerboard background and \"squeeze\" the dark shadow away, then recede from the background and \"suck\" the shadow under itself.","title":"Shadows"},{"location":"demos/shadows/#cast-shadows-and-depth","text":"The strength of a cast shadow as a cue for depth can be illustrated by moving a shadow without moving the object casting the shadow. In the demo below, the green square doesn't move in the image, but it appears to move in depth, and in the image: See: Kersten, D., Knill, D., Mamassian, P. et al. Illusory motion from shadows. Nature 379, 31 (1996). local link . Nature site: (https://doi.org/10.1038/379031a0.). In the next demonstration, the image size of the ball is unchanged, but the position of the ball changes. The ball follows a diagonal trajectory inside a box. The ball's shadow first moves diagonally in a trajectory parallel to the ball, then it moves horizontally. The ball's trajectory is the same for both segments of the animation. The apparent motion in depth of the ball is strikingly different in the two cases. When the shadow is diagonal, the ball appears to slide along the floor to the back of the box. When the shadow trajectory is horizontal, the ball appears to rise above the floor of the box. See: Kersten, D., Mamassian, P., & Knill, D. C. (1997). Moving cast shadows induce apparent motion in depth. Perception, 26(2), 171-192. link","title":"Cast shadows and depth"},{"location":"demos/shadows/#shadows-and-the-bouncing-ball","text":"The next demo provides a simple demonstration of vision's preference to interpret motion of a ball and its shadow as consistent with a stationary light source.","title":"Shadows and the bouncing ball"},{"location":"demos/shadows/#12-minutes-worth-of-assorted-shadow-demonstrations","text":"Developed at the Max Planck Institute for Biological Cybernetics with Pascal Mamassian, Isabelle B\u00fclthoff, David Knill and Heinrich B\u00fclthoff in 1993. The video includes demonstrations of: how cast shadows can affect perceived size through depth; how motion of the light source are interpreted as changes in depth; apparent non-linear motion from cast shadows; how additional cues for light source motion don't help in interpreting ball motion as due to light source rather than depth changes; how cast shadows can reduce shape ambiguity; influence perceived rigidity; how the shape of an object doesn't need to match the shape or color of the \"shadow\" patch; and how the reversing the contrast of the \"shadow\"-i.e. a light rather than dark shadow--reduces the effect; and how illumination from below also can reduce the strength of the depth illusion.","title":"12 minutes worth of assorted shadow demonstrations"},{"location":"demos/shadows/#shadows-and-sterescopic-depth","text":"In this video, as in the above green square demo, the size of the green square doesn't change. But a stereoscopic cue is introduced that is in conflict with the shadow cue. The demonstration should be viewed with crossed-fusion--i.e. the left image to the right eye, and the right image to the left eye. The shadows are still effective at conveying a change in depth, despite the stereo disparity cue consistent with a depth change in the opposite direction\u2014at least initially. After a while, the disparity seems to win out and the green square move appears to move towards the checkerboard background and \"squeeze\" the dark shadow away, then recede from the background and \"suck\" the shadow under itself.","title":"Shadows and sterescopic depth"},{"location":"demos/transparency/","text":"Transparency and structure from motion \u00b6 Bistability in Transparency and rigidity \u00b6 When you initially view, you will most likely see one transparent (darker) square surface in front of a (lighter) opaque square surface, together rotating about a single axis. This percept corresponds an interpretation of the front and back faces of a rotating cube viewed from slightly above, similar to: 1) two faces rotating about a single central axis. but with a transparent rather than opaque front face. However, if you look long enough at the first transparency video, eventually your perceptual interpretation will suddenly flip, and you will see the two surfaces apparently slipping and sliding over one another, where the lighter upper surface now appears transparent and in front, while the lower darker surface now appears opaque and in back. This percept looks like 2): It is as if your \"visual brain\" \"knows\" about the physics of rotation and surface transparency, coming up with the split axes interpretation even before you are cognitively aware that this is a second possible physical explanation for the rotation. Kersten, D., B\u00fclthoff, H. H., Schwartz, B., & Kurtz, K. (1992). Interaction between transparency and structure from motion. Neural Computation, 4(4), 573-589. These quicktime video demos were prepared by Gina Albanese.","title":"Transparency"},{"location":"demos/transparency/#transparency-and-structure-from-motion","text":"","title":"Transparency and structure from motion"},{"location":"demos/transparency/#bistability-in-transparency-and-rigidity","text":"When you initially view, you will most likely see one transparent (darker) square surface in front of a (lighter) opaque square surface, together rotating about a single axis. This percept corresponds an interpretation of the front and back faces of a rotating cube viewed from slightly above, similar to: 1) two faces rotating about a single central axis. but with a transparent rather than opaque front face. However, if you look long enough at the first transparency video, eventually your perceptual interpretation will suddenly flip, and you will see the two surfaces apparently slipping and sliding over one another, where the lighter upper surface now appears transparent and in front, while the lower darker surface now appears opaque and in back. This percept looks like 2): It is as if your \"visual brain\" \"knows\" about the physics of rotation and surface transparency, coming up with the split axes interpretation even before you are cognitively aware that this is a second possible physical explanation for the rotation. Kersten, D., B\u00fclthoff, H. H., Schwartz, B., & Kurtz, K. (1992). Interaction between transparency and structure from motion. Neural Computation, 4(4), 573-589. These quicktime video demos were prepared by Gina Albanese.","title":"Bistability in Transparency and rigidity"}]}